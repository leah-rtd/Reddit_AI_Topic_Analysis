{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAPm0qIzWWjp"
      },
      "outputs": [],
      "source": [
        "## Imports which will be necessary for dataframes(pandas) getting rid of NAs\n",
        "## (numpy)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## This is how to connect your Colab notebook to your Google Drive files\n",
        "## I have the\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l27Tkj1AXNa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Reading the CSV all_comments.csv which is the dataframe with has the\n",
        "## following columns: date, title, text, subreddit, num of comments, url,\n",
        "## full_comment (which are all of the comments of the post in one cell)\n",
        "\n",
        "\n",
        "## Remember to change the path to your path\n",
        "all_comments = pd.read_csv(\"/content/drive/MyDrive/DeepLearning/data/all_comments.csv\", encoding='utf-8')"
      ],
      "metadata": {
        "id": "tJKY8G4kK_u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Having a look at the dataframe\n",
        "\n",
        "all_comments.head()"
      ],
      "metadata": {
        "id": "Z8Xfi3bZLNKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation for `pip install transformers`\n",
        "https://pypi.org/project/transformers/\n",
        "We put the `!` in front so we can write command line commands into the notebook"
      ],
      "metadata": {
        "id": "wENiJbkcLu_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## This is the command to install hugging face transformers intot the\n",
        "## notebook, even if you have the package in your python environment\n",
        "## you need to download it again for this notebook\n",
        "\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "wYpt_I79WlcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing the pipeline for the model which we want to use\n",
        "## see more instructions here\n",
        "## https://huggingface.co/facebook/bart-large-mnli\n",
        "\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "-uBSjxGGWfFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Replacing np.nan with \"\" so that I can create the full_text column\n",
        "## which is title + text\n",
        "\n",
        "all_comments = all_comments.replace(np.nan, \"\", regex=True)"
      ],
      "metadata": {
        "id": "b40fLZUjalyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_comments[\"full_text\"] = all_comments['title'].str.cat(all_comments['text'], sep=' ')\n",
        "all_comments.head()"
      ],
      "metadata": {
        "id": "V52LAND5Zbkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_comments[\"full_text\"].isna().sum()"
      ],
      "metadata": {
        "id": "KRik_OZ-aKqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is the loop to get the label probabilities for the first five\n",
        "## full_text observations\n",
        "\n",
        "result = []\n",
        "for i in range(5):\n",
        "  sequence_to_classify = all_comments[\"full_text\"][i]\n",
        "  candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "  result.append(classifier(sequence_to_classify, candidate_labels))"
      ],
      "metadata": {
        "id": "29R9MpZpbFTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Looking at what the result looks like for the 3rd observation\n",
        "## Indexing in python starts at 0, so result[2] is the third entry\n",
        "\n",
        "result[2]"
      ],
      "metadata": {
        "id": "Jkq-9TebbvN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking if all the label probabilities are equal to 1\n",
        "\n",
        "sum(result[2][\"scores\"])"
      ],
      "metadata": {
        "id": "DkQA4wbmwKRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Running for all of the full_text observations (takes for ever)\n",
        "\n",
        "full_result = []\n",
        "for i in range(len(all_comments)):\n",
        "  print(\"-\"*100)\n",
        "  sequence_to_classify = all_comments[\"full_text\"][i]\n",
        "  candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "  full_result.append(classifier(sequence_to_classify, candidate_labels))\n",
        "  if i in range(0,367,10):\n",
        "    print(f\"Fetching data for {i}\")"
      ],
      "metadata": {
        "id": "3aQpEmDBwx4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_result"
      ],
      "metadata": {
        "id": "pwwfvAs0_t_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a dataframe from full_results\n",
        "## Here I want one column where sequence = full_text\n",
        "## And then there are 8 more columns for each of the label probabilities\n",
        "\n",
        "df = pd.DataFrame([{\n",
        "    'sequence': trial['sequence'],\n",
        "    **{label: score for label, score in zip(trial['labels'], trial['scores'])}\n",
        "} for trial in full_result])"
      ],
      "metadata": {
        "id": "h7USh6Zs_yt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## So my loop above broke because my computer went to sleep oopsss\n",
        "## at observation 339 out of 367 so I had to run the loop again from 340\n",
        "## to 367\n",
        "\n",
        "## Here with df.tail() I am checking where the loop stopped\n",
        "\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "6PwsNowM_1-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## I am saving the df up to entry 399 just for security, if the\n",
        "## loop breaks again\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/DeepLearning/data/df_339.csv\")"
      ],
      "metadata": {
        "id": "7uF7DESE_97A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Here I'm running again for the observations 340 to 367\n",
        "\n",
        "last_result = []\n",
        "for i in range(340, len(all_comments)+1):\n",
        "  print(\"-\"*100)\n",
        "  sequence_to_classify = all_comments[\"full_text\"][i]\n",
        "  candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "  last_result.append(classifier(sequence_to_classify, candidate_labels))\n",
        "  if i in range(340,368,10):\n",
        "    print(f\"Fetching data for {i}\")"
      ],
      "metadata": {
        "id": "ZaT6nMrE_5gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking that last_result (observations 340 to 367) and full_result\n",
        "## (observations 0 to 399) are equal to 367, that I have managed to run for\n",
        "## all of them\n",
        "\n",
        "len(last_result) + len(full_result)"
      ],
      "metadata": {
        "id": "bq6UuMbCIdDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating the df for observations 340 to 367 and saving it as a csv\n",
        "## Remember to change the path if you want to save csv\n",
        "\n",
        "df_399_367 = pd.DataFrame([{\n",
        "    'sequence': trial['sequence'],\n",
        "    **{label: score for label, score in zip(trial['labels'], trial['scores'])}\n",
        "        } for trial in last_result])\n",
        "df_399_367.to_csv(\"/content/drive/MyDrive/DeepLearning/data/df_339_367.csv\")"
      ],
      "metadata": {
        "id": "gnbhOrQtIn8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Concatenating the 2 dfs\n",
        "\n",
        "full_df = pd.concat([df, df_399_367])"
      ],
      "metadata": {
        "id": "sg2-3dCiI0eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(full_df)"
      ],
      "metadata": {
        "id": "fsiuwfIfJRHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Saving the full df\n",
        "\n",
        "full_df.to_csv(\"/content/drive/MyDrive/DeepLearning/data/classification_all_posts.csv\")"
      ],
      "metadata": {
        "id": "562QMgduJtGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_comments.head()"
      ],
      "metadata": {
        "id": "VRpd6LA5KPoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trying to run on the \"full_comment\" column but it never finished\n",
        "\n",
        "comment_result = []\n",
        "for i in range(len(all_comments)):\n",
        "  print(\"-\"*100)\n",
        "  sequence_to_classify = all_comments[\"full_comment\"][i]\n",
        "  if sequence_to_classify != \"\":\n",
        "    candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "    comment_result.append(classifier(sequence_to_classify, candidate_labels))\n",
        "  if i in range(0,367,10):\n",
        "    print(f\"Fetching data for {i}\")"
      ],
      "metadata": {
        "id": "kJgirjpeKCSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is how you would save the comment label probabilities\n",
        "\n",
        "comment_result = pd.DataFrame([{\n",
        "    'sequence': trial['sequence'],\n",
        "    **{label: score for label, score in zip(trial['labels'], trial['scores'])}\n",
        "        } for trial in last_result])\n",
        "comment_result.to_csv(\"/content/drive/MyDrive/DeepLearning/data/comment_result.csv\")"
      ],
      "metadata": {
        "id": "2HoMirUsM7JA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}