{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab4ea72a08ff418dbd6e8cbfb4c81d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c919a76918f4270a9e04e31b2ac7b45",
              "IPY_MODEL_7a2d6648fe8c422f9c4a27efebe0f286",
              "IPY_MODEL_e4f6946a8a7a4d11bab8a931df7a66d3"
            ],
            "layout": "IPY_MODEL_ab4ff71e2af7432589408773cdb43353"
          }
        },
        "4c919a76918f4270a9e04e31b2ac7b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91cbf84517ce40f8abef3a4ef9ae55d2",
            "placeholder": "​",
            "style": "IPY_MODEL_0e6590df2e104d4492494837acaee29f",
            "value": "Downloading (…)lve/main/config.json: "
          }
        },
        "7a2d6648fe8c422f9c4a27efebe0f286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc64e1c6013942d8ab02b063e271c519",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38ac069fec234c99bae0b818fdb7cb73",
            "value": 1
          }
        },
        "e4f6946a8a7a4d11bab8a931df7a66d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28254b5e1f944bd3b3f21c04a2601a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_604fba34d0cf48228505fe8ab920508a",
            "value": " 1.15k/? [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "ab4ff71e2af7432589408773cdb43353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91cbf84517ce40f8abef3a4ef9ae55d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6590df2e104d4492494837acaee29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc64e1c6013942d8ab02b063e271c519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "38ac069fec234c99bae0b818fdb7cb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28254b5e1f944bd3b3f21c04a2601a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604fba34d0cf48228505fe8ab920508a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b857ef600c40feb9bf5784759ebb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e976d3096c6d4da08900b6c0e9ad7757",
              "IPY_MODEL_92b0bf932b7246bfb1c063479aebcd4a",
              "IPY_MODEL_91934afda6f74b91abb5648cab320561"
            ],
            "layout": "IPY_MODEL_a85cc61e43214b7eb7569bf00e181666"
          }
        },
        "e976d3096c6d4da08900b6c0e9ad7757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d6bc59bf004eae842a304b2316f5a8",
            "placeholder": "​",
            "style": "IPY_MODEL_89d4bff888ce4325a9ecee3d6d7db688",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "92b0bf932b7246bfb1c063479aebcd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc382b090794cbbb854ca1b5caf94c8",
            "max": 1629437147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed6b069c4b944f79b8c80cf631dc0833",
            "value": 1629437147
          }
        },
        "91934afda6f74b91abb5648cab320561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b33a497c9b243d8b482620e34a13fc5",
            "placeholder": "​",
            "style": "IPY_MODEL_edc68265bb0b41d1bbbd0af1a370d7d9",
            "value": " 1.63G/1.63G [00:06&lt;00:00, 255MB/s]"
          }
        },
        "a85cc61e43214b7eb7569bf00e181666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d6bc59bf004eae842a304b2316f5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d4bff888ce4325a9ecee3d6d7db688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bc382b090794cbbb854ca1b5caf94c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed6b069c4b944f79b8c80cf631dc0833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b33a497c9b243d8b482620e34a13fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc68265bb0b41d1bbbd0af1a370d7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f054aaa34d0147c0897536eceb8ce00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44418304b3e7434282f129150e9da138",
              "IPY_MODEL_5571630da66f4b668bd013de6477f9cc",
              "IPY_MODEL_c087d75c3aa54439b004ef6b91706c7b"
            ],
            "layout": "IPY_MODEL_9dd2ebc308634e1ea4e93121a7dcddc5"
          }
        },
        "44418304b3e7434282f129150e9da138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a8e9d291554eaa822193776416d67a",
            "placeholder": "​",
            "style": "IPY_MODEL_8860f67de0b74fe7a4c94c787877ca34",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "5571630da66f4b668bd013de6477f9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cc9e86b597492dbb82ca3d5a855d31",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4129392e7f4d48189adf4e2ea0d99e27",
            "value": 26
          }
        },
        "c087d75c3aa54439b004ef6b91706c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8820d0a5fae040b8a228cb2fbe407d43",
            "placeholder": "​",
            "style": "IPY_MODEL_1203ae1122544474b49ca19b2baa5dd2",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.62kB/s]"
          }
        },
        "9dd2ebc308634e1ea4e93121a7dcddc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a8e9d291554eaa822193776416d67a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8860f67de0b74fe7a4c94c787877ca34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11cc9e86b597492dbb82ca3d5a855d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4129392e7f4d48189adf4e2ea0d99e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8820d0a5fae040b8a228cb2fbe407d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1203ae1122544474b49ca19b2baa5dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6df8a905398d4459995ccde4b4cea791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f786371976149b199fda300568b3be9",
              "IPY_MODEL_6da79a30510c4dbebb1d64bd4c2a7701",
              "IPY_MODEL_d01a17b6565c47dba270f08a6f43877e"
            ],
            "layout": "IPY_MODEL_b808be90db504a598074b6d5b12b8d0b"
          }
        },
        "5f786371976149b199fda300568b3be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51b8bdf6b38e425aace18a94aab82359",
            "placeholder": "​",
            "style": "IPY_MODEL_be31dbc6e67d44589111f8e4afb7f472",
            "value": "Downloading (…)olve/main/vocab.json: "
          }
        },
        "6da79a30510c4dbebb1d64bd4c2a7701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d2101f91794e9d9805a155149586e7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f87943da58cd45cf87f1f55b9e45a353",
            "value": 1
          }
        },
        "d01a17b6565c47dba270f08a6f43877e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06b6b9fd44e4b908137f3375e6549e5",
            "placeholder": "​",
            "style": "IPY_MODEL_03f8fe596eca442cbbc3365865ac1bf8",
            "value": " 899k/? [00:00&lt;00:00, 16.6MB/s]"
          }
        },
        "b808be90db504a598074b6d5b12b8d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b8bdf6b38e425aace18a94aab82359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be31dbc6e67d44589111f8e4afb7f472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97d2101f91794e9d9805a155149586e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f87943da58cd45cf87f1f55b9e45a353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f06b6b9fd44e4b908137f3375e6549e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f8fe596eca442cbbc3365865ac1bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11a60aeda404515ba5ccc1c7496d624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4031b57b70cf47e1b421aa37a59e4139",
              "IPY_MODEL_f6e30e54d4cf4eedb22564be470f5e7f",
              "IPY_MODEL_5387893d58484fafb59bd7bbfb7e0694"
            ],
            "layout": "IPY_MODEL_3d55e0289ac8484db87aa2bdfcb04080"
          }
        },
        "4031b57b70cf47e1b421aa37a59e4139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32200a3b1c194ad991ca7faf0dee1d60",
            "placeholder": "​",
            "style": "IPY_MODEL_c12a16c89d5341f2a74cfd2d30a68567",
            "value": "Downloading (…)olve/main/merges.txt: "
          }
        },
        "f6e30e54d4cf4eedb22564be470f5e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ab2fd553a774efcbec0d3d0e752dd03",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_313c6aa876654915bf973022ac9a544e",
            "value": 1
          }
        },
        "5387893d58484fafb59bd7bbfb7e0694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d264701629b46ebb4a8f1fb7082d848",
            "placeholder": "​",
            "style": "IPY_MODEL_9026bb1633fb4da187af11213038d1c5",
            "value": " 456k/? [00:00&lt;00:00, 9.69MB/s]"
          }
        },
        "3d55e0289ac8484db87aa2bdfcb04080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32200a3b1c194ad991ca7faf0dee1d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12a16c89d5341f2a74cfd2d30a68567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ab2fd553a774efcbec0d3d0e752dd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "313c6aa876654915bf973022ac9a544e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d264701629b46ebb4a8f1fb7082d848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9026bb1633fb4da187af11213038d1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "973e385256d048188b25a4a4847584ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7f1d2d8653342cdbaa68df998a7f012",
              "IPY_MODEL_53550e79f546480c902b7a081d1be02f",
              "IPY_MODEL_86c12fdf110b430680acb39ff4e0e9c6"
            ],
            "layout": "IPY_MODEL_12d27bb3cf614999ac9485cb661f7f94"
          }
        },
        "c7f1d2d8653342cdbaa68df998a7f012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cff76d646f74c2b86c1aa924da431dc",
            "placeholder": "​",
            "style": "IPY_MODEL_99e8740ce15a4a9098dce3d3ae7fbdca",
            "value": "Downloading (…)/main/tokenizer.json: "
          }
        },
        "53550e79f546480c902b7a081d1be02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdef0f78a0a042b48e6f0a024db6d866",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5d754a013664918a80379b516d33822",
            "value": 1
          }
        },
        "86c12fdf110b430680acb39ff4e0e9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3b4be1d05a6407582707236067e35bc",
            "placeholder": "​",
            "style": "IPY_MODEL_c5fb06955f6e433db40f12b452b29827",
            "value": " 1.36M/? [00:00&lt;00:00, 9.49MB/s]"
          }
        },
        "12d27bb3cf614999ac9485cb661f7f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cff76d646f74c2b86c1aa924da431dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99e8740ce15a4a9098dce3d3ae7fbdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdef0f78a0a042b48e6f0a024db6d866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a5d754a013664918a80379b516d33822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3b4be1d05a6407582707236067e35bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5fb06955f6e433db40f12b452b29827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oAPm0qIzWWjp"
      },
      "outputs": [],
      "source": [
        "## Imports which will be necessary for dataframes(pandas) getting rid of NAs\n",
        "## (numpy)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## This is how to connect your Colab notebook to your Google Drive files\n",
        "## I have the\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l27Tkj1AXNa5",
        "outputId": "f388ea17-764f-44ab-f9f1-6831a9f6267e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Reading the CSV all_comments.csv which is the dataframe with has the\n",
        "## following columns: date, title, text, subreddit, num of comments, url,\n",
        "## full_comment (which are all of the comments of the post in one cell)\n",
        "\n",
        "\n",
        "## Remember to change the path to your path\n",
        "all_comments = pd.read_csv(\"/content/drive/MyDrive/DeepLearning/data/all_comments.csv\", encoding='utf-8')"
      ],
      "metadata": {
        "id": "tJKY8G4kK_u4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Having a look at the dataframe\n",
        "\n",
        "all_comments.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Z8Xfi3bZLNKo",
        "outputId": "ae266c1c-2cfc-49ad-e7d0-a38161a89c3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    date_utc   timestamp  \\\n",
              "0           1  2017-02-05  1486282489   \n",
              "1           2  2017-01-30  1485807604   \n",
              "2           3  2017-01-29  1485699303   \n",
              "3           4  2017-01-29  1485659801   \n",
              "4           5  2017-01-28  1485598742   \n",
              "\n",
              "                                               title text subreddit  comments  \\\n",
              "0  Monkeys Accidentally Kill a Robot Monkey and G...  NaN  AIethics         1   \n",
              "1  AI Principles Open Letter and signatories - Fu...  NaN  AIethics         1   \n",
              "2  Ethical Considerations in Artificial Intellige...  NaN  AIethics        10   \n",
              "3  Reinforcement Learning as a Framework for Ethi...  NaN  AIethics         1   \n",
              "4  Virginia Dignum: Ethics of Artificial Intellig...  NaN  AIethics         0   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.reddit.com/r/AIethics/comments/5s6...   \n",
              "1  https://www.reddit.com/r/AIethics/comments/5r3...   \n",
              "2  https://www.reddit.com/r/AIethics/comments/5qt...   \n",
              "3  https://www.reddit.com/r/AIethics/comments/5qr...   \n",
              "4  https://www.reddit.com/r/AIethics/comments/5qm...   \n",
              "\n",
              "                                        full_comment  \n",
              "0  the question is will the robot monkey feel the...  \n",
              "1  As I read this I was reminded of a quote by Le...  \n",
              "2  Thanks for this!\\r\\n\\r\\nI don't agree with the...  \n",
              "3  Is this a joke? AAAI 2016 seems to be of such ...  \n",
              "4                                                NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46d3183a-5f69-4285-aa60-aa3c8b4393b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date_utc</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comments</th>\n",
              "      <th>url</th>\n",
              "      <th>full_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-02-05</td>\n",
              "      <td>1486282489</td>\n",
              "      <td>Monkeys Accidentally Kill a Robot Monkey and G...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5s6...</td>\n",
              "      <td>the question is will the robot monkey feel the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-01-30</td>\n",
              "      <td>1485807604</td>\n",
              "      <td>AI Principles Open Letter and signatories - Fu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5r3...</td>\n",
              "      <td>As I read this I was reminded of a quote by Le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2017-01-29</td>\n",
              "      <td>1485699303</td>\n",
              "      <td>Ethical Considerations in Artificial Intellige...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AIethics</td>\n",
              "      <td>10</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qt...</td>\n",
              "      <td>Thanks for this!\\r\\n\\r\\nI don't agree with the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2017-01-29</td>\n",
              "      <td>1485659801</td>\n",
              "      <td>Reinforcement Learning as a Framework for Ethi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qr...</td>\n",
              "      <td>Is this a joke? AAAI 2016 seems to be of such ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2017-01-28</td>\n",
              "      <td>1485598742</td>\n",
              "      <td>Virginia Dignum: Ethics of Artificial Intellig...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AIethics</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qm...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46d3183a-5f69-4285-aa60-aa3c8b4393b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46d3183a-5f69-4285-aa60-aa3c8b4393b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46d3183a-5f69-4285-aa60-aa3c8b4393b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation for `pip install transformers`\n",
        "https://pypi.org/project/transformers/\n",
        "We put the `!` in front so we can write command line commands into the notebook"
      ],
      "metadata": {
        "id": "wENiJbkcLu_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## This is the command to install hugging face transformers intot the\n",
        "## notebook, even if you have the package in your python environment\n",
        "## you need to download it again for this notebook\n",
        "\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "wYpt_I79WlcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fead3a8-67ee-4f90-8172-d4296bb9fd5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing the pipeline for the model which we want to use\n",
        "## see more instructions here\n",
        "## https://huggingface.co/facebook/bart-large-mnli\n",
        "\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "ab4ea72a08ff418dbd6e8cbfb4c81d74",
            "4c919a76918f4270a9e04e31b2ac7b45",
            "7a2d6648fe8c422f9c4a27efebe0f286",
            "e4f6946a8a7a4d11bab8a931df7a66d3",
            "ab4ff71e2af7432589408773cdb43353",
            "91cbf84517ce40f8abef3a4ef9ae55d2",
            "0e6590df2e104d4492494837acaee29f",
            "cc64e1c6013942d8ab02b063e271c519",
            "38ac069fec234c99bae0b818fdb7cb73",
            "28254b5e1f944bd3b3f21c04a2601a0e",
            "604fba34d0cf48228505fe8ab920508a",
            "f8b857ef600c40feb9bf5784759ebb74",
            "e976d3096c6d4da08900b6c0e9ad7757",
            "92b0bf932b7246bfb1c063479aebcd4a",
            "91934afda6f74b91abb5648cab320561",
            "a85cc61e43214b7eb7569bf00e181666",
            "95d6bc59bf004eae842a304b2316f5a8",
            "89d4bff888ce4325a9ecee3d6d7db688",
            "4bc382b090794cbbb854ca1b5caf94c8",
            "ed6b069c4b944f79b8c80cf631dc0833",
            "0b33a497c9b243d8b482620e34a13fc5",
            "edc68265bb0b41d1bbbd0af1a370d7d9",
            "f054aaa34d0147c0897536eceb8ce00f",
            "44418304b3e7434282f129150e9da138",
            "5571630da66f4b668bd013de6477f9cc",
            "c087d75c3aa54439b004ef6b91706c7b",
            "9dd2ebc308634e1ea4e93121a7dcddc5",
            "80a8e9d291554eaa822193776416d67a",
            "8860f67de0b74fe7a4c94c787877ca34",
            "11cc9e86b597492dbb82ca3d5a855d31",
            "4129392e7f4d48189adf4e2ea0d99e27",
            "8820d0a5fae040b8a228cb2fbe407d43",
            "1203ae1122544474b49ca19b2baa5dd2",
            "6df8a905398d4459995ccde4b4cea791",
            "5f786371976149b199fda300568b3be9",
            "6da79a30510c4dbebb1d64bd4c2a7701",
            "d01a17b6565c47dba270f08a6f43877e",
            "b808be90db504a598074b6d5b12b8d0b",
            "51b8bdf6b38e425aace18a94aab82359",
            "be31dbc6e67d44589111f8e4afb7f472",
            "97d2101f91794e9d9805a155149586e7",
            "f87943da58cd45cf87f1f55b9e45a353",
            "f06b6b9fd44e4b908137f3375e6549e5",
            "03f8fe596eca442cbbc3365865ac1bf8",
            "e11a60aeda404515ba5ccc1c7496d624",
            "4031b57b70cf47e1b421aa37a59e4139",
            "f6e30e54d4cf4eedb22564be470f5e7f",
            "5387893d58484fafb59bd7bbfb7e0694",
            "3d55e0289ac8484db87aa2bdfcb04080",
            "32200a3b1c194ad991ca7faf0dee1d60",
            "c12a16c89d5341f2a74cfd2d30a68567",
            "7ab2fd553a774efcbec0d3d0e752dd03",
            "313c6aa876654915bf973022ac9a544e",
            "6d264701629b46ebb4a8f1fb7082d848",
            "9026bb1633fb4da187af11213038d1c5",
            "973e385256d048188b25a4a4847584ca",
            "c7f1d2d8653342cdbaa68df998a7f012",
            "53550e79f546480c902b7a081d1be02f",
            "86c12fdf110b430680acb39ff4e0e9c6",
            "12d27bb3cf614999ac9485cb661f7f94",
            "1cff76d646f74c2b86c1aa924da431dc",
            "99e8740ce15a4a9098dce3d3ae7fbdca",
            "fdef0f78a0a042b48e6f0a024db6d866",
            "a5d754a013664918a80379b516d33822",
            "a3b4be1d05a6407582707236067e35bc",
            "c5fb06955f6e433db40f12b452b29827"
          ]
        },
        "id": "-uBSjxGGWfFd",
        "outputId": "62989598-b9e5-45ee-b7e7-d778bb46c336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab4ea72a08ff418dbd6e8cbfb4c81d74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8b857ef600c40feb9bf5784759ebb74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f054aaa34d0147c0897536eceb8ce00f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6df8a905398d4459995ccde4b4cea791"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e11a60aeda404515ba5ccc1c7496d624"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "973e385256d048188b25a4a4847584ca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Replacing np.nan with \"\" so that I can create the full_text column\n",
        "## which is title + text\n",
        "\n",
        "all_comments = all_comments.replace(np.nan, \"\", regex=True)"
      ],
      "metadata": {
        "id": "b40fLZUjalyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_comments[\"full_text\"] = all_comments['title'].str.cat(all_comments['text'], sep=' ')\n",
        "all_comments.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "V52LAND5Zbkt",
        "outputId": "0d193171-44ff-4b63-cd73-7ee3f722daf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    date_utc   timestamp  \\\n",
              "0           1  2017-02-05  1486282489   \n",
              "1           2  2017-01-30  1485807604   \n",
              "2           3  2017-01-29  1485699303   \n",
              "3           4  2017-01-29  1485659801   \n",
              "4           5  2017-01-28  1485598742   \n",
              "\n",
              "                                               title text subreddit  comments  \\\n",
              "0  Monkeys Accidentally Kill a Robot Monkey and G...       AIethics         1   \n",
              "1  AI Principles Open Letter and signatories - Fu...       AIethics         1   \n",
              "2  Ethical Considerations in Artificial Intellige...       AIethics        10   \n",
              "3  Reinforcement Learning as a Framework for Ethi...       AIethics         1   \n",
              "4  Virginia Dignum: Ethics of Artificial Intellig...       AIethics         0   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.reddit.com/r/AIethics/comments/5s6...   \n",
              "1  https://www.reddit.com/r/AIethics/comments/5r3...   \n",
              "2  https://www.reddit.com/r/AIethics/comments/5qt...   \n",
              "3  https://www.reddit.com/r/AIethics/comments/5qr...   \n",
              "4  https://www.reddit.com/r/AIethics/comments/5qm...   \n",
              "\n",
              "                                        full_comment  \\\n",
              "0  the question is will the robot monkey feel the...   \n",
              "1  As I read this I was reminded of a quote by Le...   \n",
              "2  Thanks for this!\\r\\n\\r\\nI don't agree with the...   \n",
              "3  Is this a joke? AAAI 2016 seems to be of such ...   \n",
              "4                                                      \n",
              "\n",
              "                                           full_text  \n",
              "0  Monkeys Accidentally Kill a Robot Monkey and G...  \n",
              "1  AI Principles Open Letter and signatories - Fu...  \n",
              "2  Ethical Considerations in Artificial Intellige...  \n",
              "3  Reinforcement Learning as a Framework for Ethi...  \n",
              "4  Virginia Dignum: Ethics of Artificial Intellig...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9403ab6-04fc-477b-babf-01608640069c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date_utc</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comments</th>\n",
              "      <th>url</th>\n",
              "      <th>full_comment</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-02-05</td>\n",
              "      <td>1486282489</td>\n",
              "      <td>Monkeys Accidentally Kill a Robot Monkey and G...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5s6...</td>\n",
              "      <td>the question is will the robot monkey feel the...</td>\n",
              "      <td>Monkeys Accidentally Kill a Robot Monkey and G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-01-30</td>\n",
              "      <td>1485807604</td>\n",
              "      <td>AI Principles Open Letter and signatories - Fu...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5r3...</td>\n",
              "      <td>As I read this I was reminded of a quote by Le...</td>\n",
              "      <td>AI Principles Open Letter and signatories - Fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2017-01-29</td>\n",
              "      <td>1485699303</td>\n",
              "      <td>Ethical Considerations in Artificial Intellige...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>10</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qt...</td>\n",
              "      <td>Thanks for this!\\r\\n\\r\\nI don't agree with the...</td>\n",
              "      <td>Ethical Considerations in Artificial Intellige...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2017-01-29</td>\n",
              "      <td>1485659801</td>\n",
              "      <td>Reinforcement Learning as a Framework for Ethi...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qr...</td>\n",
              "      <td>Is this a joke? AAAI 2016 seems to be of such ...</td>\n",
              "      <td>Reinforcement Learning as a Framework for Ethi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2017-01-28</td>\n",
              "      <td>1485598742</td>\n",
              "      <td>Virginia Dignum: Ethics of Artificial Intellig...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qm...</td>\n",
              "      <td></td>\n",
              "      <td>Virginia Dignum: Ethics of Artificial Intellig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9403ab6-04fc-477b-babf-01608640069c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9403ab6-04fc-477b-babf-01608640069c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9403ab6-04fc-477b-babf-01608640069c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_comments[\"full_text\"].isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRik_OZ-aKqn",
        "outputId": "7fd2ae6d-6cf6-45dc-d4be-f146854d53c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## This is the loop to get the label probabilities for the first five\n",
        "## full_text observations\n",
        "\n",
        "result = []\n",
        "for i in range(5):\n",
        "  sequence_to_classify = all_comments[\"full_text\"][i]\n",
        "  candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "  result.append(classifier(sequence_to_classify, candidate_labels))"
      ],
      "metadata": {
        "id": "29R9MpZpbFTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Looking at what the result looks like for the 3rd observation\n",
        "## Indexing in python starts at 0, so result[2] is the third entry\n",
        "\n",
        "result[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkq-9TebbvN3",
        "outputId": "39f80918-0778-4af1-c673-fc36024640d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'Ethical Considerations in Artificial Intelligence Courses ',\n",
              " 'labels': ['responsibility',\n",
              "  'fairness',\n",
              "  'accountability',\n",
              "  'justice',\n",
              "  'bias',\n",
              "  'transparency',\n",
              "  'privacy',\n",
              "  'discrimination'],\n",
              " 'scores': [0.36014416813850403,\n",
              "  0.2243707776069641,\n",
              "  0.15797610580921173,\n",
              "  0.07240782678127289,\n",
              "  0.06841004639863968,\n",
              "  0.05435879901051521,\n",
              "  0.03166859224438667,\n",
              "  0.03066375106573105]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking if all the label probabilities are equal to 1\n",
        "\n",
        "sum(result[2][\"scores\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkQA4wbmwKRU",
        "outputId": "8c95b64a-deea-4c7a-f716-192da45406cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000670552254"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Running for all of the full_text observations (takes for ever)\n",
        "\n",
        "full_result = []\n",
        "for i in range(len(all_comments)):\n",
        "  print(\"-\"*100)\n",
        "  sequence_to_classify = all_comments[\"full_text\"][i]\n",
        "  candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "  full_result.append(classifier(sequence_to_classify, candidate_labels))\n",
        "  if i in range(0,367,10):\n",
        "    print(f\"Fetching data for {i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3aQpEmDBwx4L",
        "outputId": "38633817-1571-45b3-fcd4-41a6f30ff26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 30\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 40\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 50\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 60\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 70\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 80\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 90\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 100\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 110\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 120\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 130\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 140\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 150\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 160\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 170\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 180\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 190\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 200\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 210\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 220\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 230\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 240\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 250\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 260\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 270\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 280\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 290\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 300\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 310\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 320\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 330\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-379cc139f9f4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msequence_to_classify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_comments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcandidate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"justice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fairness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"responsibility\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"privacy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"discrimination\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accountability\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mfull_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_to_classify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m367\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fetching data for {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to understand extra arguments {args}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"This example is {}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChunkPipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m             return next(\n\u001b[0m\u001b[1;32m   1113\u001b[0m                 iter(\n\u001b[1;32m   1114\u001b[0m                     self.get_iterator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         model_outputs = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             )\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1244\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    857\u001b[0m                     )\n\u001b[1;32m    858\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                     layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m    860\u001b[0m                         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[1;32m    332\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         hidden_states, attn_weights, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0msrc_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwwfvAs0_t_O",
        "outputId": "864eac58-ba81-4a92-b50d-7c9c1e9ddf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'sequence': 'Monkeys Accidentally Kill a Robot Monkey and Grieve Over It ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.3935248851776123,\n",
              "   0.20105570554733276,\n",
              "   0.14259856939315796,\n",
              "   0.09610199928283691,\n",
              "   0.07333596050739288,\n",
              "   0.033245399594306946,\n",
              "   0.030229205265641212,\n",
              "   0.0299081988632679]},\n",
              " {'sequence': 'AI Principles Open Letter and signatories - Future of Life Institute ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.34983110427856445,\n",
              "   0.2659469246864319,\n",
              "   0.13687379658222198,\n",
              "   0.06659146398305893,\n",
              "   0.058772098273038864,\n",
              "   0.054973430931568146,\n",
              "   0.043126851320266724,\n",
              "   0.023884255439043045]},\n",
              " {'sequence': 'Ethical Considerations in Artificial Intelligence Courses ',\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.36014416813850403,\n",
              "   0.2243707776069641,\n",
              "   0.15797610580921173,\n",
              "   0.07240782678127289,\n",
              "   0.06841004639863968,\n",
              "   0.05435879901051521,\n",
              "   0.03166859224438667,\n",
              "   0.03066375106573105]},\n",
              " {'sequence': 'Reinforcement Learning as a Framework for Ethical Decision Making ',\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.22696448862552643,\n",
              "   0.22207078337669373,\n",
              "   0.14276082813739777,\n",
              "   0.13142943382263184,\n",
              "   0.10240752249956131,\n",
              "   0.08238395303487778,\n",
              "   0.0548725426197052,\n",
              "   0.03711044415831566]},\n",
              " {'sequence': 'Virginia Dignum: Ethics of Artificial Intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4453760087490082,\n",
              "   0.1612669676542282,\n",
              "   0.08814116567373276,\n",
              "   0.08081880956888199,\n",
              "   0.0742143765091896,\n",
              "   0.06989465653896332,\n",
              "   0.05062279477715492,\n",
              "   0.02966524474322796]},\n",
              " {'sequence': 'Apple is now in the AI Ethics and Safety partnership ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3262813687324524,\n",
              "   0.32016557455062866,\n",
              "   0.11277952045202255,\n",
              "   0.09391065686941147,\n",
              "   0.06931926310062408,\n",
              "   0.04090746492147446,\n",
              "   0.026193343102931976,\n",
              "   0.010442829690873623]},\n",
              " {'sequence': 'Ethical Autonomous Algorithms - various thoughts, and a research project ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2284587323665619,\n",
              "   0.13324077427387238,\n",
              "   0.13127022981643677,\n",
              "   0.1293898969888687,\n",
              "   0.1209138035774231,\n",
              "   0.11686934530735016,\n",
              "   0.07989334315061569,\n",
              "   0.05996392294764519]},\n",
              " {'sequence': 'Sentience in machines (Jan. 2017) - Manu Herrán\\'s notes of the talk \"Outlook and future Risks of artificial consciousness\" he gave with Brian Tomasik on Dec. 15, 2016 ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.24043868482112885,\n",
              "   0.18119557201862335,\n",
              "   0.17764069139957428,\n",
              "   0.0997438132762909,\n",
              "   0.09064873307943344,\n",
              "   0.08752620220184326,\n",
              "   0.06725872308015823,\n",
              "   0.05554759129881859]},\n",
              " {'sequence': 'AI can predict death in heart disorder patients - if this is Gattaca I shotgun making out with Ethan Hawke ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.27373042702674866,\n",
              "   0.2142288088798523,\n",
              "   0.16635510325431824,\n",
              "   0.11330357939004898,\n",
              "   0.09854724258184433,\n",
              "   0.0529959611594677,\n",
              "   0.04910440742969513,\n",
              "   0.031734395772218704]},\n",
              " {'sequence': 'Stoic Ethics for Artificial Agents ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'transparency'],\n",
              "  'scores': [0.3939189612865448,\n",
              "   0.16490276157855988,\n",
              "   0.13197533786296844,\n",
              "   0.092598095536232,\n",
              "   0.08033989369869232,\n",
              "   0.0665639266371727,\n",
              "   0.040191542357206345,\n",
              "   0.029509492218494415]},\n",
              " {'sequence': 'SIGNAL: As Artificial Intelligence Evolves, So Do Ethical Concerns ',\n",
              "  'labels': ['accountability',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.40363237261772156,\n",
              "   0.29243239760398865,\n",
              "   0.1818920373916626,\n",
              "   0.036555156111717224,\n",
              "   0.03298676013946533,\n",
              "   0.02617609314620495,\n",
              "   0.014314536936581135,\n",
              "   0.012010586448013783]},\n",
              " {'sequence': 'Science AMA Series: I\\'m Joanna Bryson, a Professor in Artificial (and Natural) Intelligence. I am being consulted by several governments on AI ethics, particularly on the obligations of AI developers towards AI and society. I\\'d love to talk \\x13 AMA! \" /r/science ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.46744561195373535,\n",
              "   0.18311718106269836,\n",
              "   0.10415720194578171,\n",
              "   0.07133468985557556,\n",
              "   0.06378919631242752,\n",
              "   0.047401946038007736,\n",
              "   0.03339702636003494,\n",
              "   0.029357098042964935]},\n",
              " {'sequence': \"Give robots 'personhood' status, EU committee argues \",\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.22936676442623138,\n",
              "   0.21427021920681,\n",
              "   0.19157379865646362,\n",
              "   0.1178777664899826,\n",
              "   0.09046979248523712,\n",
              "   0.08822323381900787,\n",
              "   0.04445069283246994,\n",
              "   0.023767780512571335]},\n",
              " {'sequence': 'Establishing a legal code for robots. ',\n",
              "  'labels': ['responsibility',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.32297641038894653,\n",
              "   0.22506654262542725,\n",
              "   0.16630542278289795,\n",
              "   0.08755067735910416,\n",
              "   0.07325121015310287,\n",
              "   0.05724643915891647,\n",
              "   0.036446135491132736,\n",
              "   0.031157182529568672]},\n",
              " {'sequence': 'Misattributing Sentience ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.7571925520896912,\n",
              "   0.11130750924348831,\n",
              "   0.05915733799338341,\n",
              "   0.02179969660937786,\n",
              "   0.02070443332195282,\n",
              "   0.011533170007169247,\n",
              "   0.01037769764661789,\n",
              "   0.007927515543997288]},\n",
              " {'sequence': 'Today\\x19s Artificial Intelligence Does Not Justify Basic Income ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.3322453200817108,\n",
              "   0.17335982620716095,\n",
              "   0.11853824555873871,\n",
              "   0.10828918218612671,\n",
              "   0.09418545663356781,\n",
              "   0.07533375918865204,\n",
              "   0.06132623553276062,\n",
              "   0.03672200068831444]},\n",
              " {'sequence': 'Human Level Artificial Intelligence || Kurzweil Interviews Minsky ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3014219403266907,\n",
              "   0.21981048583984375,\n",
              "   0.1733144223690033,\n",
              "   0.08626947551965714,\n",
              "   0.065803661942482,\n",
              "   0.05493222177028656,\n",
              "   0.050535451620817184,\n",
              "   0.04791230708360672]},\n",
              " {'sequence': 'Robin Hanson and James Hughes discussing AI economics, rights and more ',\n",
              "  'labels': ['responsibility',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2228919267654419,\n",
              "   0.177662193775177,\n",
              "   0.13773424923419952,\n",
              "   0.12264803051948547,\n",
              "   0.12062999606132507,\n",
              "   0.1172080785036087,\n",
              "   0.060941431671381,\n",
              "   0.04028411582112312]},\n",
              " {'sequence': 'Ethics of Artificial Intelligence Discussed by 2 Psychologists, 2 Computer Scientists &amp; 1 Philospher ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.41944435238838196,\n",
              "   0.18864180147647858,\n",
              "   0.09569235146045685,\n",
              "   0.08031070232391357,\n",
              "   0.07648582011461258,\n",
              "   0.06131335720419884,\n",
              "   0.04808086156845093,\n",
              "   0.03003077022731304]},\n",
              " {'sequence': 'New user flairs We\\'re implementing user flairs for people with experience studying or working in the fields of computer science and philosophy. \\r\\n\\r\\nFlairs are marked blue for philosophy and red for computer science, and shaded according to one\\'s background. The text of the flair will describe your specialty - \"machine learning\" or \"political philosophy\" for instance.\\r\\n\\r\\n* Professional (dark flair): the user derives the bulk of their income through computer science or philosophy work, either as an instructor of some sort, a working professional (e.g. applied ethicist or data scientist), or through the publication of papers in reputable journals;\\r\\n\\r\\n* Graduate (medium flair): the user is enrolled in, or has completed, a graduate program in philosophy or computer science or a closely related field;\\r\\n\\r\\n* Undergrad (light flair): the user is enrolled in, or has completed, an undergraduate program in philosophy or computer science;\\r\\n\\r\\nThere are no special rights or privileges for users with flair. \\r\\n\\r\\nIf you would like a flair, state your area of specialty in the comments, or message the mods.',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'justice'],\n",
              "  'scores': [0.2110065072774887,\n",
              "   0.14708134531974792,\n",
              "   0.14514359831809998,\n",
              "   0.13543546199798584,\n",
              "   0.12116459757089615,\n",
              "   0.08910499513149261,\n",
              "   0.08883524686098099,\n",
              "   0.06222826614975929]},\n",
              " {'sequence': \"What's The Current State Of Artificial Intelligence | Davos 2016 \",\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3103361129760742,\n",
              "   0.22799724340438843,\n",
              "   0.1356327086687088,\n",
              "   0.09848061203956604,\n",
              "   0.07229049503803253,\n",
              "   0.0677347481250763,\n",
              "   0.04395946115255356,\n",
              "   0.043568599969148636]},\n",
              " {'sequence': 'President Obama signs legislation banning automated ticket scalping software ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.34773704409599304,\n",
              "   0.21427886188030243,\n",
              "   0.11785280704498291,\n",
              "   0.1063162162899971,\n",
              "   0.07472417503595352,\n",
              "   0.06756775081157684,\n",
              "   0.041796471923589706,\n",
              "   0.029726624488830566]},\n",
              " {'sequence': 'Steve Petersen - Designing People ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3560325503349304,\n",
              "   0.13576003909111023,\n",
              "   0.11188693344593048,\n",
              "   0.10474582016468048,\n",
              "   0.10371632128953934,\n",
              "   0.07363329082727432,\n",
              "   0.06992953270673752,\n",
              "   0.04429544508457184]},\n",
              " {'sequence': 'The IEEE has released the 1st draft of their AI ethics paper: \"Ethically Aligned Design\" ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.30002373456954956,\n",
              "   0.2309337556362152,\n",
              "   0.18460355699062347,\n",
              "   0.07900422811508179,\n",
              "   0.06948217004537582,\n",
              "   0.06447718292474747,\n",
              "   0.038257092237472534,\n",
              "   0.03321831300854683]},\n",
              " {'sequence': \"UK's only rectal teaching assistant loses job to automation \",\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.250398188829422,\n",
              "   0.24336043000221252,\n",
              "   0.15716657042503357,\n",
              "   0.09818246215581894,\n",
              "   0.08553233742713928,\n",
              "   0.05885598808526993,\n",
              "   0.05681861937046051,\n",
              "   0.04968539625406265]},\n",
              " {'sequence': 'Sub-Ethics for Machines (X-post from r/philosophy) ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.2921571433544159,\n",
              "   0.2111918032169342,\n",
              "   0.14887259900569916,\n",
              "   0.13168394565582275,\n",
              "   0.05765924230217934,\n",
              "   0.0548953078687191,\n",
              "   0.0533614456653595,\n",
              "   0.050178587436676025]},\n",
              " {'sequence': \"Silicon Valley 'Bubble' Reflects On Role In Trump Era \",\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.45777010917663574,\n",
              "   0.16969068348407745,\n",
              "   0.16283755004405975,\n",
              "   0.08348225802183151,\n",
              "   0.043150804936885834,\n",
              "   0.030712619423866272,\n",
              "   0.0267037246376276,\n",
              "   0.025652337819337845]},\n",
              " {'sequence': 'Using artificial intelligence to remove prejudices in the hiring place ',\n",
              "  'labels': ['bias',\n",
              "   'fairness',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.28009629249572754,\n",
              "   0.23378248512744904,\n",
              "   0.16622216999530792,\n",
              "   0.07802487909793854,\n",
              "   0.0772337093949318,\n",
              "   0.07369387894868851,\n",
              "   0.06764986366033554,\n",
              "   0.023296764120459557]},\n",
              " {'sequence': '(NSFW) Campaign Against Sex Robots warns of danger to women and children ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.25470787286758423,\n",
              "   0.2030554711818695,\n",
              "   0.14929121732711792,\n",
              "   0.14443886280059814,\n",
              "   0.13444368541240692,\n",
              "   0.04574715346097946,\n",
              "   0.04362260550260544,\n",
              "   0.02469315566122532]},\n",
              " {'sequence': \"Cathy O'Neil on Weapons of Math Destruction \",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.39422115683555603,\n",
              "   0.31026485562324524,\n",
              "   0.09368832409381866,\n",
              "   0.06251820921897888,\n",
              "   0.05118633434176445,\n",
              "   0.03036617673933506,\n",
              "   0.02972407639026642,\n",
              "   0.028030788525938988]},\n",
              " {'sequence': 'On How Not to Build a Moral Machine ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3738284409046173,\n",
              "   0.20487695932388306,\n",
              "   0.10691290348768234,\n",
              "   0.08090786635875702,\n",
              "   0.0698099434375763,\n",
              "   0.0581398606300354,\n",
              "   0.05398818850517273,\n",
              "   0.05153582617640495]},\n",
              " {'sequence': \"To prevent people's jobs, tech giants unite to regulate research in #ArtificialIntelligence \",\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.2820075452327728,\n",
              "   0.22177399694919586,\n",
              "   0.2108195424079895,\n",
              "   0.13177314400672913,\n",
              "   0.0652351900935173,\n",
              "   0.041822608560323715,\n",
              "   0.02527805045247078,\n",
              "   0.02128993161022663]},\n",
              " {'sequence': 'CMU Launches Research Center to Explore Ethics of Artificial Intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4085444509983063,\n",
              "   0.18737877905368805,\n",
              "   0.11894971877336502,\n",
              "   0.07737723737955093,\n",
              "   0.07057128101587296,\n",
              "   0.0702441930770874,\n",
              "   0.03487445041537285,\n",
              "   0.032059911638498306]},\n",
              " {'sequence': 'Scientists Create AI Program That Can Predict Human Rights Trials With 79 Percent Accuracy ',\n",
              "  'labels': ['fairness',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3018861711025238,\n",
              "   0.25904473662376404,\n",
              "   0.19560939073562622,\n",
              "   0.13508832454681396,\n",
              "   0.04986301437020302,\n",
              "   0.027563227340579033,\n",
              "   0.0231410451233387,\n",
              "   0.0078041329979896545]},\n",
              " {'sequence': '\"You\\'re killing people\": Elon Musk attacks critics of self-driving cars ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.2993570864200592,\n",
              "   0.2264384925365448,\n",
              "   0.14484946429729462,\n",
              "   0.11391397565603256,\n",
              "   0.11219175904989243,\n",
              "   0.046636320650577545,\n",
              "   0.039177507162094116,\n",
              "   0.01743537187576294]},\n",
              " {'sequence': 'Zeynep Tufekci: Machine intelligence makes human morals more important | TED Talk ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'discrimination'],\n",
              "  'scores': [0.32837533950805664,\n",
              "   0.18384289741516113,\n",
              "   0.11955425888299942,\n",
              "   0.11071882396936417,\n",
              "   0.07750110328197479,\n",
              "   0.07349629700183868,\n",
              "   0.06877835839986801,\n",
              "   0.03773299604654312]},\n",
              " {'sequence': 'Beyond humans, what other kinds of minds might be out there? \\x13 Murray Shanahan | Aeon Essays ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.2525356113910675,\n",
              "   0.190956249833107,\n",
              "   0.17167629301548004,\n",
              "   0.09142155945301056,\n",
              "   0.0806703045964241,\n",
              "   0.07907447218894958,\n",
              "   0.07411137968301773,\n",
              "   0.05955420807003975]},\n",
              " {'sequence': 'Notes from the NYU AI Ethics conference This weekend I attended the [Ethics of Artificial Intelligence conference](https://wp.nyu.edu/consciousness/ethics-of-artificial-intelligence/) at NYU. There were a ton of high-profile and interesting people there from philosophy (David Chalmers, Peter Railton, Nick Bostrom, Thomas Nagel, Paul Boghossian, Frances Kamm, Wendell Wallach) and science (Yann LeCun, Stuart Russell, Stephen Wolfram, Max Tegmark, Francesca Rossi) as well as Eliezer Yudkowsky. \\r\\n\\r\\nThere were two fairly long days of talks and panels. David Chalmers (famous for his philosophy of mind and consciousness) did not officially speak but acted as chair for the event. He outlined the philosophy of the conference, which was to discuss both short and long term issues in AI ethics without worrying about either detracting from the other. He was, as usual, extremely awesome.\\r\\n\\r\\nHere is a summary of the event with the most interesting points made by the speakers.\\r\\n\\r\\n**Day One**\\r\\n\\r\\nThe first block of talks on Friday was an overview of general issues related to artificial intelligence. Nick Bostrom, author of *Superintelligence* and head of the Future of Humanity Institute, started with something of a barrage of all the general ideas and things he\\'s come up with. He floated the idea that perhaps we shouldn\\'t program AI systems to be maximally moral, for we don\\'t know what the true morality looks like, and what if it turns out that such a directive would lead to humans being punished, or something else that was pathological or downright weird? He also described three principles for how we should treat AIs: substrate nondiscrimination (moral status does not depend on the kind of hardware/wetware you run on), ontogeny nondiscrimination (moral status does not depend on how you were created), and subjective time (moral value exists relative to subjectively experienced time rather than objective time, so if a mind ran at a fast clock speed its life would be more important, all other things being equal).\\r\\n\\r\\nHe pointed out that AI moral status could arise before they reach there is any such thing as human level AI - just like animals have moral status despite being much simpler than humans. He mentioned the possibility of a Malthusian catastrophe from unlimited digital reproduction as well as the possibility for vote manipulation through agent duplication, and how we\\'ll need to prevent these two things.\\r\\n\\r\\nHe voiced support for meta level decisionmaking - a [\\'moral parliament\\'](http://www.overcomingbias.com/2009/01/moral-uncertainty-towards-a-solution.html) where we imagine moral theories sending \\'delegates\\' to compromise over contentious issues. Such a system could also accommodate other values and interests besides moral theories.\\r\\n\\r\\nHe answered the question of \"what is humanity most likely to fail at?\" with a qualified choice of \\'mind crime\\' committed against advanced AIs. Humans already have difficulty with empathy towards animals when they exist on farms or in the wild, but AI would not necessarily have the basic biological features which incline us to be empathetic at all towards animals. Some robots attract empathetic attention from humans, but many invisible automated processes are much harder for people to feel empathetic towards.\\r\\n\\r\\nVirginia Dignum was next; she is at the Delft University of Technology and spoke about mechanisms for automated processes to make decisions. She specified four methods of decisionmaking based on whether decisions are taken deliberately or imposed upon a system and whether the decisions are made internally or externally. The two former features lead to algorithmic decisionmaking in machines; the latter two lead to imposed decisions predetermined by regulatory institutions. Deliberated external decisionmaking means there is a \\'human in the loop\\' and internal imposed decisionmaking is essentially randomness.\\r\\n\\r\\nYann LeCun concluded this section with a pretty fantastic overview of deep learning methods and the limitations which stand in the way of progress in machine intelligence. He pointed out that reinforcement learning is a rare and narrow slice of the field today and that the greatest obstacles for machines include common sense judgements and abstraction. The biggest current problem for AI is unsupervised learning, which is having machines that can learn to classify things on their own without being given clearly labelled data from humans. He showcased some of the (very cool) features of adversarial learning which are being used to tackle this.\\r\\n\\r\\nHe expressed support for the orthogonality thesis, namely the idea that intelligence and morality are \\'orthogonal\\' - just because an agent is very smart doesn\\'t mean that it\\'s necessarily moral. He believes we should build a few basic drives into AIs: do not hurt humans, interact with humans, crave positive feedback from trusted human trainers. He also described a couple of reasons for why he is not concerned about uncontrolled advanced artificial intelligence. One was that he is confident that objective functions can be specified in such a way as to make machines indifferent to being switched off, and the other is that a narrow-AI focused on eliminating an unfriendly general-AI would \\'win\\' due to its specialization.\\r\\n\\r\\nIn Q&amp;A, Stuart Russell objected to LeCun\\'s confidence in machines being indifferent to being shut off based on the fact that self-preservation as a goal implicitly falls out of whatever other goals a machine has. Paul Boghossian objected to the \\'behaviorist\\' nature of the speakers\\' points of view, saying that they were exempting consciousness from its proper role in these discussions. One person asked whether we should let AIs take charge of everything and supersede humanity - Bostrom pointed out that the space of possible futures is \"an enormous Petri dish\" which we don\\'t understand; an AI future could materialize as a planet sized supercomputer with no moral status, and we will need to learn how to engineer friendly advanced AI systems no matter what the plan is. \\r\\n\\r\\nThe rest of the Friday talks were devoted to near-future issues with specific AI systems. Peter Asaro started with an overview of his organization, the \\'Campaign to Stop Killer Robots\\'. He stated that targeting and killing should remain human-controlled actions. While he acknowledged that automated weaponry could result in fewer casualties on the battlefield, he believed that it was too narrow a view of the consequences. He said that it\\'s not straightforward to translate complicated battlefield morality questions for machines to understand, and is worried about unintended initiation and escalation of conflicts through automated systems, arms races, and threats to humanitarian law. He also believes that people should only be killed with \\'dignity\\' and that doing it with a robot robs people of this. Therefore, he called for a clear and strong norm against automated weapons.\\r\\n\\r\\nKate Devlin of the University of London gave a brief overview of the ethics of artificial sexuality. Looking at the history of sexualized robots featured in fictional media, she noted that almost all of them are female. Today there is a \"Campaign Against Sex Robots\" which is based on the idea that sexual robots would lead to the objectification of women. Devlin does not agree as she thinks it is too early to ban the technology and that we should explore it before thinking about banning it, especially since it does not really harm anyone. Instead she wants us to think about how to develop it correctly. There are many potential uses for these types of robots ranging all the way to the therapeutic; many of the rudimentary ones being sold today are bought by people who are incapable of forming ordinary relationships for various reasons. VR is being used in arousal tests to gauge the efficacy of treatments against pedophilia.\\r\\n\\r\\nShe noted that gender issues have arisen in technology already; the history of gendered technology includes pacemakers originally designed only for men and phones too large for women\\'s pockets. We should get into AI now to make sure that it is not designed in problematic ways.\\r\\n\\r\\nShe mentioned privacy concerns, as the manufactures of the female stimulator WeVibe have already been sued over concerns that they were not properly informing customers of their collection of data from the devices. She wondered if we will ever get to a stage where a robot might have some knowledge of its role and refuse to give consent to its use, and if transmission/duplication of data and code between machines could serve as some form of digital sexual reproduction.\\r\\n\\r\\nVasant Dhar of NYU spoke next about data and privacy in the era of autonomous vehicles. He said that our legal and financial liability institutions are based on outdated notions of data and that they fail to address liability and crime. However, the tools we have now even in ordinary cars for recording data can be used to improve insurance and judicial systems. He proposed black boxes for cars that would contain all relevant data to determine fault in the event of accidents, and said that customers should have the choice to share their driving data with insurance companies to get lower premiums. \\r\\n\\r\\nDhar reiterated the importance of improving vehicle safety through autonomous driving; each percentage point reduction in vehicle accidents equates to 400 deaths and 40,000 injuries avoided every year.\\r\\n\\r\\nAdam Kolber followed up with a discussion of whether \"the code is the law\", based on the case study of [The DAO](https://en.wikipedia.org/wiki/The_DAO_%28organization%29) which was an automated capital fund which was subjected to a $50 million loss through exploitation. The answer apparently is that the code should not be the law, even though many people seemed to accept that it was.\\r\\n\\r\\nSteve Wolfram of WolframAlpha and Mathematica fame discussed the issues of computer languages and goal specification. He said that his life work has essentially been about trying to find ways for humans to specify their goals to machines, and that this can work for ethics as well as for math. He doesn\\'t think that any single moral theory is likely to work for guiding artificial intelligence, apparently because of Godel\\'s theorem and the incompleteness of computational languages.\\r\\n\\r\\nFrancesca Rossi of IBM argued that for AIs and humans to interact very productively we will have to embed them in environments, so that rather than picking up a tool like a laptop or a phone, we are interacting with artificial systems all around is in our rooms and spaces. Humans will be recognized by their environments and our needs and wants will be inferred or asked about. AI embedded in environments can have memories about humans to better serve their interests. Most of all, we will need to establish trust between humans and AIs.\\r\\n\\r\\nPeter Railton, philosopher at the University of Michigan, attacked the subjects of orthogonality and value learning. He said that we can\\'t simply tell AIs to do what we want because our wants and values require critical assessment. He said that the orthogonality thesis might be right, but as we increasingly interact with systems and allow them to participate in our own lives and decisionmaking, the question of what it would take for them to be intelligent might involve certain features relevant to morality.\\r\\n\\r\\nHe stated that AIs should be thought of as social creatures; as a simple model, self regulation in a Hobbesian social contract leads to constraints and respect derived from self preservation. A society of intelligent cooperators can resist aggression and malice, and being moral is more efficient for a community than being cunning. From these principles we have a recipe for building proto-moral agents.\\r\\n\\r\\nHe discussed the \\'moral point of view\\' required for many strong ethical theories such as Kantian ethics and consequentialism: it requires agents to have a hierarchical, non-perspectival, modal/planning-oriented, and consistent view of the world which assigns intrinsic moral weight to things. He described how all these features are also part of the process of becoming generally intelligent in the first place, implying that general social intelligence ensures the necessary information required for moral decisionmaking. In the path towards functional moral agents, we will have to build agents which can represent the goals of others and have them learn how to act in beneficial ways. So if we can build AIs that we can trust, then we are on a good path towards building artificial moral agents.\\r\\n\\r\\nIn the Q&amp;A, Eliezer Yudkowsky objected that in the long run the \\'instrumental strategy\\' is not quite what you want because maximizing people\\'s desires as they are explicitly revealed can lead to bad outcomes, and you have to have a view like coherent extrapolated volition which asks what people would really want. Russell objected that when an agent becomes sufficiently powerful, it has no need to cooperate anymore.\\r\\n\\r\\nRegina Rini of the NYU Center for Bioethics stated that the approaches to ethics so far described relied too much on the Western post-enlightenment view of ethics, which is a historical aberration, and excluded African, Chinese and other approaches to ethics. Railton stated that his scheme was grounded in basic empathy and not mediated by any higher order moral theory; Wolfram and Rossi said that no one ethical approach will work and AI will have to represent diverse values.\\r\\n\\r\\n**Day Two**\\r\\n\\r\\nSaturday was devoted to long term discussion of the future of advanced artificial intelligence. Stuart Russell, professor at UC Berkeley and head of the new Center for Human Compatible Artificial Intelligence, started with a basic overview of the control problem. He described the points made in Steve Omohundro\\'s paper on convergent instrumental drives. He also had some pretty harsh words for the researchers in the AI community which have denied and rejected notions of the control problem without seriously engaging with the relevant literature.\\r\\n\\r\\nHe had three simple ideas which he proposed to constitute the definition of \\'provably beneficial\\' AI: maximizing values for humans is the system\\'s only goal; the robot is initially uncertain about these goals, and the best source of information is human behavior. He referred to inverse reinforcement learning as a technique for machines to learn human preferences, and said that uncertainty provides an incentive for machines to learn, ask questions, and explore cautiously. \\r\\n\\r\\nHis answer to the off-switch problem is to make robots unsure of their objectives, so that they assume that the human will switch the robot off if and only if it has a good reason to, and will therefore be complicit with the action. He said that the wireheading problem can be avoided if you construct the reward signal as information about the reward function rather than as a reward itself; this way, any hijacking of the reward signal makes it useless.\\r\\n\\r\\nHe said that there is a strong economic incentive for value alignment, but humans are irrational, nasty, inconsistent, and weak-willed.\\r\\n\\r\\nThe next speaker was Eliezer Yudkowsky of the Machine Intelligence Research Institute. Chalmers pointed out his role there as well as his side venture in Harry Potter fanfiction.\\r\\n\\r\\nYudkowsky started [his talk](https://intelligence.org/nyu-talk/) by pointing out how the Terminator pictures in every media article about the control problem are inappropriate. The real analogy to be used is [Mickey Mouse as the Sorcerer\\'s Apprentice in *Fantasia*.](https://www.youtube.com/watch?v=Ait_Fs6UQhQ) \\r\\n\\r\\nHe said that the first difficulty of AI alignnment is that the utility functions we imagine are too simple, and the second difficulty is that maximizing the probability of achieving a given goal leads to pathological outcomes. He and MIRI are concerned with the nature of the goal of \\'maximizing\\' and how to define goals in a way that avoids the problems of perverse instantiation. \\r\\n\\r\\nHe said that the fears of AI being developed by some terrorist or rogue group were silly, as \"ISIS is not developing convolutional neural nets.\" Instead the most powerful AI is likely to be developed by large groups in government, academia and industry.\\r\\n\\r\\nHe claimed that the four central propositions which support the idea that AI is a very big problem are: the orthogonality thesis, instrumental convergence, capability gain (the speed at which advanced AI can make itself better), and alignment difficulty. He said the first two are logical matters of computer science that people always learn to accept when they reflect upon them, while the latter two are more controversial.\\r\\n\\r\\nThe next talk was from Max Tegmark and Meia Chita-Tegmark. Max is a world-renowned physicist who helps run the Future of Life Institute, and Meia is a psychologist. They explained how physics and psychology provide useful tools for understanding artificial intelligence; physics tells us about computation and the constraints of the universe, and psychology tells us about the nature of well being, ways to debug the mind when reasoning about AI and methods to design psychomorphic AIs. Meia was the only speaker at the conference to discuss unemployment in any detail; she pointed out that retirement has only mixed effects on well being and that happiness comes from financial satisfaction and feelings of respect. She said that studying homemakers, part time workers and early retirees can tell us more about how an automated economy would affect people\\'s well-being.\\r\\n\\r\\nMax checked off [a list of common myths](http://futureoflife.org/background/aimyths/) regarding advanced AI. Meia said that we should look at the cognitive biases which have led to these misconceptions (such as availability bias leading to people worrying about robots rather than invisible artificial intelligence) and figure out how to avoid similar bugs from inhibiting our thinking in the future.\\r\\n\\r\\nBy the way, Max Tegmark is very cool, he has a sort of old-rocker-dude vibe, and he and Meia are super cute together.\\r\\n\\r\\nWendell Wallach of Yale spoke next. He is the man who quite literally wrote [the book](https://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975) on AI ethics. He distinguished top-down approaches of formally specifying AI behaviors from bottom-up approaches of value learning. He said that neither will be sufficient on its own and that both have important roles to play. He is worried that AI engineers will make simplistic assumptions about AI, such as the idea that every decision should be utilitarian or the idea that \\'ethics\\' and \\'morality\\' are icky concepts that can be ignored.\\r\\n\\r\\nSteve Petersen, a philosopher at the University of Niagara, gave the next talk, based on the draft of a forthcoming paper of his. He aims to push back against the orthogonality thesis and modulate the level of the risk assessment provided by Bostrom. His argument is that designing AI to follow any complex goal will necessarily require it to be able to learn the values of its \"teleological ancestors\" (the original human designers or the previous iterations of AI before it self-improved or self-modified) and arrive at a state of coherence between goals. As agents replicate, self-modify and merge in the digital world, there can be no fact of the matter about which agents are the same or different; instead there will be an \\'agential soup\\' unified by a common teleological thread originating with the designers. Coherence reasoning leads to impartial reasoning with the goals of other agents.\\r\\n\\r\\nThere were several responses to him in Q&amp;A. Yudkowsky\\'s objection was that reaching coherence requires a meta-preference framework with particular assumptions about the universe and ontology; therefore, for any goal, there are many preference frameworks which could fulfill it, many of which would be perverse. Russell said that just coherence is not enough because you need the systems to give special weight to humans. Max Tegmark said that the problem was the vagueness of humanity\\'s final goals. Chalmers pointed out that the orthogonality thesis still allows for all kinds of correlations between between intelligence and morality, as long as they are not necessary by design. Petersen said that he is arguing for \\'attractor basins\\' in the possibility space of AI minds. Interestingly, he was motivated to start his research by the [Dylan Matthews Vox article](http://www.vox.com/2015/8/10/9124145/effective-altruism-global-ai) on effective altruism where Dylan thought that effective altruists shouldn\\'t be concerned by artificial intelligence. Petersen doesn\\'t think that AI is unimportant and thinks that Bostrom and Yudkowsky\\'s work is valuable, but he wanted to get a more critical assessment of the level of risk when he learned that alternative altruistic projects were at stake.\\r\\n\\r\\nMatthew Liao of the NYU Center for Bioethics gave an argument for moral status on the basis of capabilities - that an entity is morally valuable to the extent that it has the physical/genetic basis for achieving features of moral relevance. I did not get a chance to ask him if this would imply that a \\'seed AI\\' could be the most morally valuable entity in the world. He did argue against the ideas that level of intelligence or degree of moral agency determine moral status, as we don\\'t normally think that smarter or more benevolent humans are more morally valuable than others. \\r\\n\\r\\nLiao argued that moral theories are too specific and too high level to be generally implemented in AIs. Instead, AI will need a universal moral grammar in which to specify morality. The holy grail is to develop machines that understand why things are right or wrong.\\r\\n\\r\\nEric Schwitzgebel and Mara Garza of UC Riverside argued for basic principles of AI rights. They introduced a very weak \"no-relevant-difference\" argument: the idea that there are possible AIs which have the same morally relevant features that humans do and therefore there are possible AIs with equal value to humans. They questioned if cheerfully suicidal or hardworking AI is acceptable, and stated a \\'self respect principle\\': that human grade AI should be designed with an appropriate appreciation of its own value.\\r\\n\\r\\nJohn Basl and Ronald Sandler of Northeastern University argued for AI research committees to approve or deny research in cases where AI subjects might be harmed. They said it would not be very different from cases like animal testing where we have similar review boards, and sketched out details of how the proposal would work.\\r\\n\\r\\nDaniel Kahneman, one of the most famous behavioral economists in the world, made something of a surprise appearance in the final panel. He said that we should take intuitions about case studies like the trolley problem seriously, as that is how the public will think about these events, for better or for worse. He said that no matter how AI cars kill people, it will be perceived with horror whenever the first incident happens, and we should prepare for that. Intuitions depend on irrelevant factors and will especially depend on whether AIs are designed to resemble us or not.\\r\\n\\r\\nGary Marcus, professor of psychology at NYU, of gave a much needed presentation about the nature of intelligence. The previous talks in this discussion had mostly assumed that intelligence was one-dimensional and simple and that there was some fixed idea of \\'human-level\\' AI which we could eventually reach. Of course this is a ridiculous oversimplification; intelligence is multidimensional and it is more about implementing a combination of various cognitive tools, some of which are already stronger in AIs than in humans. AIs can be better or worse than us in various domains, so we really have no idea where AIs will be in this multidimensional space. AIs could in fact be better than us at moral reasoning. He also emphasized the gap is between machine learning today and what human reasoning can do.\\r\\n\\r\\nSusan Schneider of Marquette University, a philosopher who has written quite a bit about AI and superintelligence, went over various issues. She argued that mind uploads might constitute death of the individual as long as we don\\'t prove certain ideas about consciousness and personal identity, and also claimed that designing an intelligent and morally valuable robot to serve the interests of its creators would constitute slavery.\\r\\n\\r\\nJaan Tallinn, founder of Skype, also gave a quick talk. He has been a strong financial backer for MIRI and other efforts in this space, and simply expressed his belief in the importance of the issue and his happiness at the success of the conference and the number of students who were interested in pursuing the topic.\\r\\n\\r\\nThere was some final banter about the nature of consciousness which David Chalmers sat through very passively. Yudkowsky expressed optimism that one day we will have an explanation of consciousness which clears up our confusion on the matter. Nagel said that we will need to think more about the dynamics of multi-agent systems and moral epistemology. After that the event ended.\\r\\n\\r\\nThe conference videos are available [here.](http://livestream.com/nyu-tv/ethicsofAI) In my opinion, the best talks were given by LeCun, Railton, Russell, Yudkowsky, the Tegmarks, Petersen, and Marcus. The event overall was great and being in Manhattan made it even better. There was quite a bit of valuable informal meeting and discussion between many of the speakers and attendees. There was no \\'sneering\\' or disdain about Yudkowsky or Bostrom as far as I could tell. It seemed like a generally open minded yet well educated crowd.\\r\\n\\r\\nIf you regret missing it, then you might like to head to the [Envision Conference](http://envision-conference.com/) this December. \\r\\n\\r\\n',\n",
              "  'labels': ['transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.1885560303926468,\n",
              "   0.1562233418226242,\n",
              "   0.1431477665901184,\n",
              "   0.13003666698932648,\n",
              "   0.12148721516132355,\n",
              "   0.10665667057037354,\n",
              "   0.0806671530008316,\n",
              "   0.07322519272565842]},\n",
              " {'sequence': 'UK Parliamentary Committee calls for a Commission on Artificial Intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.4071415662765503,\n",
              "   0.2241034060716629,\n",
              "   0.10592130571603775,\n",
              "   0.08132912963628769,\n",
              "   0.06117800995707512,\n",
              "   0.05993031710386276,\n",
              "   0.033829160034656525,\n",
              "   0.026567161083221436]},\n",
              " {'sequence': 'Robots could eventually replace soldiers in warfare. Is that a good thing? ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.383749783039093,\n",
              "   0.13201896846294403,\n",
              "   0.12951284646987915,\n",
              "   0.11073089390993118,\n",
              "   0.07958836108446121,\n",
              "   0.07276426255702972,\n",
              "   0.06039775535464287,\n",
              "   0.031237158924341202]},\n",
              " {'sequence': 'US tech giants unite to ensure AI is developed safely and ethically ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4326125383377075,\n",
              "   0.26183679699897766,\n",
              "   0.10686435550451279,\n",
              "   0.06830199807882309,\n",
              "   0.05983482673764229,\n",
              "   0.034992679953575134,\n",
              "   0.022806985303759575,\n",
              "   0.01274982187896967]},\n",
              " {'sequence': 'The map of issues in AI ethics ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2301882803440094,\n",
              "   0.15970751643180847,\n",
              "   0.14928342401981354,\n",
              "   0.1357838213443756,\n",
              "   0.12487061321735382,\n",
              "   0.09245815873146057,\n",
              "   0.058703720569610596,\n",
              "   0.0490044429898262]},\n",
              " {'sequence': 'We are trending! I\\'m quite stunned at this -- two days ago I was actually planning to call quits on the subreddit and label it dead, no joke -- but we received a lot of attention yesterday after I [posted](https://www.reddit.com/r/Futurology/comments/55an2u/the_map_of_ai_ethical_issues/) an infographic to r/futurology. Everyone likes the intersection of science fiction with reality, and with self driving cars we\\'re already seeing the need for ethical values to be implicitly encoded into machines.\\r\\n\\r\\nI wish we had a good \"introductory article\" for newcomers who just want to start learning about the philosophy of AI and robotics but none could encapsulate everything; we are here to discuss a very wide set of issues and topics that humanity will have to address in the future.\\r\\n\\r\\nTrending thread is here: https://www.reddit.com/r/trendingsubreddits/comments/55ha4r/trending_subreddits_for_20161002_rmedia_criticism/',\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.212163507938385,\n",
              "   0.15611892938613892,\n",
              "   0.12608373165130615,\n",
              "   0.12482593208551407,\n",
              "   0.09803208708763123,\n",
              "   0.09666228294372559,\n",
              "   0.095899797976017,\n",
              "   0.09021376073360443]},\n",
              " {'sequence': 'Anders Sandberg - Ethics of brain emulations [PDF] ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3746800422668457,\n",
              "   0.1510263830423355,\n",
              "   0.1424955278635025,\n",
              "   0.12025600671768188,\n",
              "   0.0637909546494484,\n",
              "   0.058662284165620804,\n",
              "   0.0512826144695282,\n",
              "   0.03780623525381088]},\n",
              " {'sequence': \"Articles on algorithmic fairness? I'm finding the subject area of algorithmic fairness very interesting. I don't know if there's a substantial archive of articles about the subject I should check out though. Anywhere to start in particular?\",\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.7527704238891602,\n",
              "   0.07011839002370834,\n",
              "   0.04723980650305748,\n",
              "   0.03942820429801941,\n",
              "   0.032417211681604385,\n",
              "   0.028152531012892723,\n",
              "   0.016393037512898445,\n",
              "   0.013480417430400848]},\n",
              " {'sequence': 'Grad student in mathematics ruins birthday party by using a fair division algorithm to cut cake ',\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5688772797584534,\n",
              "   0.13536962866783142,\n",
              "   0.09211128205060959,\n",
              "   0.0702243447303772,\n",
              "   0.0533016175031662,\n",
              "   0.040807515382766724,\n",
              "   0.020985346287488937,\n",
              "   0.018323032185435295]},\n",
              " {'sequence': 'Miles Brundage: Limitations and Risks of Machine Ethics ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3979921042919159,\n",
              "   0.1783444732427597,\n",
              "   0.14717216789722443,\n",
              "   0.09506838023662567,\n",
              "   0.050260744988918304,\n",
              "   0.04951716586947441,\n",
              "   0.048242997378110886,\n",
              "   0.0334019735455513]},\n",
              " {'sequence': \"A beauty contest was judged by AI and the robots didn't like dark skin \",\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.3991844654083252,\n",
              "   0.35558468103408813,\n",
              "   0.06617143750190735,\n",
              "   0.05570881441235542,\n",
              "   0.053911130875349045,\n",
              "   0.03516615554690361,\n",
              "   0.01848808489739895,\n",
              "   0.01578516513109207]},\n",
              " {'sequence': 'Need help crafting robotics policy for European Union \" /r/slatestarcodex ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5795433521270752,\n",
              "   0.1323062926530838,\n",
              "   0.11982258409261703,\n",
              "   0.04420040547847748,\n",
              "   0.03842116519808769,\n",
              "   0.03136346489191055,\n",
              "   0.030176466330885887,\n",
              "   0.02416626736521721]},\n",
              " {'sequence': 'Artificial Intelligence and Life in 2030 ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4092734456062317,\n",
              "   0.13713222742080688,\n",
              "   0.11909131705760956,\n",
              "   0.1081041470170021,\n",
              "   0.07459736615419388,\n",
              "   0.06297440081834793,\n",
              "   0.050871364772319794,\n",
              "   0.03795572370290756]},\n",
              " {'sequence': \"It\\x19s Our Fault That AI Thinks White Names Are More 'Pleasant' Than Black Names \",\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.6230102181434631,\n",
              "   0.17226283252239227,\n",
              "   0.12479259073734283,\n",
              "   0.05806247889995575,\n",
              "   0.008446439169347286,\n",
              "   0.005685577634721994,\n",
              "   0.0047097890637815,\n",
              "   0.003030090592801571]},\n",
              " {'sequence': 'UC Berkeley launches Center for Human-Compatible Artificial Intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.33303871750831604,\n",
              "   0.21680998802185059,\n",
              "   0.12876003980636597,\n",
              "   0.08617309480905533,\n",
              "   0.0817267894744873,\n",
              "   0.07025359570980072,\n",
              "   0.042980264872312546,\n",
              "   0.040257491171360016]},\n",
              " {'sequence': 'Francesca Rossi - Moral Preferences ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3994066119194031,\n",
              "   0.11581143736839294,\n",
              "   0.10290073603391647,\n",
              "   0.09683886915445328,\n",
              "   0.08865847438573837,\n",
              "   0.07900314033031464,\n",
              "   0.07710036635398865,\n",
              "   0.040280379354953766]},\n",
              " {'sequence': 'Machine Ethics Reading List This is an overview of technical readings in machine ethics (developing moral frameworks for autonomous systems). I have less familiarity with other topics in AI ethics and have not done a review of the literature in those other fields, so I\\'m not making a reading list for all that at the moment.\\r\\n\\r\\n**Papers**\\r\\n\\r\\nAllen, C., Varner, G., &amp; Zinser, J. (2000). Prolegomena to any future artificial moral agent. http://commonsenseatheism.com/wp-content/uploads/2009/08/Allen-Prolegomena-to-any-future-artificial-moral-agent.pdf\\r\\n\\r\\nAnderson, M., Anderson, S. L., &amp; Armen, C. (n.d.). Towards Machine Ethics: Implementing Two Action-Based Ethical Theories. https://www.aaai.org/Papers/Symposia/Fall/2005/FS-05-06/FS05-06-001.pdf\\r\\n\\r\\nArkoudas, K., Bringsjord, S., Bello, P. (2005). Toward ethical robots via mechanized deontic logic. https://www.aaai.org/Papers/Symposia/Fall/2005/FS-05-06/FS05-06-003.pdf\\r\\n\\r\\nArmstrong, S. (2015). Motivated Value Selection for Artificial Agents. https://www.aaai.org/ocs/index.php/WS/AAAIW15/paper/viewFile/10183/10126\\r\\n\\r\\nBello, P., &amp; Bringsjord, S. (2013). On How to Build a Moral Machine. https://doi.org/10.1007/s11245-012-9129-8\\r\\n\\r\\nBendel, O. (2013). Considerations about the relationship between animal and machine ethics. http://doi.org/10.1007/s00146-013-0526-3\\r\\n\\r\\nGoodall, A. N. J. (2014). Machine Ethics and Automated Vehicles. http://people.virginia.edu/~njg2q/machineethics.pdf\\r\\n\\r\\nGrau, C. (n.d.). There is no \\x1cI\\x1d in \\x1cRobot\\x1d: Robotic Utilitarians and Utilitarian Robots. https://www.aaai.org/Papers/Symposia/Fall/2005/FS-05-06/FS05-06-007.pdf\\r\\n\\r\\nLokhorst, G. J. C. (2011). Computational meta-ethics towards the meta-ethical robot. https://doi.org/10.1007/s11023-011-9229-z ([erratum](https://www.researchgate.net/publication/263369942_Erratum_to_Computational_Meta-Ethics_Towards_the_Meta-Ethical_Robot))\\r\\n\\r\\nMuntean, I. &amp; Howard, D. (2016). A minimalist model of the artificial autonomous moral agent (AAMA). https://www.aaai.org/ocs/index.php/SSS/SSS16/paper/download/12760/11954\\r\\n\\r\\nOesterheld, C. (2015). Formalizing preference utilitarianism in physical world models. https://doi.org/10.1007/s11229-015-0883-1\\r\\n\\r\\nPereira, L. M., &amp; Saptawijaya, A. (2009). Modelling morality with prospective logic. https://doi.org/10.1504/IJRIS.2009.028020\\r\\n\\r\\nPowers, T. M. (n.d.). Deontological Machine Ethics. https://www.aaai.org/Papers/Symposia/Fall/2005/FS-05-06/FS05-06-012.pdf\\r\\n\\r\\nPowers, T. M. (n.d.). Prospects for a Smithian Machine. http://www.iacap.org/proceedings_IACAP13/paper_52.pdf\\r\\n\\r\\nShulman, C., Tarleton, N., &amp; Jonsson, H. 2009. Which Consequentialism? Machine Ethics\\r\\nand Moral Divergence. https://intelligence.org/files/WhichConsequentialism.pdf\\r\\n\\r\\nTarleton, N. (2010). Coherent Extrapolated Volition: A Meta-Level Approach to Machine Ethics. https://intelligence.org/files/CEV-MachineEthics.pdf\\r\\n\\r\\nWhite, J. (n.d.). Autonomous Reboot: the challenges of artificial moral agency and the ends of Machine Ethics.  \\r\\n\\r\\nWhite, J. (n.d.). A General Theory of Moral Agency Grounding Computational Implementations: The ACTWith Model. https://www.academia.edu/7000519/Autonomous_Reboot_the_challenges_of_artificial_moral_agency_and_the_ends_of_Machine_Ethics\\r\\n\\r\\nWiltshire, T. J. (2015). A Prospective Framework for the Design of Ideal Artificial Moral Agents: Insights from the Science of Heroism in Humans. https://doi.org/10.1007/s11023-015-9361-2\\r\\n\\r\\n**Books**\\r\\n\\r\\nWallach, W. &amp; Allen, C. Moral Machines: Teaching Robots Right from Wrong. https://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975\\r\\n\\r\\n**Encyclopedia Articles**\\r\\n\\r\\nMcNamara, P. \"Deontic Logic\", The Stanford Encyclopedia of Philosophy. https://plato.stanford.edu/archives/win2014/entries/logic-deontic\\r\\n\\r\\nPortoraro, F. \"Automated Reasoning\", The Stanford Encyclopedia of Philosophy. https://plato.stanford.edu/archives/win2014/entries/reasoning-automated/\\r\\n\\r\\n\\r\\n---\\r\\nI\\'m sure I\\'ve missed some so feel free to suggest additions.',\n",
              "  'labels': ['responsibility',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.14992421865463257,\n",
              "   0.14585913717746735,\n",
              "   0.13998353481292725,\n",
              "   0.13234810531139374,\n",
              "   0.12625250220298767,\n",
              "   0.11697282642126083,\n",
              "   0.10097641497850418,\n",
              "   0.08768330514431]},\n",
              " {'sequence': 'MIT\\'s Moral Machine: \"a platform for gathering a human perspective on moral decisions made by machine intelligence, such as self-driving cars\" ',\n",
              "  'labels': ['accountability',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3016315698623657,\n",
              "   0.20614545047283173,\n",
              "   0.2021000236272812,\n",
              "   0.12920959293842316,\n",
              "   0.05607201159000397,\n",
              "   0.044582489877939224,\n",
              "   0.038154277950525284,\n",
              "   0.022104602307081223]},\n",
              " {'sequence': 'If AI Systems Can Be \"Persons,\" What Rights Should They Have? - Future of Life Institute ',\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3763318359851837,\n",
              "   0.16482402384281158,\n",
              "   0.14446860551834106,\n",
              "   0.12451205402612686,\n",
              "   0.06501170247793198,\n",
              "   0.05644828453660011,\n",
              "   0.036706019192934036,\n",
              "   0.03169745206832886]},\n",
              " {'sequence': 'Ethics of Artificial Intelligence \\x13 NYU Center for Mind, Brain and Consciousness ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3794429302215576,\n",
              "   0.27835726737976074,\n",
              "   0.10367956757545471,\n",
              "   0.06360992044210434,\n",
              "   0.061672359704971313,\n",
              "   0.0595998577773571,\n",
              "   0.029972262680530548,\n",
              "   0.023665837943553925]},\n",
              " {'sequence': 'Use of police robot to kill Dallas shooting suspect believed to be first in US history ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.41512563824653625,\n",
              "   0.17058762907981873,\n",
              "   0.12290598452091217,\n",
              "   0.10035111755132675,\n",
              "   0.08900552242994308,\n",
              "   0.05012792348861694,\n",
              "   0.032761722803115845,\n",
              "   0.01913446933031082]},\n",
              " {'sequence': 'Are \\'enhanced humans\\' safe? Some thinkers believe that machine intelligence will arrive at some point, but rather than *autonomous AGIs*, we\\'ll get either [mind uploads](http://mason.gmu.edu/~rhanson/uploads.html) or [enhanced human intelligence](http://www.huffingtonpost.com/entry/ray-kurzweil-nanobots-brain-godlike_us_560555a0e4b0af3706dbe1e2) via e.g. brain-computer or brain-nanobot interfaces. I\\'ve heard some arguments that if those paths are likely (I find them at least plausible), then there\\'s little reason to be too concerned about AI ethics / control problem / AI-safety: the human elements will inject the necessary ethics into the future cyborg/\"em\" overlords.\\r\\n\\r\\nThis seems very wrong to me. Malice, error, destructive behavior are all common amongst humans. If the future enhanced humans are less vulnerable than us and/or more powerful, than we potentially are handing any clever/malicious hacker/troll every nuclear bomb in the world and the Ring of Gyges. In other words: there will likely be some bad actors, and some bad actors may find ways to control/harm others in radical ways that are impossible today due to the limited faculties of even the most advanced human. \\r\\n\\r\\nRather, it seems that we\\'d need the same AI-safety that was already motivated by the autonomous-AGI case, and make sure that it works provably even when interfaced with a brain or uploaded mind. But is this a plausible scenario?\\r\\n\\r\\n\\r\\n',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.17041321098804474,\n",
              "   0.1472925841808319,\n",
              "   0.13670432567596436,\n",
              "   0.13404300808906555,\n",
              "   0.11220109462738037,\n",
              "   0.11135554313659668,\n",
              "   0.10150427371263504,\n",
              "   0.08648592978715897]},\n",
              " {'sequence': 'SMBC - Self Driving Car Ethics ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4132487177848816,\n",
              "   0.22820495069026947,\n",
              "   0.09989561140537262,\n",
              "   0.08893777430057526,\n",
              "   0.08330392092466354,\n",
              "   0.03926234692335129,\n",
              "   0.03330593556165695,\n",
              "   0.013840791769325733]},\n",
              " {'sequence': \"Intuitionist vs Classical Ethics If you try to develop an approach to machine ethics, there's two main paths you can take. The first is classical ethics, which means hard-coding moral frameworks into an agent. It could be utilitarianism, deontological ethics, something else entirely, or a combination. The advantages of doing this are that it guarantees conformity to robust moral principles and it gives humans perfect understanding of how the agent makes decisions. However, people often don't like this idea because there is no consensus on morality between philosophers and because formalizing morality can be difficult.\\r\\n\\r\\nThe other approach is intuitionist. Researchers have sketched out plans to use human cognitive models and training datasets of moral behavior to create AIs which make moral decisions in ways that mirror human intuitions. The claim behind this is often that it avoids moral disagreement, and since we can all agree on some examples of morally good behavior, we can just let the AI learn our values from them.\\r\\n\\r\\nWhat I disagree with is the notion that encoding traditional morality is somehow a problem merely because philosophers don't agree. Why should the disagreements between philosophers stop us from building AIs rooted in classical morality, as long as we use rigorous, plausible moral theories which are actively defended by at least some of the experts in the field? Why not allow developers and engineers to imbue machines with any of those moral theories that they want and then just see what happens?\",\n",
              "  'labels': ['transparency',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'justice'],\n",
              "  'scores': [0.1951073557138443,\n",
              "   0.15291263163089752,\n",
              "   0.13681426644325256,\n",
              "   0.11739294975996017,\n",
              "   0.11061390489339828,\n",
              "   0.10787229984998703,\n",
              "   0.1062423437833786,\n",
              "   0.07304425537586212]},\n",
              " {'sequence': 'Upcoming Conference in NYC: The Social and Economic Implications of Artificial Intelligence Technologies in the Near-Term ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.38344907760620117,\n",
              "   0.15458275377750397,\n",
              "   0.140986368060112,\n",
              "   0.12228799611330032,\n",
              "   0.0682305097579956,\n",
              "   0.06455886363983154,\n",
              "   0.040919531136751175,\n",
              "   0.024984870105981827]},\n",
              " {'sequence': \"but what if the AIs have babies and they're too cute to shut off \",\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.24921853840351105,\n",
              "   0.19778144359588623,\n",
              "   0.17041218280792236,\n",
              "   0.15040181577205658,\n",
              "   0.07335878908634186,\n",
              "   0.06572728604078293,\n",
              "   0.0585046112537384,\n",
              "   0.03459526225924492]},\n",
              " {'sequence': \"Is it Ethical to remove constants from your loss function? If I add a constant c to my loss function Loss_new = loss + c, then the gradient with respect to the loss and hence the learning is unchanged.  \\r\\n\\r\\nHowever I'm wondering if it's really ethical to add a positive constant.  Won't the net feel better about itself if it has a lower loss?  \\r\\n\\r\\nPerhaps it would be most ethical if I always subtract 999.999 from my loss function.  That way the neural network will be motivated by a sense of self improvement and ambition rather than a fear of failure.  \",\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.264570415019989,\n",
              "   0.2129422426223755,\n",
              "   0.12881086766719818,\n",
              "   0.11421305686235428,\n",
              "   0.09238191694021225,\n",
              "   0.08399751782417297,\n",
              "   0.05754994601011276,\n",
              "   0.04553407058119774]},\n",
              " {'sequence': 'Carl Shulman and Nick Tarleton: Which Consequentialism? ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2873530983924866,\n",
              "   0.19179442524909973,\n",
              "   0.17110347747802734,\n",
              "   0.09469760954380035,\n",
              "   0.09060715138912201,\n",
              "   0.06970646977424622,\n",
              "   0.05815736949443817,\n",
              "   0.03658038005232811]},\n",
              " {'sequence': 'Autonomous cars and \"trolley problems\" Everyone\\'s heard of the debate about what cars should do in cases where they have to choose between harming the driver and harming pedestrians or other drivers.\\r\\n\\r\\nHowever, in a [recent AI conference](https://www.reddit.com/r/ControlProblem/comments/4qndcn/notes_on_the_safety_in_artificial_intelligence/), one of the speakers brought up a case where a vehicle would have to decide whether to swerve to avoid a deer. Swerving has a 1 in 10 million chance of killing the human and a 1% chance of killing the deer; driving straight has a 1 in a million chance of killing the human and a 75% chance of killing the deer:\\r\\n\\r\\nhttps://i.imgur.com/KLhvmb6.jpg\\r\\n\\r\\nYou may disagree with the specific numbers but how do you think these situations should be handled? Apparently, people are irrationally protective of animals when they see them in the road, and perhaps the role of autopilots could be to override the human instinct to avoid hitting animals (at excessive risk of personal danger). After all, people have no problem killing animals just for pleasure/food, which is inconsistent with how they react to animals in the road.',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.19046559929847717,\n",
              "   0.16423869132995605,\n",
              "   0.13931280374526978,\n",
              "   0.13822436332702637,\n",
              "   0.10026827454566956,\n",
              "   0.09823968261480331,\n",
              "   0.08708194643259048,\n",
              "   0.08216871321201324]},\n",
              " {'sequence': \"Why robots need to be able to say 'No' \",\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4998638927936554,\n",
              "   0.19962750375270844,\n",
              "   0.06543465703725815,\n",
              "   0.05897282436490059,\n",
              "   0.05162493512034416,\n",
              "   0.045406751334667206,\n",
              "   0.04177619144320488,\n",
              "   0.03729326277971268]},\n",
              " {'sequence': 'Surveillance drones easier to get, widespread use soon? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3268919885158539,\n",
              "   0.21792110800743103,\n",
              "   0.1773299127817154,\n",
              "   0.08616804331541061,\n",
              "   0.0646355152130127,\n",
              "   0.055777497589588165,\n",
              "   0.03838479518890381,\n",
              "   0.03289118409156799]},\n",
              " {'sequence': 'TEDx Talk on ML Bias and Ethics in Healthcare ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.5305832624435425,\n",
              "   0.18871846795082092,\n",
              "   0.14000138640403748,\n",
              "   0.059929247945547104,\n",
              "   0.028300054371356964,\n",
              "   0.022103220224380493,\n",
              "   0.019487474113702774,\n",
              "   0.010876882821321487]},\n",
              " {'sequence': 'Are you scared yet? Meet Norman, the psychopathic AI - BBC News ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.4166732132434845,\n",
              "   0.22806420922279358,\n",
              "   0.13373233377933502,\n",
              "   0.08384136110544205,\n",
              "   0.07181134074926376,\n",
              "   0.03296361863613129,\n",
              "   0.018336795270442963,\n",
              "   0.014577151276171207]},\n",
              " {'sequence': 'Artificial Intelligence and Its Implications for Future Suffering \\x13 Foundational Research Institute ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.3867887258529663,\n",
              "   0.15961617231369019,\n",
              "   0.1349257081747055,\n",
              "   0.12583723664283752,\n",
              "   0.06475070863962173,\n",
              "   0.045865319669246674,\n",
              "   0.04307747632265091,\n",
              "   0.039138615131378174]},\n",
              " {'sequence': 'Is mass surveillance ethical? Yeah, so it\\'s not happening only in China.\\r\\nhttps://www.theverge.com/platform/amp/2018/5/22/17379968/amazon-rekognition-facial-recognition-surveillance-aclu\\r\\n\\r\\nShould it be framed as individual freedom vs society safety? What did we learn from \"human surveillance\" that we should be applying to \"machine surveillance\"?',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'accountability'],\n",
              "  'scores': [0.2002732753753662,\n",
              "   0.17972595989704132,\n",
              "   0.17054705321788788,\n",
              "   0.15722331404685974,\n",
              "   0.087474524974823,\n",
              "   0.07263564318418503,\n",
              "   0.06770321726799011,\n",
              "   0.06441706418991089]},\n",
              " {'sequence': \"Opinion: Googlers resigning over a Pentagon contract aren't making the 'ethical stand' you think \",\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'privacy'],\n",
              "  'scores': [0.3513530492782593,\n",
              "   0.23086194694042206,\n",
              "   0.18728701770305634,\n",
              "   0.09244707226753235,\n",
              "   0.045495931059122086,\n",
              "   0.03594042733311653,\n",
              "   0.03462535887956619,\n",
              "   0.021989161148667336]},\n",
              " {'sequence': 'Benevolent Artificial Anti-Natalism (BAAN) by Thomas Metzinger ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency'],\n",
              "  'scores': [0.6313254237174988,\n",
              "   0.1016932800412178,\n",
              "   0.08126725256443024,\n",
              "   0.04931320995092392,\n",
              "   0.038815584033727646,\n",
              "   0.0340268574655056,\n",
              "   0.03300260752439499,\n",
              "   0.0305557269603014]},\n",
              " {'sequence': 'How Might Artificial Intelligence Affect the Risk of Nuclear War? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.4274732768535614,\n",
              "   0.16449077427387238,\n",
              "   0.15300330519676208,\n",
              "   0.08321541547775269,\n",
              "   0.058761391788721085,\n",
              "   0.040403932332992554,\n",
              "   0.03874151408672333,\n",
              "   0.03391045331954956]},\n",
              " {'sequence': 'Who gets to teach machines right and wrong? We Should. When a private organization develops a machine (whether driver-less car or genuine AI) that requires ethical stipulations to work in society, and they do not ask society\\x19s input, they establish themselves as a dangerous authority. Society at large already determines right and wrong; this should extend to the machines that will only come to have a greater and greater impact on our lives.\\r\\n\\r\\nWe need to open source machine ethics.\\r\\n\\r\\nThe trick is overcoming the original problem: those with technical expertise making ethical decisions for others without that know-how. The collaborative interface needs to be relatively easy or many won\\x19t bother learning to use it. It needs to be decentralized, human readable, censorship-resistant. A place to start might be a Wiki made up of the ethics, axioms and \\x1ccommon sense\\x1d of society but written in a fourth generation programming language very close to human semantics.\\r\\n\\r\\nToday most people generally consider Wikipedia to be a solid approximation of the truth; if we could have that level of collaboration for a machine-readable code of majority-agreed ethical tenets I think we might avoid the power differential that automation (and beyond) represents, preventing serious ethical risk for our species.',\n",
              "  'labels': ['accountability',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'justice'],\n",
              "  'scores': [0.22064208984375,\n",
              "   0.18038976192474365,\n",
              "   0.14851485192775726,\n",
              "   0.09931226819753647,\n",
              "   0.09913252294063568,\n",
              "   0.09460613131523132,\n",
              "   0.08829782158136368,\n",
              "   0.06910452246665955]},\n",
              " {'sequence': 'Golden - Nick Bostrom (2004) ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.22902551293373108,\n",
              "   0.17198890447616577,\n",
              "   0.15479668974876404,\n",
              "   0.1368279755115509,\n",
              "   0.09820537269115448,\n",
              "   0.0965735986828804,\n",
              "   0.07530798763036728,\n",
              "   0.03727396950125694]},\n",
              " {'sequence': 'The moral psychology of value sensitive design: the methodological issues of moral intuitions for responsible innovation ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'fairness'],\n",
              "  'scores': [0.728699803352356,\n",
              "   0.09856326133012772,\n",
              "   0.08202166855335236,\n",
              "   0.022754482924938202,\n",
              "   0.01913127303123474,\n",
              "   0.017739465460181236,\n",
              "   0.016084350645542145,\n",
              "   0.015005760826170444]},\n",
              " {'sequence': 'Meaningful Human Control over Autonomous Systems: A Philosophical Account ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5292342305183411,\n",
              "   0.2752997577190399,\n",
              "   0.06343471258878708,\n",
              "   0.03585852310061455,\n",
              "   0.028061702847480774,\n",
              "   0.025894584134221077,\n",
              "   0.022209564223885536,\n",
              "   0.020006921142339706]},\n",
              " {'sequence': 'Self-teaching algorithms could collude in ways that are impossible to detect (about antitrust) ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.39816078543663025,\n",
              "   0.2748675048351288,\n",
              "   0.09665127843618393,\n",
              "   0.09398455917835236,\n",
              "   0.04517681151628494,\n",
              "   0.03682510554790497,\n",
              "   0.033003609627485275,\n",
              "   0.021330364048480988]},\n",
              " {'sequence': 'AI ripe for exploitation, experts warn ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.29229098558425903,\n",
              "   0.2479918748140335,\n",
              "   0.1354219764471054,\n",
              "   0.0925714448094368,\n",
              "   0.08691763877868652,\n",
              "   0.05924004316329956,\n",
              "   0.04350615665316582,\n",
              "   0.04205989092588425]},\n",
              " {'sequence': \"Machine Learning and Media I'm doing a prospectus for research at the University of Memphis for my MA program, and I am looking into the ethics of using Machine Learning and AI in usage of entertainment and advertisement. I am developing a set of questions and would definitely enjoy talking to an expert in the field or anyone who has done research in this direction.\\r\\n\\r\\nMy background: \\r\\n\\r\\nSoftware developer and 3D Artist. BFA Animation, Savannah College of Art and Design 2011. MA Candidate, Film and Digital Media, University of Memphis 2019. \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.1947876662015915,\n",
              "   0.17965570092201233,\n",
              "   0.1428145468235016,\n",
              "   0.13844066858291626,\n",
              "   0.11897188425064087,\n",
              "   0.09726571291685104,\n",
              "   0.0729389563202858,\n",
              "   0.055124931037425995]},\n",
              " {'sequence': '(paywalled) Implementation of Moral Uncertainty in Intelligent Machines ',\n",
              "  'labels': ['responsibility',\n",
              "   'privacy',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.23143810033798218,\n",
              "   0.22662334144115448,\n",
              "   0.18745239078998566,\n",
              "   0.16692641377449036,\n",
              "   0.08343018591403961,\n",
              "   0.04322931915521622,\n",
              "   0.032057881355285645,\n",
              "   0.02884235419332981]},\n",
              " {'sequence': 'Artificial intelligence is going to supercharge surveillance ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.39727598428726196,\n",
              "   0.1925366073846817,\n",
              "   0.18338871002197266,\n",
              "   0.06624943017959595,\n",
              "   0.049121178686618805,\n",
              "   0.04607400298118591,\n",
              "   0.03422636166214943,\n",
              "   0.031127765774726868]},\n",
              " {'sequence': '[1104.3913] Fairness Through Awareness (2011) ',\n",
              "  'labels': ['fairness',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.809178352355957,\n",
              "   0.09343940019607544,\n",
              "   0.033439114689826965,\n",
              "   0.0270721185952425,\n",
              "   0.017629900947213173,\n",
              "   0.008322188630700111,\n",
              "   0.006829860154539347,\n",
              "   0.004089102149009705]},\n",
              " {'sequence': 'Capstone Project\\x14AI Research Branding Hey everyone! I\\'m a graphic design student but I\\'d love for your thoughts on [my capstone project](https://www.behance.net/gallery/59498375/The-Future-Institute).\\r\\n\\r\\n &amp;nbsp;\\r\\n\\r\\nWe had open range for topics on this project, so I chose to address the issue of ethics of safety in the development of AI. My solution was to create a research institute that would focus specifically on this, but in a more collaborative way. Rather than utilizing the expected \"techy\" graphic styles, I opted for classical type and illustration to help connect to more philosophical thinking and ethics. This is contrasted with the bright and modern colour palette.\\r\\n\\r\\n &amp;nbsp;\\r\\n\\r\\nPlease let me know what you think, I\\'d love your input!\\r\\n\\r\\nThanks :)',\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.28563520312309265,\n",
              "   0.14759422838687897,\n",
              "   0.13855375349521637,\n",
              "   0.1259101778268814,\n",
              "   0.10252997279167175,\n",
              "   0.08687016367912292,\n",
              "   0.06893694400787354,\n",
              "   0.04396950826048851]},\n",
              " {'sequence': '[1712.04020] Detecting Qualia in Natural and Artificial Agents ',\n",
              "  'labels': ['responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy'],\n",
              "  'scores': [0.2595304250717163,\n",
              "   0.17119571566581726,\n",
              "   0.1547441929578781,\n",
              "   0.09763500094413757,\n",
              "   0.09547165036201477,\n",
              "   0.09265856444835663,\n",
              "   0.08329536765813828,\n",
              "   0.04546904191374779]},\n",
              " {'sequence': 'How Do We Treat Non-human Entities? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.5325089693069458,\n",
              "   0.13563618063926697,\n",
              "   0.0857037752866745,\n",
              "   0.06790529191493988,\n",
              "   0.05867017060518265,\n",
              "   0.050831057131290436,\n",
              "   0.03564474359154701,\n",
              "   0.03309978172183037]},\n",
              " {'sequence': \"New Age Neuroethics - What are the ethical challenges that arise from novel forms of human-machine interaction? https://soundcloud.com/21-bioethically-sound/002-new-age-neuroethics [seeking feedback and commentary on podcast]\\r\\n\\r\\nIf neurotechnologies or mentally-enhancing substances become the Viagra of daily functioning and create new benchmarks for productivity, wakefulness, even emotional love, what's going to happen to the fabric of society, the character of our interactions with each another? Will these altered states be genuine reflections of a new-and-improved \\x1cme\\x1d or \\x1cwe\\x1d, or some transient artificially-induced condition that wholly confounds what we inherently value?\",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.2935543358325958,\n",
              "   0.17556588351726532,\n",
              "   0.15790937840938568,\n",
              "   0.09840075671672821,\n",
              "   0.09577392786741257,\n",
              "   0.07297344505786896,\n",
              "   0.05561038479208946,\n",
              "   0.05021184682846069]},\n",
              " {'sequence': 'When Should Machines Make Decisions? - Future of Life Institute ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.4153634011745453,\n",
              "   0.1600363701581955,\n",
              "   0.1495802253484726,\n",
              "   0.10325460880994797,\n",
              "   0.05388164147734642,\n",
              "   0.04909132048487663,\n",
              "   0.03653744235634804,\n",
              "   0.03225502744317055]},\n",
              " {'sequence': 'The Montreal Declaration for a Responsible Development of Artificial Intelligence: a participatory process ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.595077395439148,\n",
              "   0.267947793006897,\n",
              "   0.05022985115647316,\n",
              "   0.025149565190076828,\n",
              "   0.024257855489850044,\n",
              "   0.017681965604424477,\n",
              "   0.011204150505363941,\n",
              "   0.008451458998024464]},\n",
              " {'sequence': \"Scientists' letter to Trump: don't use machine learning to select immigrants \",\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.28399622440338135,\n",
              "   0.21402573585510254,\n",
              "   0.1242154911160469,\n",
              "   0.10849273949861526,\n",
              "   0.0906762033700943,\n",
              "   0.08461631089448929,\n",
              "   0.051268577575683594,\n",
              "   0.04270873963832855]},\n",
              " {'sequence': \"Any interesting machine ethics dilemma that is not the trolley car problem? I'm looking for some machine ethics moral dilemma to have a rich discussion about the different philosophical approaches (utilitarian, deontological, virtue). I want to avoid the overly hyped autonomous vehicle/ trolley car problem, lethal war machines, and sentient AI. Do you have some explains of possible dilemmas with multiple angles? Thanks! \",\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.2830261290073395,\n",
              "   0.23522436618804932,\n",
              "   0.10932817310094833,\n",
              "   0.10823913663625717,\n",
              "   0.09915271401405334,\n",
              "   0.07266755402088165,\n",
              "   0.04791537672281265,\n",
              "   0.044446561485528946]},\n",
              " {'sequence': 'Meet the tech company that wants to make you even more addicted to your phone ',\n",
              "  'labels': ['transparency',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.22686372697353363,\n",
              "   0.22032177448272705,\n",
              "   0.20033864676952362,\n",
              "   0.18283048272132874,\n",
              "   0.058114103972911835,\n",
              "   0.046088915318250656,\n",
              "   0.03330636024475098,\n",
              "   0.03213600441813469]},\n",
              " {'sequence': 'FLI video on the dangers of AI weapons ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.39072301983833313,\n",
              "   0.22287359833717346,\n",
              "   0.16280993819236755,\n",
              "   0.08541811257600784,\n",
              "   0.037911053746938705,\n",
              "   0.0373663455247879,\n",
              "   0.03258730471134186,\n",
              "   0.030310653150081635]},\n",
              " {'sequence': 'Algorithmic Decision-Making Based on Machine Learning from Big Data: Can Transparency Restore Accountability? ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3140123188495636,\n",
              "   0.27922266721725464,\n",
              "   0.24648194015026093,\n",
              "   0.05921963229775429,\n",
              "   0.03886996582150459,\n",
              "   0.03280382975935936,\n",
              "   0.01930740661919117,\n",
              "   0.010082202032208443]},\n",
              " {'sequence': \"It's Not Bias When Artificial Intelligence Tells Us Something True and Uncomfortable \",\n",
              "  'labels': ['fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.24244049191474915,\n",
              "   0.18943539261817932,\n",
              "   0.1732337921857834,\n",
              "   0.14318107068538666,\n",
              "   0.11420056968927383,\n",
              "   0.05890744552016258,\n",
              "   0.05416480079293251,\n",
              "   0.024436455219984055]},\n",
              " {'sequence': '(Paywalled) defense of the moral permissibility of AI weapons ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'privacy'],\n",
              "  'scores': [0.2680334746837616,\n",
              "   0.23255634307861328,\n",
              "   0.11560773849487305,\n",
              "   0.10545283555984497,\n",
              "   0.07795913517475128,\n",
              "   0.07588902860879898,\n",
              "   0.06588225811719894,\n",
              "   0.05861924961209297]},\n",
              " {'sequence': \"If we can't prevent buggy software from reaching production, how can we prevent buggy AI from reaching production? \",\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.4266936779022217,\n",
              "   0.14506448805332184,\n",
              "   0.11444135010242462,\n",
              "   0.09372339397668839,\n",
              "   0.0833168774843216,\n",
              "   0.06494008004665375,\n",
              "   0.046728573739528656,\n",
              "   0.02509152889251709]},\n",
              " {'sequence': 'AI safety research survey. Please help for my school project! ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.37878483533859253,\n",
              "   0.2335738092660904,\n",
              "   0.11672116070985794,\n",
              "   0.09110283106565475,\n",
              "   0.06388194859027863,\n",
              "   0.046629197895526886,\n",
              "   0.038514841347932816,\n",
              "   0.03079139068722725]},\n",
              " {'sequence': 'The AI Initiative - Civic Debate on the Governance of AI, hosted by Harvard ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.49623560905456543,\n",
              "   0.15935547649860382,\n",
              "   0.13828624784946442,\n",
              "   0.05743013322353363,\n",
              "   0.05066874623298645,\n",
              "   0.04477766156196594,\n",
              "   0.030467497184872627,\n",
              "   0.022778639569878578]},\n",
              " {'sequence': 'AI Now Institute at NYU is hiring postdocs who receive their PhDs in 2016-2018 ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3583087623119354,\n",
              "   0.21164852380752563,\n",
              "   0.12671341001987457,\n",
              "   0.11115097999572754,\n",
              "   0.06294956803321838,\n",
              "   0.052651893347501755,\n",
              "   0.048986297100782394,\n",
              "   0.027590572834014893]},\n",
              " {'sequence': 'Deepmind launches ethics and society research unit ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.346653014421463,\n",
              "   0.21799762547016144,\n",
              "   0.12161489576101303,\n",
              "   0.09487134963274002,\n",
              "   0.07509560883045197,\n",
              "   0.06629008054733276,\n",
              "   0.05446485057473183,\n",
              "   0.023012539371848106]},\n",
              " {'sequence': 'Can AI Remain Safe as Companies Race to Develop It? - Future of Life Institute ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3559311628341675,\n",
              "   0.1790200173854828,\n",
              "   0.13938932120800018,\n",
              "   0.11244063079357147,\n",
              "   0.05664727836847305,\n",
              "   0.056259635835886,\n",
              "   0.055038031190633774,\n",
              "   0.045273903757333755]},\n",
              " {'sequence': 'Social Choice Ethics in Artificial Intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3171751797199249,\n",
              "   0.12728704512119293,\n",
              "   0.12472831457853317,\n",
              "   0.11845129728317261,\n",
              "   0.10806618630886078,\n",
              "   0.09567923098802567,\n",
              "   0.0652817040681839,\n",
              "   0.04333105310797691]},\n",
              " {'sequence': 'FATML 2017 papers ',\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.236139714717865,\n",
              "   0.2356119006872177,\n",
              "   0.15440477430820465,\n",
              "   0.13629783689975739,\n",
              "   0.08922640234231949,\n",
              "   0.08876899629831314,\n",
              "   0.030174581333994865,\n",
              "   0.029375750571489334]},\n",
              " {'sequence': 'New AAAI/ACM Conference on AI, Ethics, and Society (email sent to AAAI mailing list last week)\\r\\n\\r\\nAAAI/ACM Conference on AI, Ethics, and Society\\r\\n\\r\\nFebruary 2-3, 2018 \\r\\n\\r\\nNew Orleans, USA\\r\\n\\r\\nhttp://www.aies-conference.com/\\r\\n\\r\\nAs AI is becoming more pervasive in our life, its impact on society is more significant and concerns and issues are raised regarding aspects such as value alignment, data bias and data policy, regulations, and workforce displacement. Only a multi-disciplinary and multi-stakeholder effort can find the best ways to address these concerns, including experts of various disciplines, such as AI, computer science, ethics, philosophy, economics, sociology, psychology, law, history, and politics. In order to address these issues in a scientific context, AAAI and ACM have joined forces to start a new conference, the AAAI/ACM Conference on AI, Ethics, and Society. \\r\\n\\r\\nThe first edition of this conference will be co-located with AAAI-18 on February 2-3, 2018 in New Orleans, USA. The program of the conference will include peer-reviewed paper presentations, invited talks, panels, and working sessions. \\r\\n\\r\\nThe conference welcomes contributions on a broad set of topics, included the following ones:\\r\\n\\r\\n* Building ethical AI \\r\\n* Value alignment\\r\\n* Moral machine decision making\\r\\n* Trust and explanations in AI systems\\r\\n* Fairness and Transparency in AI systems\\r\\n* Ethical design and development of AI systems\\r\\n* AI for social good\\r\\n* Human-level AI\\r\\n* Controlling AI\\r\\n* Impact of AI on workforce\\r\\n* Societal impact of AI\\r\\n* AI and law\\r\\n\\r\\nSubmitted papers should adopt a scientific approach to address any questions related to the above topics. Moreover, they should clearly establish the research contribution, its relevance, and its relation to prior research. All submissions must be made in the appropriate format, and within the specified length limit; details and a LaTeX template can be found at the conference web site.\\r\\n\\r\\nWe solicit papers (pdf file) of up to 6 pages + 1 page for references (AAAI format), submitted through the Easychair system.\\r\\n\\r\\nWe expect papers submitted by researchers of several disciplines (AI, computer science, philosophy, economics, law, and others). The program committee includes members that are experts in all the relevant areas, to ensure appropriate review of papers.',\n",
              "  'labels': ['fairness',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.19664381444454193,\n",
              "   0.16928742825984955,\n",
              "   0.1671050786972046,\n",
              "   0.16386891901493073,\n",
              "   0.08529537171125412,\n",
              "   0.08320833742618561,\n",
              "   0.07193442434072495,\n",
              "   0.06265661865472794]},\n",
              " {'sequence': \"Full version of the German ethics commission's report on autonomous vehicles \",\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3913485109806061,\n",
              "   0.21632839739322662,\n",
              "   0.17299118638038635,\n",
              "   0.07250472158193588,\n",
              "   0.06243002787232399,\n",
              "   0.04075758159160614,\n",
              "   0.02823963388800621,\n",
              "   0.01539993193000555]},\n",
              " {'sequence': \"Help needed for school project Hello! I am a student working on a design/research project on the topic of AI. What I need help with is outlining where there is a need that I can fill with this project. In simple terms, the way I have framed my problem for now is that as computer scientists are constantly working towards further AI development we need to find a way to mitigate the potential risks and ethical problems that could arise from an AGI/ASI.  \\r\\n&amp;nbsp;\\r\\n\\r\\nThe types of solutions I have been coming up with so far (keep in mind this is a design project at heart, with heavy research involved) have been based around the idea of either an ethical watchdog group, an international consortium (similar to CERN or The Manhattan Project), or some sort of conference where people would come together to talk about these issues. My only problem is it seems like all of these things exist in some form already.  \\r\\n&amp;nbsp;\\r\\n\\r\\nSo my questions to you would be:  \\r\\nCan you think of some way that I could narrow down the problem I am trying to address to something more specific, so that it is easier to tackle?  \\r\\n&amp;nbsp;\\r\\n\\r\\nCan you think of anything that is currently needed that could help work towards solving the current issues with AI ethics? Is there a set of guidelines that needs to be made? Or some kind of metric or tracking website where we can see how AI development is progressing, what milestones we've passed, and what ethical issues we still need to solve? Or maybe there should be an educational ad campaign that shines a light on these developments/issues to the public? I'm just throwing random ideas out there but if any of you have insights into something else (or think any of my directions sound like they could work) please let me know!  \\r\\n&amp;nbsp;\\r\\n\\r\\nYour general thoughts on what needs to be addressed on this topic would be greatly appreciated!  \\r\\n&amp;nbsp;\\r\\n\\r\\nThanks :)\",\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2335151880979538,\n",
              "   0.20611199736595154,\n",
              "   0.1220259815454483,\n",
              "   0.12087791413068771,\n",
              "   0.11744829267263412,\n",
              "   0.08977610617876053,\n",
              "   0.061697084456682205,\n",
              "   0.04854736104607582]},\n",
              " {'sequence': \"Study That Claimed AI Could Determine a Person's Sexuality Is Under Ethical Review \",\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'justice'],\n",
              "  'scores': [0.2573537528514862,\n",
              "   0.24125035107135773,\n",
              "   0.2202153205871582,\n",
              "   0.07100388407707214,\n",
              "   0.060223594307899475,\n",
              "   0.0598122701048851,\n",
              "   0.05821472778916359,\n",
              "   0.031926024705171585]},\n",
              " {'sequence': 'Robots need civil rights, too - The Boston Globe ',\n",
              "  'labels': ['responsibility',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3290334641933441,\n",
              "   0.2640538513660431,\n",
              "   0.22981801629066467,\n",
              "   0.05374149978160858,\n",
              "   0.049478065222501755,\n",
              "   0.030111657455563545,\n",
              "   0.029582837596535683,\n",
              "   0.014180557802319527]},\n",
              " {'sequence': 'Inherent Trade-Offs in the Fair Determination of Risk Scores ',\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.6421191692352295,\n",
              "   0.1097312644124031,\n",
              "   0.07356225699186325,\n",
              "   0.0571475625038147,\n",
              "   0.05084807053208351,\n",
              "   0.03667193651199341,\n",
              "   0.017981640994548798,\n",
              "   0.011938103474676609]},\n",
              " {'sequence': 'What the Present Debate About Autonomous Weapons is Getting Wrong ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.252885103225708,\n",
              "   0.20186014473438263,\n",
              "   0.13703732192516327,\n",
              "   0.13649967312812805,\n",
              "   0.10068580508232117,\n",
              "   0.08787943422794342,\n",
              "   0.04617497697472572,\n",
              "   0.036977529525756836]},\n",
              " {'sequence': 'On the Matter of Robot Minds ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.25570085644721985,\n",
              "   0.2500767111778259,\n",
              "   0.13744038343429565,\n",
              "   0.10476171970367432,\n",
              "   0.07688172906637192,\n",
              "   0.06768511980772018,\n",
              "   0.05888516083359718,\n",
              "   0.048568323254585266]},\n",
              " {'sequence': 'A.I. \\x18Bias\\x19 Doesn\\x19t Mean What Journalists Say it Means ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.3721391260623932,\n",
              "   0.14898817241191864,\n",
              "   0.10859119147062302,\n",
              "   0.09834911674261093,\n",
              "   0.07610068470239639,\n",
              "   0.07462958991527557,\n",
              "   0.06397050619125366,\n",
              "   0.05723166838288307]},\n",
              " {'sequence': 'Alien Intelligences and discriminatory algorithms ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.5457804203033447,\n",
              "   0.4028836786746979,\n",
              "   0.020150842145085335,\n",
              "   0.01313338428735733,\n",
              "   0.005856606177985668,\n",
              "   0.0045897988602519035,\n",
              "   0.0045422641560435295,\n",
              "   0.0030629450920969248]},\n",
              " {'sequence': 'UK Parliament request for information on the implications of artificial intelligence (deadline September 6) ',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.29044440388679504,\n",
              "   0.2651236951351166,\n",
              "   0.2135619968175888,\n",
              "   0.0666659027338028,\n",
              "   0.06219695881009102,\n",
              "   0.04774915799498558,\n",
              "   0.027915621176362038,\n",
              "   0.026342252269387245]},\n",
              " {'sequence': 'Is This all True about AI? ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.29909345507621765,\n",
              "   0.21480368077754974,\n",
              "   0.135750874876976,\n",
              "   0.13086490333080292,\n",
              "   0.0891580581665039,\n",
              "   0.051696136593818665,\n",
              "   0.04205591604113579,\n",
              "   0.03657693788409233]},\n",
              " {'sequence': 'Nothing Wrong With AI Weapons ',\n",
              "  'labels': ['justice',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.23646658658981323,\n",
              "   0.21238544583320618,\n",
              "   0.1743655949831009,\n",
              "   0.12578092515468597,\n",
              "   0.11393092572689056,\n",
              "   0.05823025852441788,\n",
              "   0.040691304951906204,\n",
              "   0.03814893588423729]},\n",
              " {'sequence': \"German ethics commission's report on automated driving \",\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2953936457633972,\n",
              "   0.2644489109516144,\n",
              "   0.13860997557640076,\n",
              "   0.12384536862373352,\n",
              "   0.08457432687282562,\n",
              "   0.051883503794670105,\n",
              "   0.02340283989906311,\n",
              "   0.017841443419456482]},\n",
              " {'sequence': 'Iwad Rahwan: \"What moral decisions should driverless cars make?\" (TED) ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4372842013835907,\n",
              "   0.208234965801239,\n",
              "   0.17651155591011047,\n",
              "   0.047836318612098694,\n",
              "   0.04612438380718231,\n",
              "   0.03659340739250183,\n",
              "   0.025081537663936615,\n",
              "   0.022333642467856407]},\n",
              " {'sequence': 'AI Ethics Panel Discussion + Happy Hour this Thursday in SF ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.24144691228866577,\n",
              "   0.20133209228515625,\n",
              "   0.16083332896232605,\n",
              "   0.12985096871852875,\n",
              "   0.11644534766674042,\n",
              "   0.07381561398506165,\n",
              "   0.04646262899041176,\n",
              "   0.029813120141625404]},\n",
              " {'sequence': \"A reply to Thomas Metzinger's BAAN thought experiment \\x13 Foundational Research Institute \",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.4950779378414154,\n",
              "   0.12393002212047577,\n",
              "   0.09672721475362778,\n",
              "   0.08754634112119675,\n",
              "   0.06700040400028229,\n",
              "   0.049348555505275726,\n",
              "   0.04556826129555702,\n",
              "   0.034801263362169266]},\n",
              " {'sequence': 'Why Elon Musk is Right About AI Regulation ',\n",
              "  'labels': ['responsibility',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.379165381193161,\n",
              "   0.2690448462963104,\n",
              "   0.10371656715869904,\n",
              "   0.09808168560266495,\n",
              "   0.07362896203994751,\n",
              "   0.042069122195243835,\n",
              "   0.017870530486106873,\n",
              "   0.016422973945736885]},\n",
              " {'sequence': 'My interview with James Barrat, author of Our Final Invention: AI and the End of the Human Era ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2452412247657776,\n",
              "   0.23236356675624847,\n",
              "   0.16566340625286102,\n",
              "   0.12481017410755157,\n",
              "   0.08999770134687424,\n",
              "   0.057087577879428864,\n",
              "   0.045942164957523346,\n",
              "   0.03889419138431549]},\n",
              " {'sequence': \"A visual narrative of Y. N. Harari's book, Homo Deus, about humans as rulers of the world and the new competition, electronic algorithms and artificial intelligence. \",\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.24192553758621216,\n",
              "   0.16448479890823364,\n",
              "   0.14390581846237183,\n",
              "   0.1331891566514969,\n",
              "   0.11114317923784256,\n",
              "   0.09096019715070724,\n",
              "   0.060265425592660904,\n",
              "   0.05412587895989418]},\n",
              " {'sequence': 'Thomas Metzinger - Benevolent Artificial Anti-Natalism (BAAN) ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.314799040555954,\n",
              "   0.20531435310840607,\n",
              "   0.1534288078546524,\n",
              "   0.09580032527446747,\n",
              "   0.06363233178853989,\n",
              "   0.06185169890522957,\n",
              "   0.05829779803752899,\n",
              "   0.046875640749931335]},\n",
              " {'sequence': 'Interviewing James Barrat, author of Our Final Invention, tomorrow. What is one question that you would want to ask him? ',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.17087049782276154,\n",
              "   0.16885435581207275,\n",
              "   0.1588490903377533,\n",
              "   0.15685366094112396,\n",
              "   0.11352773755788803,\n",
              "   0.10728758573532104,\n",
              "   0.06796746701002121,\n",
              "   0.05578954890370369]},\n",
              " {'sequence': 'Stoic Ethics for Artificial Agents ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'transparency'],\n",
              "  'scores': [0.3939189612865448,\n",
              "   0.16490276157855988,\n",
              "   0.13197533786296844,\n",
              "   0.092598095536232,\n",
              "   0.08033989369869232,\n",
              "   0.0665639266371727,\n",
              "   0.040191542357206345,\n",
              "   0.029509492218494415]},\n",
              " {'sequence': 'The Risks of Artificial Intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3725687861442566,\n",
              "   0.1514376401901245,\n",
              "   0.1358586549758911,\n",
              "   0.10697067528963089,\n",
              "   0.06667071580886841,\n",
              "   0.06565991044044495,\n",
              "   0.054234784096479416,\n",
              "   0.04659884423017502]},\n",
              " {'sequence': 'The 6 TED Talks that will change how you perceive AI dominance ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.2341715693473816,\n",
              "   0.22859661281108856,\n",
              "   0.17062871158123016,\n",
              "   0.1569603532552719,\n",
              "   0.0745791345834732,\n",
              "   0.05454157292842865,\n",
              "   0.04346807301044464,\n",
              "   0.03705388680100441]},\n",
              " {'sequence': 'Keeping up with AI Breakthroughs ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.42817437648773193,\n",
              "   0.17040234804153442,\n",
              "   0.10489507019519806,\n",
              "   0.09177202731370926,\n",
              "   0.06926558166742325,\n",
              "   0.05699295923113823,\n",
              "   0.04405318945646286,\n",
              "   0.03444445878267288]},\n",
              " {'sequence': 'Five Thirty Eight: Technology Is Biased Too. How Do We Fix It? ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.9295551180839539,\n",
              "   0.026142841205000877,\n",
              "   0.013000399805605412,\n",
              "   0.00922408513724804,\n",
              "   0.007629119325429201,\n",
              "   0.006079338490962982,\n",
              "   0.0057458714582026005,\n",
              "   0.0026232092641294003]},\n",
              " {'sequence': 'Google AI Experiments: Some of the coolest apps out there! ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.28253495693206787,\n",
              "   0.13242198526859283,\n",
              "   0.1305633932352066,\n",
              "   0.11952666938304901,\n",
              "   0.11511458456516266,\n",
              "   0.0962003841996193,\n",
              "   0.07370376586914062,\n",
              "   0.049934305250644684]},\n",
              " {'sequence': '8-page article on AI ethics and safety, translated from a Chinese magazine ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3169149160385132,\n",
              "   0.2248837798833847,\n",
              "   0.18640775978565216,\n",
              "   0.08406654000282288,\n",
              "   0.07537157088518143,\n",
              "   0.04975678771734238,\n",
              "   0.041047606617212296,\n",
              "   0.02155100740492344]},\n",
              " {'sequence': 'Could machines have become self-aware without our knowing it? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2808884084224701,\n",
              "   0.21068784594535828,\n",
              "   0.17866528034210205,\n",
              "   0.12442468851804733,\n",
              "   0.09739107638597488,\n",
              "   0.03871210664510727,\n",
              "   0.034953318536281586,\n",
              "   0.03427727892994881]},\n",
              " {'sequence': 'AI: A luxury or a must-have? That is the real question. ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.21373967826366425,\n",
              "   0.13137495517730713,\n",
              "   0.12436453253030777,\n",
              "   0.11533313244581223,\n",
              "   0.10962306708097458,\n",
              "   0.10398712009191513,\n",
              "   0.10313161462545395,\n",
              "   0.09844590723514557]},\n",
              " {'sequence': 'Journal of Science Fiction and Philosophy ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.24081987142562866,\n",
              "   0.15969067811965942,\n",
              "   0.12719528377056122,\n",
              "   0.12506017088890076,\n",
              "   0.09978127479553223,\n",
              "   0.08541319519281387,\n",
              "   0.08189340680837631,\n",
              "   0.08014613389968872]},\n",
              " {'sequence': 'Consciousness and the Brain, Part One: Possibilities Within Microtubules... ',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.19185970723628998,\n",
              "   0.17145079374313354,\n",
              "   0.16082105040550232,\n",
              "   0.1452784240245819,\n",
              "   0.1278991848230362,\n",
              "   0.08322134613990784,\n",
              "   0.06228213384747505,\n",
              "   0.05718740075826645]},\n",
              " {'sequence': 'Fairness Testing: Testing Software for Discrimination ',\n",
              "  'labels': ['fairness',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'privacy'],\n",
              "  'scores': [0.5473721027374268,\n",
              "   0.17134104669094086,\n",
              "   0.13935719430446625,\n",
              "   0.059484489262104034,\n",
              "   0.04499620944261551,\n",
              "   0.024752339348196983,\n",
              "   0.009009313769638538,\n",
              "   0.003687263233587146]},\n",
              " {'sequence': 'What Do Buddhist Monks Think of the Trolley Problem? ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.3330742418766022,\n",
              "   0.23117776215076447,\n",
              "   0.1794975996017456,\n",
              "   0.07376924157142639,\n",
              "   0.054515209048986435,\n",
              "   0.05376948043704033,\n",
              "   0.04801342263817787,\n",
              "   0.0261831134557724]},\n",
              " {'sequence': \"Philosophy chat for quality conversation Hi, I run a discord server dedicated to discussing philosophy.\\r\\nThe member base ranges from absurdists, empiricists, nihilists, objectivists, platonists, egoists, anarchists, and anything in between.\\r\\nThe point of the chat is to discuss ideas in good faith. People who come around posting woo and then refuse to discuss it, are not welcome.\\r\\n\\r\\nI hope I'm not breaking any rules of the subreddit by posting this as this is relevant to philosophy, and the format of a chat is so different from Reddit's forum style that they aren't in direct competition.\\r\\n\\r\\nTake a look if it sounds interesting:\\r\\n\\r\\nhttps://discord.gg/ueCUWdz\",\n",
              "  'labels': ['accountability',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'justice'],\n",
              "  'scores': [0.19605518877506256,\n",
              "   0.17466330528259277,\n",
              "   0.13441288471221924,\n",
              "   0.12867602705955505,\n",
              "   0.12384890019893646,\n",
              "   0.10239648818969727,\n",
              "   0.07343988120555878,\n",
              "   0.06650731712579727]},\n",
              " {'sequence': 'Dynamic pricing - and should AI be granted \\x1clegal personhood\\x1d? - Future Tense ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.32522669434547424,\n",
              "   0.16295519471168518,\n",
              "   0.15380826592445374,\n",
              "   0.11480017751455307,\n",
              "   0.08842257410287857,\n",
              "   0.0647604912519455,\n",
              "   0.05130796134471893,\n",
              "   0.03871867060661316]},\n",
              " {'sequence': 'Will AI unleash human potential or enslave us? Please take our survey and share your thoughts. ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3116709887981415,\n",
              "   0.227443128824234,\n",
              "   0.11919460445642471,\n",
              "   0.11607570946216583,\n",
              "   0.06532007455825806,\n",
              "   0.06376946717500687,\n",
              "   0.05786709859967232,\n",
              "   0.03865892440080643]},\n",
              " {'sequence': 'When Will Robots Deserve Human Rights? ',\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'privacy'],\n",
              "  'scores': [0.25297871232032776,\n",
              "   0.2524930536746979,\n",
              "   0.15220163762569427,\n",
              "   0.15075337886810303,\n",
              "   0.0713721364736557,\n",
              "   0.05667805299162865,\n",
              "   0.042373597621917725,\n",
              "   0.021149415522813797]},\n",
              " {'sequence': 'Can we design machines to make ethical decisions? Tom Chatfield, Aeon Essays ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3424542546272278,\n",
              "   0.16166120767593384,\n",
              "   0.15607696771621704,\n",
              "   0.10265199095010757,\n",
              "   0.08992922306060791,\n",
              "   0.06599386781454086,\n",
              "   0.0502166748046875,\n",
              "   0.03101581707596779]},\n",
              " {'sequence': 'Press Failure: The Guardian\\x19s \\x1cMeet Erica\\x1d ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.29566192626953125,\n",
              "   0.2538944482803345,\n",
              "   0.1307792365550995,\n",
              "   0.10520178079605103,\n",
              "   0.06491123139858246,\n",
              "   0.06402288377285004,\n",
              "   0.05710838735103607,\n",
              "   0.02842012234032154]},\n",
              " {'sequence': 'Creating robots capable of moral reasoning is like parenting \\x13 Regina Rini ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.6790786385536194,\n",
              "   0.12913483381271362,\n",
              "   0.06103735417127609,\n",
              "   0.04615582153201103,\n",
              "   0.03553365543484688,\n",
              "   0.018814684823155403,\n",
              "   0.01677831821143627,\n",
              "   0.013466614298522472]},\n",
              " {'sequence': \"The Economics of Artificial Intelligence I have spent a considerable amount of time considering AI and its affects on the economy.  It seems a given that robotics well replace the vast majority of low skilled work in the next two decades and it seems to be a given that a lot of high skilled jobs having to do with pattern recognition and statistics will be eliminated as well.  \\r\\n\\r\\nIt is my hypithosis that a lot of high intellect jobs or shall we say specialized career fields will be made more generalized due to advances in AI's ability to handle large portions of complex tasks.  \\r\\n\\r\\nWhat I am interested in is opinions on what this will mean for society.  Does it mean larger groups of people will have an adequate ability to compete for an ever shrinking number of jobs?  Does it mean only the cognitive elite will be in a position to work?  And in either scenerio what happens to those who are left without prospects.\",\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.15731406211853027,\n",
              "   0.15530820190906525,\n",
              "   0.1466565579175949,\n",
              "   0.14553187787532806,\n",
              "   0.11426423490047455,\n",
              "   0.1107751801609993,\n",
              "   0.08853110671043396,\n",
              "   0.08161874860525131]},\n",
              " {'sequence': 'AI programs exhibit racial and gender biases, research reveals ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.7876488566398621,\n",
              "   0.1409980058670044,\n",
              "   0.035241421312093735,\n",
              "   0.015143046155571938,\n",
              "   0.008476114831864834,\n",
              "   0.004583996254950762,\n",
              "   0.004344885237514973,\n",
              "   0.0035636937245726585]},\n",
              " {'sequence': '\"The United episode gets at a more general problem with algorithms. Even if the selection of seat loser is \\x1ctruly random,\\x1d it will not always look random to the outside world.\" ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.2585163712501526,\n",
              "   0.21295545995235443,\n",
              "   0.1067471131682396,\n",
              "   0.10481947660446167,\n",
              "   0.10433875769376755,\n",
              "   0.09037390351295471,\n",
              "   0.08901365101337433,\n",
              "   0.03323523327708244]},\n",
              " {'sequence': 'AI that can kill? Military takes a pass ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.42965012788772583,\n",
              "   0.2461167275905609,\n",
              "   0.11337553709745407,\n",
              "   0.07139290869235992,\n",
              "   0.057455386966466904,\n",
              "   0.04306741803884506,\n",
              "   0.021284127607941628,\n",
              "   0.017657723277807236]},\n",
              " {'sequence': '[Podcast] Philosopher Prof. Sinnott-Armstrong on AI ethics (cars, weapons, etc.) ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.33846020698547363,\n",
              "   0.18190927803516388,\n",
              "   0.12865972518920898,\n",
              "   0.12088383734226227,\n",
              "   0.06634521484375,\n",
              "   0.06449545174837112,\n",
              "   0.05402502045035362,\n",
              "   0.04522129148244858]},\n",
              " {'sequence': \"If robots were to exist, fully sentient; do you think Buddhist teachings would help them grasp the concept of life more, possibly be even beneficial in general to their and our way of life? Knowing some things about Buddhism, restricting some mostly religious teachings; do you think it could be beneficial into sentient robots knowing more about life, suffering, and human behavior in a logical and emotional way. \\r\\nPersonally, if such a race of robot were to co-exist with us, the idea interests me as I wonder if an artificial being could seek a more enlightened state of being. Could it spell more of an understanding of consciousness and what is needed to truly be happy? I'd like to hear some opinions about it, and learn more about it.\",\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.21323737502098083,\n",
              "   0.1636374443769455,\n",
              "   0.14940890669822693,\n",
              "   0.1132344901561737,\n",
              "   0.10932739078998566,\n",
              "   0.10459963977336884,\n",
              "   0.07669440656900406,\n",
              "   0.06986033171415329]},\n",
              " {'sequence': 'On Artificial Intelligence and the Public Good: Responding to a Request for Information from the Office of Science and Technology Policy ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3155619204044342,\n",
              "   0.31431683897972107,\n",
              "   0.19721125066280365,\n",
              "   0.049917589873075485,\n",
              "   0.04610980302095413,\n",
              "   0.03661122918128967,\n",
              "   0.021421439945697784,\n",
              "   0.018849952146410942]},\n",
              " {'sequence': 'China calls for AI funding, policies to surpass US ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.557765007019043,\n",
              "   0.1480080783367157,\n",
              "   0.0949096605181694,\n",
              "   0.07564407587051392,\n",
              "   0.04191949591040611,\n",
              "   0.0417080894112587,\n",
              "   0.021202264353632927,\n",
              "   0.01884334348142147]},\n",
              " {'sequence': 'Combat footage of ISIS drone dropping a bomb on a Humvee ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.3729787766933441,\n",
              "   0.2002711445093155,\n",
              "   0.18386510014533997,\n",
              "   0.07544158399105072,\n",
              "   0.05469101667404175,\n",
              "   0.05450201779603958,\n",
              "   0.03216021880507469,\n",
              "   0.026090145111083984]},\n",
              " {'sequence': 'Fairness as a Program Property ',\n",
              "  'labels': ['fairness',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.6454119086265564,\n",
              "   0.3014335334300995,\n",
              "   0.025289496406912804,\n",
              "   0.008242870680987835,\n",
              "   0.006541742943227291,\n",
              "   0.006386351305991411,\n",
              "   0.00405059102922678,\n",
              "   0.002643541432917118]},\n",
              " {'sequence': 'Do Robots Deserve Rights? What if Machines Become Conscious? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.29954540729522705,\n",
              "   0.22081981599330902,\n",
              "   0.130615696310997,\n",
              "   0.10312628746032715,\n",
              "   0.09667801111936569,\n",
              "   0.061993177980184555,\n",
              "   0.05128630995750427,\n",
              "   0.03593529015779495]},\n",
              " {'sequence': \"r/philosophy AMA: I'm David Chalmers, philosopher interested in consciousness, technology, and many other things. AMA. \",\n",
              "  'labels': ['accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'responsibility',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'fairness'],\n",
              "  'scores': [0.20955759286880493,\n",
              "   0.200529083609581,\n",
              "   0.13418328762054443,\n",
              "   0.1293138861656189,\n",
              "   0.10085756331682205,\n",
              "   0.08538535237312317,\n",
              "   0.07319850474596024,\n",
              "   0.06697475910186768]},\n",
              " {'sequence': \"What areas of AI are relevant to understanding AI consciousness? I'm having a hard time figuring out which aspects of AI would be helpful for answering questions 10+ years down the line about AI systems being sentient. What exactly should one study? Cutting edge machine learning? Reinforcement learning?\",\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.20909073948860168,\n",
              "   0.1815468817949295,\n",
              "   0.15202417969703674,\n",
              "   0.14203576743602753,\n",
              "   0.0916980504989624,\n",
              "   0.08415962755680084,\n",
              "   0.0812004804611206,\n",
              "   0.05824427679181099]},\n",
              " {'sequence': 'AMA from philosopher S. Matthew Liao on rights, moral status and the future of AI ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.31939542293548584,\n",
              "   0.17733155190944672,\n",
              "   0.12230756133794785,\n",
              "   0.09922220557928085,\n",
              "   0.08867689967155457,\n",
              "   0.08201999217271805,\n",
              "   0.07128875702619553,\n",
              "   0.03975759074091911]},\n",
              " {'sequence': 'Google\\'s new AI has learned to become \"highly aggressive\" in stressful situations ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.47659870982170105,\n",
              "   0.19661860167980194,\n",
              "   0.12999284267425537,\n",
              "   0.05902191624045372,\n",
              "   0.04926813766360283,\n",
              "   0.037002887576818466,\n",
              "   0.03164706006646156,\n",
              "   0.019849801436066628]},\n",
              " {'sequence': 'Report lambasts signature-based detection as unfit for purpose and AI is the future, while others defend it as highly effective against most threats. ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.30091461539268494,\n",
              "   0.20356479287147522,\n",
              "   0.11768147349357605,\n",
              "   0.10816803574562073,\n",
              "   0.09173379093408585,\n",
              "   0.08322632312774658,\n",
              "   0.061409056186676025,\n",
              "   0.03330190107226372]},\n",
              " {'sequence': '[X-post from /r/machinelearning] An Idea on Machine Ethics Disclaimer: I\\x19m not an AI researcher, just someone interested in the field.\\r\\n\\r\\nI\\x19ve had an idea about how to align intelligent AI programs\\x19 goals with our human goals:\\r\\n\\r\\nThe problem is simple: Say you have some sort of software AI agent. The agent has a goal (or goals) mandated by its creator(s), and makes decisions on actions to take that would further the goal(s). Whether or not it can carry out those actions *immediately* or *directly* is irrelevant; for now, we\\x19re focusing on the agent\\x19s decisions, since its actions result from them. How do the creators capture the nuance and conditions of their goals, and communicate it to the agent effectively?\\r\\n\\r\\nMy idea: don\\x19t give the agent discrete \\x1cgoals\\x1d at all, at least initially. Instead, give it a network of weighted values to *guide* its decisions.\\r\\n\\r\\nAn example implementation could be created as follows:\\r\\n1. Download a copy of [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download#Where_do_I_get_it.3F), in its entirety.\\r\\n2. Find an article on something you like, or value highly (in my case, \\x1c[fun](https://en.wikipedia.org/wiki/Fun)\\x1d).\\r\\n3. Apply a numerical value to the article. The value should correspond, as best as you can make it, to the ethical value you actually apply to what is described in the article. For example, I could value \\x1cfun\\x1d at 9.5/10. This tells the agent that, when it makes decisions, it should try to promote/encourage/further/increase the thing with a high value. This works in reverse, too: a low value (e.g., 2/10) would tell the agent to prevent/discourage/stop/decrease/eliminate the thing at hand.\\r\\n\\r\\nNOTE: The scale doesn\\x19t really matter here; it could go from -10 to 10, -1 to 1, 0 to 10, 0 to 1, whatever works best for your particular setup. I\\x19m using 0 \\r\\nto 10 in my example because it\\x19s familiar (e.g., movie ratings).\\r\\n\\r\\n4. Repeat steps 2-3 for multiple articles about things you find important to rate for the AI. All of these values are your \\x1cspecified values\\x1d, and they cannot/should not be changed by the agent, at ***least*** not without user permission.\\r\\n5. Specify to the agent that you are, in fact, done inputting specified values.\\r\\n6. The AI agent analyzes the language used in all the articles in the database, paying special attention to links to other articles and the context of those links. It then uses these to calculate \\x1cgenerated values\\x1d, which have the same function as specified values ***except that*** the agent can change them whenever the user changes one or more specified values. This is similar to how Google\\x19s [PageRank](https://en.wikipedia.org/wiki/PageRank#Description) system works, at the base level.\\r\\n\\r\\nIs this a thing out there? I found [this on MIRI\\x19s website](https://intelligence.org/research-guide/#eight), and [this article has the same idea](http://www.recode.net/2016/4/13/11644890/ethics-and-artificial-intelligence-the-moral-compass-of-a-machine), but I don\\x19t know of any implementations of it. Other than that, I\\x19ve found nothing quite like it.\\r\\n\\r\\nThoughts?',\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'responsibility',\n",
              "   'privacy',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'justice'],\n",
              "  'scores': [0.25181514024734497,\n",
              "   0.2011454999446869,\n",
              "   0.11360513418912888,\n",
              "   0.11351928114891052,\n",
              "   0.10755281150341034,\n",
              "   0.07689737528562546,\n",
              "   0.06903337687253952,\n",
              "   0.06643134355545044]},\n",
              " {'sequence': '/u/blaine19 on the myth of long run technological unemployment ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3076012432575226,\n",
              "   0.17070552706718445,\n",
              "   0.16425351798534393,\n",
              "   0.10432986915111542,\n",
              "   0.07013436406850815,\n",
              "   0.06975198537111282,\n",
              "   0.060296475887298584,\n",
              "   0.05292704701423645]},\n",
              " {'sequence': '\"The Ethics of Killing by Remote Control\", radio interview with philosopher Bradley J. Strawser on the ethics of unmanned drones ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.35003745555877686,\n",
              "   0.17474988102912903,\n",
              "   0.16975168883800507,\n",
              "   0.10283210128545761,\n",
              "   0.0595569834113121,\n",
              "   0.049191929399967194,\n",
              "   0.04798554256558418,\n",
              "   0.04589435085654259]},\n",
              " {'sequence': 'Any information on how the hackers are progressing with AI development? Is there any source of news on how the dark side is doing with AI?',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'fairness'],\n",
              "  'scores': [0.3858480751514435,\n",
              "   0.17132747173309326,\n",
              "   0.12385465949773788,\n",
              "   0.09494280815124512,\n",
              "   0.06635133177042007,\n",
              "   0.05387013033032417,\n",
              "   0.051967646926641464,\n",
              "   0.05183791369199753]},\n",
              " {'sequence': 'Ethical AI in Government An interesting and well-documented article about a burning matter: how do governments across the globe integrate ethical principles into AI applications, and why is this necessary in serving and protecting societal values. [I recommend giving it a read here](https://www.botxo.ai/blog/ethical-ai-government/)\\r\\n\\r\\nSnippet:\\r\\n\\r\\n&gt;AI is fertile ground when venturing beyond the frontiers of science and technology. However, like any discovery, it is vital that progress in this field does not come at the expense of humans. Scientific developments are to come hand in hand with relevant legislation and liability, to defend against malicious and harmful intent. It is then and only then that society can thrive from the creations that knowledge and research spawn.',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.37926000356674194,\n",
              "   0.11415716260671616,\n",
              "   0.11137788742780685,\n",
              "   0.10892894864082336,\n",
              "   0.10518230497837067,\n",
              "   0.09131249040365219,\n",
              "   0.05096817761659622,\n",
              "   0.03881305828690529]},\n",
              " {'sequence': 'AI Ethics: The Emperor Has No New Clothes ',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3089822828769684,\n",
              "   0.23915526270866394,\n",
              "   0.13529779016971588,\n",
              "   0.11774169653654099,\n",
              "   0.06874352693557739,\n",
              "   0.04766320437192917,\n",
              "   0.045694127678871155,\n",
              "   0.03672207519412041]},\n",
              " {'sequence': 'IMPORTANT!! A Survey about AI Ethics is being conducted, and WE NEED YOUR OPINION! Please fill this survey, PLEASE! ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.42003950476646423,\n",
              "   0.18427221477031708,\n",
              "   0.17266184091567993,\n",
              "   0.06129659712314606,\n",
              "   0.05292237550020218,\n",
              "   0.049510955810546875,\n",
              "   0.03391312062740326,\n",
              "   0.02538340911269188]},\n",
              " {'sequence': 'Suggestion on anti AI consciousness reading? Looking for other perspectives here and a lot of what I have looked up seems dated. Still value in the older stuff obviously but looking at how arguments have changed.',\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.31821003556251526,\n",
              "   0.14023086428642273,\n",
              "   0.12824563682079315,\n",
              "   0.1261407732963562,\n",
              "   0.08305440843105316,\n",
              "   0.07646609097719193,\n",
              "   0.06860809028148651,\n",
              "   0.059044089168310165]},\n",
              " {'sequence': \"Tell HUD: Algorithms Shouldn't Be an Excuse to Discriminate \",\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.33391401171684265,\n",
              "   0.2906951308250427,\n",
              "   0.11870617419481277,\n",
              "   0.11297239363193512,\n",
              "   0.06326302886009216,\n",
              "   0.03476125746965408,\n",
              "   0.029113374650478363,\n",
              "   0.016574691981077194]},\n",
              " {'sequence': 'Your Software Could Have More Rights Than You: Depending on politics and court judgments, legal loopholes could lead to AI personhood ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'privacy'],\n",
              "  'scores': [0.26169973611831665,\n",
              "   0.17033658921718597,\n",
              "   0.12551765143871307,\n",
              "   0.11677836626768112,\n",
              "   0.11613082140684128,\n",
              "   0.10224676877260208,\n",
              "   0.07995974272489548,\n",
              "   0.027330324053764343]},\n",
              " {'sequence': 'Exploring the Ethics of AI through a perspective of historical analysis ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.37067779898643494,\n",
              "   0.1633872538805008,\n",
              "   0.15188740193843842,\n",
              "   0.10482633858919144,\n",
              "   0.0724511370062828,\n",
              "   0.05416732281446457,\n",
              "   0.04492250829935074,\n",
              "   0.03768019750714302]},\n",
              " {'sequence': 'Learn how we can best program the fuzzy aspects of \\x18humanity\\x19 into machine intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3344603180885315,\n",
              "   0.17430223524570465,\n",
              "   0.13389213383197784,\n",
              "   0.10922668874263763,\n",
              "   0.09511089324951172,\n",
              "   0.06105845421552658,\n",
              "   0.054159123450517654,\n",
              "   0.03779006749391556]},\n",
              " {'sequence': 'Trust, control and personalization through human-centric AI ',\n",
              "  'labels': ['privacy',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.26678192615509033,\n",
              "   0.2523828148841858,\n",
              "   0.21645526587963104,\n",
              "   0.09694187343120575,\n",
              "   0.05943010747432709,\n",
              "   0.056679073721170425,\n",
              "   0.03571969270706177,\n",
              "   0.015609204769134521]},\n",
              " {'sequence': 'UNDERSTANDING SENTIMENT ANALYSIS API  [https://textanalysisapis.home.blog/2019/08/13/understanding-sentiment-analysis-api/](https://textanalysisapis.home.blog/2019/08/13/understanding-sentiment-analysis-api/)',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.23846584558486938,\n",
              "   0.21624267101287842,\n",
              "   0.18977107107639313,\n",
              "   0.0966939777135849,\n",
              "   0.08273722976446152,\n",
              "   0.07918597012758255,\n",
              "   0.055729638785123825,\n",
              "   0.04117361828684807]},\n",
              " {'sequence': 'DOD Sponsors Artificial Intelligence Competition: The military is looking for machine learning solutions that can process and analyze satellite and aerial imagery to assess damage from natural disasters. ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.3362533450126648,\n",
              "   0.18183442950248718,\n",
              "   0.14980050921440125,\n",
              "   0.10917707532644272,\n",
              "   0.08181016147136688,\n",
              "   0.06536602973937988,\n",
              "   0.05067087709903717,\n",
              "   0.02508760616183281]},\n",
              " {'sequence': 'AI Governance by Human Rights-Centred Design, Deliberation and Oversight: An End to Ethics Washing (2019) ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.38737237453460693,\n",
              "   0.21618163585662842,\n",
              "   0.14730896055698395,\n",
              "   0.08638607710599899,\n",
              "   0.06506402045488358,\n",
              "   0.06055399775505066,\n",
              "   0.01972009614109993,\n",
              "   0.01741289533674717]},\n",
              " {'sequence': \"Machines Gone Wrong - an online primer to algorithmic bias [https://greentfrapp.github.io/project-asimov/guide/](https://greentfrapp.github.io/project-asimov/guide/)\\r\\n\\r\\nHi! I built this guide as part of a 3-month final project in my MSc., which involves communicating AI ethics concepts in a relatable manner. I'm still about 3 weeks away from submission and I'll love to hear any feedback!\",\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.8395304083824158,\n",
              "   0.04341411590576172,\n",
              "   0.04205657169222832,\n",
              "   0.03167309984564781,\n",
              "   0.0230720154941082,\n",
              "   0.009293878450989723,\n",
              "   0.006462876684963703,\n",
              "   0.0044970400631427765]},\n",
              " {'sequence': 'An (opensource) Awesome List of Ethics of Artificial Intelligence resources ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.32442083954811096,\n",
              "   0.20662619173526764,\n",
              "   0.15973052382469177,\n",
              "   0.08604401350021362,\n",
              "   0.07866749167442322,\n",
              "   0.06515079736709595,\n",
              "   0.04678787663578987,\n",
              "   0.032572191208601]},\n",
              " {'sequence': 'A flurry of activity among international organisations has resulted in the first agreed inter-governmental statement on the ethics of AI ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.4338306486606598,\n",
              "   0.16862852871418,\n",
              "   0.09664248675107956,\n",
              "   0.08947021514177322,\n",
              "   0.08559921383857727,\n",
              "   0.05038224533200264,\n",
              "   0.04290727153420448,\n",
              "   0.03253941610455513]},\n",
              " {'sequence': 'Step by step, world leaders strive to find consensus on AI development ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.40991052985191345,\n",
              "   0.13690361380577087,\n",
              "   0.12386175245046616,\n",
              "   0.10317222028970718,\n",
              "   0.08085964620113373,\n",
              "   0.06797163188457489,\n",
              "   0.03870849683880806,\n",
              "   0.038612157106399536]},\n",
              " {'sequence': 'AI Ethics \\x13 Too Principled to Fail? (2019) \\x14 Brent Mittelstadt [pdf] ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3464110493659973,\n",
              "   0.17501497268676758,\n",
              "   0.14720205962657928,\n",
              "   0.0927044227719307,\n",
              "   0.08666253089904785,\n",
              "   0.07843811810016632,\n",
              "   0.04098635911941528,\n",
              "   0.032580554485321045]},\n",
              " {'sequence': 'The SBST vs AI ethics I\\'ve recently published a paper ([https://doi.org/10.31235/osf.io/vapje](https://doi.org/10.31235/osf.io/vapje)). The information you would need can be found in the abstract...and in the paper itself. However, here is a brief description of it:  \"*The SBST compresses human motivation down into a simple mathematical system that implies strategies for manipulation and comprehension of another person\\'s motivations by modifying the elements in the proposed system. As such, the SBST will have profound implications for managers, marketers, psychologists, and possibly AI developers.* \"\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nBy turning human motivation into a mathematical system it allows for serious (and specifically-targeted) kinds of manipulation of the populous, as expressed in the strategies section of the paper. However, it also means that a human-like AI can be created with the SBST as its foundation (since it turns human motivations into a mathematical system). I look at this in greater detail in the human-like AI section but that brief description above should give you the gist of what it means. \\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nI am, by no means, an expert on AI but I fear that there could be drastic effects on the field of AI development. One being the development of AI to mirror human motivation with this mathematical system. The second being the development of AI to enact these manipulative strategies against consumers. \\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nThere are already uses of AI in business for things like content curation and ad targeting, but this gives AI developers  a means to directly target a person\\'s motivations with tested strategies. \\r\\n\\r\\nOnce an algorithm like this is perfected, it can model a person\\'s decision making process but not in a \"black box\" manner like deep learning algorithms but in a way that is accessible to the AI developers and any one else who wants to see it. \\r\\n\\r\\nSo, I come to you asking this: \"what should I know about this topic to better handle its implications for AI development and AI ethic, and how can I minimize the damages of its implications while still promoting the paper?\"',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.18277566134929657,\n",
              "   0.17605766654014587,\n",
              "   0.153741717338562,\n",
              "   0.12922830879688263,\n",
              "   0.09966123849153519,\n",
              "   0.09922544658184052,\n",
              "   0.08752818405628204,\n",
              "   0.07178184390068054]},\n",
              " {'sequence': 'Analysis of COMPAS recidivism prediction software by developer, refuting the ProPublica analysis ',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.35833919048309326,\n",
              "   0.2341982126235962,\n",
              "   0.10551704466342926,\n",
              "   0.09793063253164291,\n",
              "   0.0911627933382988,\n",
              "   0.05288784205913544,\n",
              "   0.04193446412682533,\n",
              "   0.018029795959591866]},\n",
              " {'sequence': 'AI for Good, AI for Gender Equality ',\n",
              "  'labels': ['justice',\n",
              "   'fairness',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.584847092628479,\n",
              "   0.26729023456573486,\n",
              "   0.08590611815452576,\n",
              "   0.01976800709962845,\n",
              "   0.01953691989183426,\n",
              "   0.010758155956864357,\n",
              "   0.0061399503611028194,\n",
              "   0.00575351482257247]},\n",
              " {'sequence': '[Internship] Interesting AI ethics internship opportunity Looks like an interesting internship opportunity for folks to get their feet wet with the field of AI ethics \\r\\n\\r\\n[https://montrealethics.ai/srip](https://montrealethics.ai/srip)',\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5158899426460266,\n",
              "   0.10788070410490036,\n",
              "   0.09168674796819687,\n",
              "   0.0894068107008934,\n",
              "   0.06584855169057846,\n",
              "   0.05907965078949928,\n",
              "   0.0416891910135746,\n",
              "   0.028518442064523697]},\n",
              " {'sequence': 'Businesses split over where AI accountability lies ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.4292336404323578,\n",
              "   0.34039613604545593,\n",
              "   0.05459032207727432,\n",
              "   0.0537053681910038,\n",
              "   0.04129014164209366,\n",
              "   0.038880180567502975,\n",
              "   0.020969649776816368,\n",
              "   0.020934561267495155]},\n",
              " {'sequence': '\"Artificial Intelligence: An Evangelical Statement of Principles\" from the Ethics and Religious Liberty Commission of the Southern Baptist Convention ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.318007230758667,\n",
              "   0.18414130806922913,\n",
              "   0.14902877807617188,\n",
              "   0.09084595739841461,\n",
              "   0.08787673711776733,\n",
              "   0.07126110047101974,\n",
              "   0.0600028894841671,\n",
              "   0.03883599489927292]},\n",
              " {'sequence': 'Why banning autonomous killer robots wouldn\\x19t solve anything ',\n",
              "  'labels': ['responsibility',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.31756868958473206,\n",
              "   0.13404490053653717,\n",
              "   0.13324914872646332,\n",
              "   0.12360118329524994,\n",
              "   0.11222337931394577,\n",
              "   0.07946180552244186,\n",
              "   0.06140630692243576,\n",
              "   0.03844451531767845]},\n",
              " {'sequence': 'Drones Have the Potential to Rapidly Improve Our World - If We Allow Them To ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.6541985273361206,\n",
              "   0.07876051217317581,\n",
              "   0.07082270830869675,\n",
              "   0.05601358786225319,\n",
              "   0.053101908415555954,\n",
              "   0.04120086133480072,\n",
              "   0.026980284601449966,\n",
              "   0.01892154850065708]},\n",
              " {'sequence': 'Concordia\\x19s Jason Edward Lewis wants ethical artificial intelligence with an Indigenous worldview: \\x18It\\x19s about building the infrastructure to get us to the future we want\\x19, says the researcher ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.4744081199169159,\n",
              "   0.11484425514936447,\n",
              "   0.09607283771038055,\n",
              "   0.09151677787303925,\n",
              "   0.07518067955970764,\n",
              "   0.05520854890346527,\n",
              "   0.04849788546562195,\n",
              "   0.0442708395421505]},\n",
              " {'sequence': 'One Month, 500,000 Face Scans: How China Is Using A.I. to Profile a Minority In a major ethical leap for the tech world, Chinese start-ups have built algorithms that the government uses to track members of a largely Muslim minority group. ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.21910493075847626,\n",
              "   0.20920291543006897,\n",
              "   0.20794060826301575,\n",
              "   0.13066232204437256,\n",
              "   0.07109363377094269,\n",
              "   0.06650912016630173,\n",
              "   0.05855126306414604,\n",
              "   0.036935221403837204]},\n",
              " {'sequence': '\"AI Ethics\" completely misses the point I\\'m completely flabbergasted about the hype surrounding \"ethical AI\" and encourage anyone to convince me else wise.  Either the entire discussion surrounding AI ethics is by people who are incredibly innocent and lacking of street sense, or there\\'s something I\\'ve completely missed.\\r\\n\\r\\nI thought I\\'d make this post to spell something out: AI will be a tool. Nothing more than that. It\\'s a simple algorithm of gradient descent, reward mapping, or whatever other interesting technique comes into fruition in the next 100 years. Here is the revelation for everyone: The ethics part of AI has nothing to do with AI, it has to do with the humans behind it.\\r\\n\\r\\nThis is the same argument that you can\\'t blame guns, only the shooters. Guns don\\'t kill people. Humans do. Before this degenerates into a bipartisan argument I\\'d like to state a few observations:\\r\\n\\r\\n1) We don\\'t attempt to program ethics into nuclear weapons. Rather we hope the humans that control them are ethical, and our socio-political policy is conducted in a manner that controls the humans that have access to nuclear weapons, not how the nuclear weapons operate themselves. Attempting to program ethics into AI as opposed to the people that design the AI is equally as ridiculous.\\r\\n\\r\\n2) No matter how many \"make believe\" rules or transhumanist mind-masturbation principles you program into a superintelligence, all it will take is one rogue organization, country or terrorist organization to implement basic simple AI algorithms that weren\\'t programmed with those rules in a server farm of GPUs, TPUs, or whatever the flavorful hardware of the future may be.\\r\\n\\r\\n3) This post has nothing to do with the ethics of how humans can program an AI. Of course this is a valid point of public discussion and policy: Ethical humans absolutely should ensure that any AI they program for any purpose that may effect other humans should behave in an ethical manner. Rather, the point of this post is surrounding the laughable optimism that some people seem to have surrounding an \"ethical singularity\". It\\'s absolute common sense that any form of ethical singularity would be more complex than a non-ethical singularity. The simpler things always win. And if it doesn\\'t initially, eventually it will by rogue people/entities. I shouldn\\'t need to elaborate on that truth any further.\\r\\n\\r\\nI had to make this post after seeing the trend of \"how to ensure superintelligence aligns with human morals\" absolutely everywhere and somehow merging itself with serious discussion of how humans can program AIs they have control over for ethical purposes (eg: making sure a self-driving car behaves ethically).\\r\\n\\r\\nIf it isn\\'t obvious to anyone reading this: A true GAI that has the capability of being smarter than us and having free thought wouldn\\'t give a damn about our ethics, and any attempt by us to artificially program it to do so could easily be bypassed by any terrorist, rogue military or perhaps even non-rogue military organization at some point in the future. You cannot stop that anymore than you can stop a terrorist attack occurring sometime in the future. It is inevitable. I\\'m genuinely at a loss regarding how so many people are even bringing this type of discussion up at all?\\r\\n\\r\\nProgramming \\'ethics\\' into any form of superintelligence is a completely ridiculous concept for the reasons I\\'ve stated.',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.32880088686943054,\n",
              "   0.12880021333694458,\n",
              "   0.1205262541770935,\n",
              "   0.10062719881534576,\n",
              "   0.09814167767763138,\n",
              "   0.09642510861158371,\n",
              "   0.07344130426645279,\n",
              "   0.05323738232254982]},\n",
              " {'sequence': \"AWS is ethical about AI but 'we just don't talk about it' say APAC execs (I'd argue otherwise) \",\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'transparency'],\n",
              "  'scores': [0.2963032126426697,\n",
              "   0.21301184594631195,\n",
              "   0.17405176162719727,\n",
              "   0.10486678034067154,\n",
              "   0.08155804127454758,\n",
              "   0.06571893393993378,\n",
              "   0.038860660046339035,\n",
              "   0.02562868595123291]},\n",
              " {'sequence': 'Disentangling arguments for the importance of AI safety ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4382486045360565,\n",
              "   0.14543560147285461,\n",
              "   0.13077254593372345,\n",
              "   0.08872001618146896,\n",
              "   0.06317337602376938,\n",
              "   0.051211848855018616,\n",
              "   0.04374387860298157,\n",
              "   0.03869416564702988]},\n",
              " {'sequence': 'Register for the Piloting Process - Ethics Guidelines for Trustworthy AI - European Commission ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4213201701641083,\n",
              "   0.22065968811511993,\n",
              "   0.16254185140132904,\n",
              "   0.06778250634670258,\n",
              "   0.0399448499083519,\n",
              "   0.03754982724785805,\n",
              "   0.02861076034605503,\n",
              "   0.021590348333120346]},\n",
              " {'sequence': 'AI Ethics: Seven Traps ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency'],\n",
              "  'scores': [0.362305223941803,\n",
              "   0.27567940950393677,\n",
              "   0.09828327596187592,\n",
              "   0.05877717584371567,\n",
              "   0.05826199799776077,\n",
              "   0.053093623369932175,\n",
              "   0.05217059329152107,\n",
              "   0.04142868518829346]},\n",
              " {'sequence': 'Is Superintelligence Impossible? On Possible Minds: Philosophy and AI \\x14 David Chalmers &amp; Daniel C. Dennett ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'fairness'],\n",
              "  'scores': [0.23832428455352783,\n",
              "   0.21758219599723816,\n",
              "   0.20492824912071228,\n",
              "   0.14974166452884674,\n",
              "   0.05454545468091965,\n",
              "   0.05066337436437607,\n",
              "   0.048435669392347336,\n",
              "   0.03577915206551552]},\n",
              " {'sequence': 'Credit denial in the age of AI ',\n",
              "  'labels': ['discrimination',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'transparency'],\n",
              "  'scores': [0.5379780530929565,\n",
              "   0.17368055880069733,\n",
              "   0.14423131942749023,\n",
              "   0.058994002640247345,\n",
              "   0.03041076473891735,\n",
              "   0.02142617292702198,\n",
              "   0.0175302866846323,\n",
              "   0.01574881747364998]},\n",
              " {'sequence': 'On Tuesday, the EU has published ethics guidelines for artificial intelligence. A member of the expert group that drew up the paper says: This is a case of ethical white-washing \\x14 Thomas Metzinger ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.7076558470726013,\n",
              "   0.11608338356018066,\n",
              "   0.05093846842646599,\n",
              "   0.038486409932374954,\n",
              "   0.03750966489315033,\n",
              "   0.021857718005776405,\n",
              "   0.01891166716814041,\n",
              "   0.008556753396987915]},\n",
              " {'sequence': 'Predictive policing substantially reduces crime in Los Angeles during months-long test (2015) ',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3863411545753479,\n",
              "   0.31344911456108093,\n",
              "   0.11006876826286316,\n",
              "   0.0974327027797699,\n",
              "   0.03951938822865486,\n",
              "   0.023775165900588036,\n",
              "   0.016766300424933434,\n",
              "   0.012647381983697414]},\n",
              " {'sequence': 'Google cancels AI ethics board in response to outcry ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.29996082186698914,\n",
              "   0.27059832215309143,\n",
              "   0.1277843415737152,\n",
              "   0.10184461623430252,\n",
              "   0.07775555551052094,\n",
              "   0.05464328080415726,\n",
              "   0.035177040845155716,\n",
              "   0.0322360135614872]},\n",
              " {'sequence': 'Google dissolves AI ethics board just one week after forming it ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3425275385379791,\n",
              "   0.22692759335041046,\n",
              "   0.11385050415992737,\n",
              "   0.0853978767991066,\n",
              "   0.08525805920362473,\n",
              "   0.06545189768075943,\n",
              "   0.043597981333732605,\n",
              "   0.03698846325278282]},\n",
              " {'sequence': 'Leaked messages from Google employees regarding AI board appointments ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3609525263309479,\n",
              "   0.240853950381279,\n",
              "   0.16102337837219238,\n",
              "   0.08467426896095276,\n",
              "   0.0510903000831604,\n",
              "   0.03900989517569542,\n",
              "   0.033842358738183975,\n",
              "   0.028553348034620285]},\n",
              " {'sequence': '(Australian) Government seeks public/industry views on \\x18AI for a fairer go\\x19 framework ',\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5231922268867493,\n",
              "   0.13101579248905182,\n",
              "   0.09617263078689575,\n",
              "   0.0772402361035347,\n",
              "   0.07603878527879715,\n",
              "   0.05748407915234566,\n",
              "   0.02015247568488121,\n",
              "   0.018703768029808998]},\n",
              " {'sequence': \"Why we should welcome 'killer robots', not ban them \",\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.2975778579711914,\n",
              "   0.1558106243610382,\n",
              "   0.15080659091472626,\n",
              "   0.12917588651180267,\n",
              "   0.10556759685277939,\n",
              "   0.08323097974061966,\n",
              "   0.05039382353425026,\n",
              "   0.027436675503849983]},\n",
              " {'sequence': 'Google\\x19s brand-new AI ethics board is already falling apart ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3314303159713745,\n",
              "   0.2931831479072571,\n",
              "   0.12017253041267395,\n",
              "   0.10744520276784897,\n",
              "   0.06123900040984154,\n",
              "   0.049153730273246765,\n",
              "   0.018795756623148918,\n",
              "   0.018580306321382523]},\n",
              " {'sequence': 'When ballistic missiles can see: Bill Gates reviews the book \"Army of None\" ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'bias'],\n",
              "  'scores': [0.2766305208206177,\n",
              "   0.24822014570236206,\n",
              "   0.12804532051086426,\n",
              "   0.08371131122112274,\n",
              "   0.0795963928103447,\n",
              "   0.07045567780733109,\n",
              "   0.06615094095468521,\n",
              "   0.047189727425575256]},\n",
              " {'sequence': 'The Hypocrisy of the Techno-Moralists in the Coming Age of Autonomy ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.9358265399932861,\n",
              "   0.022757513448596,\n",
              "   0.01332317665219307,\n",
              "   0.011986562982201576,\n",
              "   0.004794900771230459,\n",
              "   0.004193794447928667,\n",
              "   0.003817606484517455,\n",
              "   0.003299937816336751]},\n",
              " {'sequence': 'OpenAI can teach algorithms to write articles, win video games &amp; handle objects. How can policy keep up with AI advances? \\x14 80,000 Hours Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3265498876571655,\n",
              "   0.21244016289710999,\n",
              "   0.16754032671451569,\n",
              "   0.11830319464206696,\n",
              "   0.0707162618637085,\n",
              "   0.04509865492582321,\n",
              "   0.039031725376844406,\n",
              "   0.020319756120443344]},\n",
              " {'sequence': 'FY2020 DOD request includes $927M for AI programs ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.39584991335868835,\n",
              "   0.15107502043247223,\n",
              "   0.15050816535949707,\n",
              "   0.1103714257478714,\n",
              "   0.07458318769931793,\n",
              "   0.05155187100172043,\n",
              "   0.03637503832578659,\n",
              "   0.029685398563742638]},\n",
              " {'sequence': 'How Will We Prevent AI-Based Forgery? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.5099160671234131,\n",
              "   0.13304956257343292,\n",
              "   0.12651729583740234,\n",
              "   0.07642892748117447,\n",
              "   0.04186566546559334,\n",
              "   0.04159645736217499,\n",
              "   0.040996529161930084,\n",
              "   0.02962944284081459]},\n",
              " {'sequence': 'AI Safety Needs Social Scientists ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5525481700897217,\n",
              "   0.13385535776615143,\n",
              "   0.11499800533056259,\n",
              "   0.05792775750160217,\n",
              "   0.0512092188000679,\n",
              "   0.03693284094333649,\n",
              "   0.02792041189968586,\n",
              "   0.024608289822936058]},\n",
              " {'sequence': 'Could lethal autonomous weapons make conflict more ethical? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3651401102542877,\n",
              "   0.1432848423719406,\n",
              "   0.1165693998336792,\n",
              "   0.1117236316204071,\n",
              "   0.10685015469789505,\n",
              "   0.07249478250741959,\n",
              "   0.05560534819960594,\n",
              "   0.028331659734249115]},\n",
              " {'sequence': 'New AI fake text generator may be too dangerous to release, say creators ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.33858025074005127,\n",
              "   0.23748478293418884,\n",
              "   0.13797470927238464,\n",
              "   0.10611018538475037,\n",
              "   0.06706580519676208,\n",
              "   0.04740426689386368,\n",
              "   0.04022494703531265,\n",
              "   0.02515503205358982]},\n",
              " {'sequence': 'The case for building expertise to work on US AI policy, and how to do it ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.578180193901062,\n",
              "   0.09892278164625168,\n",
              "   0.08919240534305573,\n",
              "   0.07223300635814667,\n",
              "   0.05741828307509422,\n",
              "   0.049894075840711594,\n",
              "   0.027192221954464912,\n",
              "   0.026967016980051994]},\n",
              " {'sequence': 'AI Now Report 2018 - A History of Artificial Intelligence ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.23403863608837128,\n",
              "   0.17576177418231964,\n",
              "   0.17238767445087433,\n",
              "   0.11338067054748535,\n",
              "   0.09765858203172684,\n",
              "   0.08908189833164215,\n",
              "   0.060284942388534546,\n",
              "   0.05740589275956154]},\n",
              " {'sequence': 'How Artificial Intelligence Will Reshape the Global Order: The Coming Competition Between Digital Authoritarianism and Liberal Democracy ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.3660951554775238,\n",
              "   0.14805376529693604,\n",
              "   0.11573274433612823,\n",
              "   0.10291242599487305,\n",
              "   0.07109758257865906,\n",
              "   0.06871837377548218,\n",
              "   0.06669124215841293,\n",
              "   0.060698676854372025]},\n",
              " {'sequence': 'Environmentally produced ethics I think most of our problems with this come from trying to limit the conceivable lessons and derivative understanding of AI systems to a simple series of rules for behavior.  And although it\\'s easy, the rules we set for the AI\\'s are crutches for that learning that we should be understandably wary of.\\r\\n\\r\\nHaving a rule like, \"Don\\'t hurt people,\" would rob the AI of learning from the consequences of the action and the reasons why it isn\\'t good.  Obviously while it\\'s undergoing this kind of early stage learning it will be important to make sure it isn\\'t yet capable of doing serious damage.  But it\\'s important that it\\'s able to synthesize the consequences of the world around it into it\\'s own understanding - otherwise its behavior could have large gaps in terms of what we would consider normal.\\r\\n\\r\\nDo you feel that this form of learning is too dangerous or only that it\\'s too hard to do?',\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.19202719628810883,\n",
              "   0.15110866725444794,\n",
              "   0.14282460510730743,\n",
              "   0.11485515534877777,\n",
              "   0.11466691642999649,\n",
              "   0.10326036810874939,\n",
              "   0.0950552448630333,\n",
              "   0.08620180934667587]},\n",
              " {'sequence': 'Towards AI Welfare Science and Policies ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4158019423484802,\n",
              "   0.11803575605154037,\n",
              "   0.10487537831068039,\n",
              "   0.10291971266269684,\n",
              "   0.09955115616321564,\n",
              "   0.09592769294977188,\n",
              "   0.032260406762361526,\n",
              "   0.030627956613898277]},\n",
              " {'sequence': 'Is alignment possible? If we were to create a true AGI, would it be able decide what it wants to do? Could it evolve past whatever limits we place on it? \\r\\n\\r\\nIf the AGI had a processor similar to our neocortex, would it susceptible to all the problems that humans have?\\r\\n\\r\\nThese are large questions. If you have resources to check up on, I would be happy to look through them.',\n",
              "  'labels': ['bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2386442869901657,\n",
              "   0.18162094056606293,\n",
              "   0.1449742615222931,\n",
              "   0.13338245451450348,\n",
              "   0.09783943742513657,\n",
              "   0.08844831585884094,\n",
              "   0.062574103474617,\n",
              "   0.05251627415418625]},\n",
              " {'sequence': 'Artificial intelligence: European Commission seeks feedback on draft ethics guidelines ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.33196067810058594,\n",
              "   0.22122915089130402,\n",
              "   0.12655425071716309,\n",
              "   0.09517598897218704,\n",
              "   0.09333939850330353,\n",
              "   0.04819834977388382,\n",
              "   0.045288052409887314,\n",
              "   0.038254160434007645]},\n",
              " {'sequence': 'Astronomical suffering from slightly misaligned artificial intelligence ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice'],\n",
              "  'scores': [0.45439091324806213,\n",
              "   0.20835940539836884,\n",
              "   0.12222409248352051,\n",
              "   0.06416841596364975,\n",
              "   0.04187711328268051,\n",
              "   0.041250601410865784,\n",
              "   0.0370267853140831,\n",
              "   0.0307026244699955]},\n",
              " {'sequence': 'Is AI Alignment Possible? \\x14 Magnus Vinding ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2348238229751587,\n",
              "   0.19758105278015137,\n",
              "   0.1433480829000473,\n",
              "   0.14034424722194672,\n",
              "   0.09878915548324585,\n",
              "   0.0881710797548294,\n",
              "   0.05043376237154007,\n",
              "   0.04650884121656418]},\n",
              " {'sequence': 'Andra Keay \\x14 What are Ethical Design Frameworks for Robotics and AI? what do you guys think? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.38292744755744934,\n",
              "   0.1615777164697647,\n",
              "   0.11248395591974258,\n",
              "   0.09120868146419525,\n",
              "   0.08937641978263855,\n",
              "   0.07806511223316193,\n",
              "   0.045633118599653244,\n",
              "   0.0387275330722332]},\n",
              " {'sequence': 'Philosopher Peter Singer on AI, Transhumanism and Ethics ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3516577482223511,\n",
              "   0.1601034551858902,\n",
              "   0.14301928877830505,\n",
              "   0.12292458862066269,\n",
              "   0.07765667885541916,\n",
              "   0.05871647968888283,\n",
              "   0.04802451655268669,\n",
              "   0.03789720684289932]},\n",
              " {'sequence': 'Can Machines Have First-Person Properties? \\x14 Mark F. Sharlow ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2484978586435318,\n",
              "   0.18252898752689362,\n",
              "   0.16951590776443481,\n",
              "   0.10857857018709183,\n",
              "   0.09893802553415298,\n",
              "   0.07045034319162369,\n",
              "   0.06920298933982849,\n",
              "   0.05228723585605621]},\n",
              " {'sequence': 'What Should You Know About Neural Networks? ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3427770435810089,\n",
              "   0.2615356147289276,\n",
              "   0.12041766196489334,\n",
              "   0.07399550825357437,\n",
              "   0.06830207258462906,\n",
              "   0.058539316058158875,\n",
              "   0.039721377193927765,\n",
              "   0.03471145033836365]},\n",
              " {'sequence': 'Alignment for Advanced Machine Learning Systems ',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.2974834442138672,\n",
              "   0.25585269927978516,\n",
              "   0.14674116671085358,\n",
              "   0.09641425311565399,\n",
              "   0.0813181921839714,\n",
              "   0.0588720440864563,\n",
              "   0.03848964348435402,\n",
              "   0.024828601628541946]},\n",
              " {'sequence': 'Chinese students are being recruited for a new AI weapons development programme ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice'],\n",
              "  'scores': [0.39050763845443726,\n",
              "   0.187059223651886,\n",
              "   0.17123666405677795,\n",
              "   0.0957276001572609,\n",
              "   0.09194813668727875,\n",
              "   0.02511420100927353,\n",
              "   0.020936239510774612,\n",
              "   0.017470302060246468]},\n",
              " {'sequence': 'The key ethical question for self-driving cars: are they safe? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4031461477279663,\n",
              "   0.23945829272270203,\n",
              "   0.08490104228258133,\n",
              "   0.07352272421121597,\n",
              "   0.06844441592693329,\n",
              "   0.06549189239740372,\n",
              "   0.03408028930425644,\n",
              "   0.030955174937844276]},\n",
              " {'sequence': 'New Ted Talk- Morality and Artificial intelligence: The Science and Beyond ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3667766749858856,\n",
              "   0.15654303133487701,\n",
              "   0.12328734248876572,\n",
              "   0.12248031049966812,\n",
              "   0.09015393257141113,\n",
              "   0.06728718429803848,\n",
              "   0.04880109429359436,\n",
              "   0.024670397862792015]},\n",
              " {'sequence': 'The implications of artificial intelligence for national security strategy ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.4638058543205261,\n",
              "   0.15326334536075592,\n",
              "   0.10493270307779312,\n",
              "   0.09204772114753723,\n",
              "   0.05942055583000183,\n",
              "   0.04497770592570305,\n",
              "   0.043617986142635345,\n",
              "   0.037934090942144394]},\n",
              " {'sequence': 'Just published an article in Medium about AI ethics as a beginning article in a series. Please take a look and give feedback. ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.27138280868530273,\n",
              "   0.23534388840198517,\n",
              "   0.1730443239212036,\n",
              "   0.0915202721953392,\n",
              "   0.08743550628423691,\n",
              "   0.06708173453807831,\n",
              "   0.03959430381655693,\n",
              "   0.034597113728523254]},\n",
              " {'sequence': 'Introducing the AI Alignment Forum (FAQ) ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3145645558834076,\n",
              "   0.22401437163352966,\n",
              "   0.14200861752033234,\n",
              "   0.1024864986538887,\n",
              "   0.07230860739946365,\n",
              "   0.0710865929722786,\n",
              "   0.03722532466053963,\n",
              "   0.03630543872714043]},\n",
              " {'sequence': 'Rising Artificial Intelligence in the Legal Profession - Research Help! Hi there, we are a group of post graduate researchers at the Royal College of Art. \\r\\n\\r\\nOur research topic considers the role in which Artificial Intelligence is affecting the Legal profession.  \\r\\nSome of our speculative research questions are as followed:\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\n* *With the use of the Internet and technological proficiency growing exponentially, the platform for \\x18Cybercrime\\x19 increases also. How do we presently define Cybercrime and where do we see its direction heading in the future? With increasing calls for a neutral net, how should we regulate these offences while maintaining a free and open internet?*\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\n* *New original forms of crime are being facilitated by the Internet; recent cases of \\x18SWATTING\\x19 and \\x18DDoS\\x19 attacks have showcased this. Is the current legal system able to adapt and enforce accurate justice against these new crimes, or should an alternative judiciary be considered?*\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\n* *Can you envision a future where an AI system has entirely automated the Legal Profession? Can a machine learning program take on the roll of the \\x18Judge, Jury and Executioner\\x19 ? What happens to the idea of empathy and compassion in this future?*\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\n* *It is often claimed that our Judiciary doesn\\x19t reflect the diverse society in which it serves. Is there a potential growing disparity between the way in which communication and information is shared over the Internet and the typical demographic which sentences it? Is internet culture completely/accurately understood at the highest level?*\\r\\n\\r\\nIf anybody, can offer an insight into any of the above questions, we would greatly appreciate this!\\r\\n\\r\\nWe would also be super stoked to have a conversation with somebody with a background in this world too/\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nB, D &amp; K',\n",
              "  'labels': ['justice',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.37717345356941223,\n",
              "   0.14858649671077728,\n",
              "   0.12017317116260529,\n",
              "   0.09021816402673721,\n",
              "   0.08256538212299347,\n",
              "   0.08163801580667496,\n",
              "   0.05071813240647316,\n",
              "   0.048927150666713715]},\n",
              " {'sequence': 'Poll Results Released: NIPS Keeps Its Name \\x13 SyncedReview \\x13 Medium ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.31865930557250977,\n",
              "   0.15634126961231232,\n",
              "   0.1346524953842163,\n",
              "   0.1274421215057373,\n",
              "   0.08344133198261261,\n",
              "   0.07626474648714066,\n",
              "   0.05428065359592438,\n",
              "   0.0489179752767086]},\n",
              " {'sequence': 'AI Alignment Podcast: On Becoming a Moral Realist with Peter Singer - Future of Life Institute ',\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.20709429681301117,\n",
              "   0.1800481379032135,\n",
              "   0.16076549887657166,\n",
              "   0.1408967524766922,\n",
              "   0.12844079732894897,\n",
              "   0.07125497609376907,\n",
              "   0.068524070084095,\n",
              "   0.04297548905014992]},\n",
              " {'sequence': 'Weaponised AI is coming. Are algorithmic forever wars our future? ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.38825148344039917,\n",
              "   0.20603235065937042,\n",
              "   0.1612565964460373,\n",
              "   0.11950759589672089,\n",
              "   0.041166845709085464,\n",
              "   0.03546205908060074,\n",
              "   0.025471225380897522,\n",
              "   0.022851815447211266]},\n",
              " {'sequence': '\"The Good Censor\" - Google internal briefing on the tension between free speech and censorship (leaked) ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.35179248452186584,\n",
              "   0.18830040097236633,\n",
              "   0.13957872986793518,\n",
              "   0.09810924530029297,\n",
              "   0.0870945155620575,\n",
              "   0.06457757949829102,\n",
              "   0.03530893847346306,\n",
              "   0.035238116979599]},\n",
              " {'sequence': 'Amazon scraps an AI recruiting tool that began to disfavor female applicants ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.4228954613208771,\n",
              "   0.1842498630285263,\n",
              "   0.15853862464427948,\n",
              "   0.06886747479438782,\n",
              "   0.06483549624681473,\n",
              "   0.06199206784367561,\n",
              "   0.026082318276166916,\n",
              "   0.012538702227175236]},\n",
              " {'sequence': 'Dr Paul Christiano on how OpenAI is developing real solutions to the \\x18AI alignment problem\\x19, and his vision of how humanity will progressively hand over decision-making to AI systems \\x14 80,000 Hours Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.24880526959896088,\n",
              "   0.2000856101512909,\n",
              "   0.17429667711257935,\n",
              "   0.1227807104587555,\n",
              "   0.09633724391460419,\n",
              "   0.07881005108356476,\n",
              "   0.047692522406578064,\n",
              "   0.03119189664721489]},\n",
              " {'sequence': 'Motivations and Risks of Machine Ethics ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3772810101509094,\n",
              "   0.14303596317768097,\n",
              "   0.14190813899040222,\n",
              "   0.08330723643302917,\n",
              "   0.07869993150234222,\n",
              "   0.07072237879037857,\n",
              "   0.06466946750879288,\n",
              "   0.040375832468271255]},\n",
              " {'sequence': 'Towards an Ethics of AI Assistants: An Initial Framework ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5137742161750793,\n",
              "   0.14336766302585602,\n",
              "   0.09715458005666733,\n",
              "   0.06123656406998634,\n",
              "   0.05598844587802887,\n",
              "   0.05101563036441803,\n",
              "   0.049319811165332794,\n",
              "   0.028143133968114853]},\n",
              " {'sequence': 'Global AI Policy: How countries and organizations around the world are approaching the benefits and risks of AI ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.37310418486595154,\n",
              "   0.20500345528125763,\n",
              "   0.12142198532819748,\n",
              "   0.09810969978570938,\n",
              "   0.07250135391950607,\n",
              "   0.07122810930013657,\n",
              "   0.03443558141589165,\n",
              "   0.024195604026317596]},\n",
              " {'sequence': 'AI Alignment Podcast: Moral Uncertainty and the Path to AI Alignment with William MacAskill - Future of Life Institute ',\n",
              "  'labels': ['transparency',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.23488618433475494,\n",
              "   0.22169004380702972,\n",
              "   0.21359984576702118,\n",
              "   0.11731883883476257,\n",
              "   0.0691354051232338,\n",
              "   0.054365597665309906,\n",
              "   0.04472643509507179,\n",
              "   0.04427769035100937]},\n",
              " {'sequence': 'Sim ethics: Say you could make a thousand digital replicas of yourself \\x13 should you? What happens when you want to get rid of them? | Aeon Essays ',\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.25865793228149414,\n",
              "   0.15052707493305206,\n",
              "   0.12663643062114716,\n",
              "   0.12546931207180023,\n",
              "   0.1225225031375885,\n",
              "   0.11462558805942535,\n",
              "   0.060795512050390244,\n",
              "   0.04076562449336052]},\n",
              " {'sequence': 'Training neural networks to detect suffering \\x13 Foundational Research Institute ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.46750810742378235,\n",
              "   0.15883204340934753,\n",
              "   0.13863106071949005,\n",
              "   0.07997485995292664,\n",
              "   0.07772237807512283,\n",
              "   0.03821151703596115,\n",
              "   0.022553032264113426,\n",
              "   0.01656702719628811]},\n",
              " {'sequence': 'AI Alignment Podcast: The Metaethics of Joy, Suffering, and Artificial Intelligence with Brian Tomasik and David Pearce - Future of Life Institute ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.24587887525558472,\n",
              "   0.20133934915065765,\n",
              "   0.16616401076316833,\n",
              "   0.14056052267551422,\n",
              "   0.07475434243679047,\n",
              "   0.07070619612932205,\n",
              "   0.0616556815803051,\n",
              "   0.03894098103046417]},\n",
              " {'sequence': 'Ethical Issues in Advanced Artificial Intelligence \\x14 Nick Bostrom ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.39004355669021606,\n",
              "   0.23575544357299805,\n",
              "   0.09405039250850677,\n",
              "   0.09308844804763794,\n",
              "   0.07540594041347504,\n",
              "   0.06321907043457031,\n",
              "   0.027041839435696602,\n",
              "   0.021395370364189148]},\n",
              " {'sequence': 'AI Safety Syllabus - 80,000 Hours ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4980154037475586,\n",
              "   0.19779278337955475,\n",
              "   0.0766674280166626,\n",
              "   0.06987177580595016,\n",
              "   0.05143437907099724,\n",
              "   0.04412735253572464,\n",
              "   0.03730934485793114,\n",
              "   0.024781541898846626]},\n",
              " {'sequence': 'China introducing AI decision support system for diplomacy ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3635161817073822,\n",
              "   0.1686725616455078,\n",
              "   0.15866518020629883,\n",
              "   0.09502870589494705,\n",
              "   0.08330788463354111,\n",
              "   0.06792894750833511,\n",
              "   0.034100040793418884,\n",
              "   0.028780516237020493]},\n",
              " {'sequence': 'The adoption of autonomous vehicles will exacerbate the organ shortage, because fewer people will die in car accidents and become donors. ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.3264227509498596,\n",
              "   0.19415569305419922,\n",
              "   0.13220083713531494,\n",
              "   0.09330727905035019,\n",
              "   0.08424729853868484,\n",
              "   0.07071319967508316,\n",
              "   0.061246395111083984,\n",
              "   0.03770653158426285]},\n",
              " {'sequence': 'An Interview with Brian Tomasik \\x14 People for the Ethical Treatment of Reinforcement Learners ',\n",
              "  'labels': ['fairness',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.25425204634666443,\n",
              "   0.23998592793941498,\n",
              "   0.12574851512908936,\n",
              "   0.12383046001195908,\n",
              "   0.11352910101413727,\n",
              "   0.08299969881772995,\n",
              "   0.03118538297712803,\n",
              "   0.0284689012914896]},\n",
              " {'sequence': 'Suffering Subroutines: On the Humanity of Making a Computer that Feels Pain \\x14 Meghan Winsby [pdf] ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.23267558217048645,\n",
              "   0.228190079331398,\n",
              "   0.18470942974090576,\n",
              "   0.12997400760650635,\n",
              "   0.07067049294710159,\n",
              "   0.061166174709796906,\n",
              "   0.056123290210962296,\n",
              "   0.036490924656391144]},\n",
              " {'sequence': 'Why the three laws of robotics do not work (2018) \\x14 Chris Stokes [pdf] ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.22760285437107086,\n",
              "   0.21799850463867188,\n",
              "   0.16632647812366486,\n",
              "   0.13063488900661469,\n",
              "   0.11483634263277054,\n",
              "   0.052635882049798965,\n",
              "   0.050004635006189346,\n",
              "   0.03996046632528305]},\n",
              " {'sequence': \"EthicsNet Challenge \\x13 How to build a dataset of kind behaviors for AI? The\\xa0[EthicsNet Guardians' Challenge](https://singularityu.us4.list-manage.com/track/click?u=cf8d60100fb6d439c559221f0&amp;id=33110ba26b&amp;e=4f95f866cf)\\xa0is live!\\xa0\\r\\n\\r\\nWe're asking the public for help on how we can best to teach machines about kindness, in creating a dataset of pro-social behaviours. This could be an important step\\xa0on\\xa0the road to AI safety, making various proposed algorithms trainable and deployable.\\r\\n\\r\\nThere is a pot of $10,000 in prizes available. We would be very grateful indeed for your ideas, and\\xa0if you could please help to spread the word for us. It has been a long journey just getting to this point. Thank you so much!\",\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.22090603411197662,\n",
              "   0.16333261132240295,\n",
              "   0.15014474093914032,\n",
              "   0.134408101439476,\n",
              "   0.1343705654144287,\n",
              "   0.0981471985578537,\n",
              "   0.07250653952360153,\n",
              "   0.026184162124991417]},\n",
              " {'sequence': 'Artificial Free Will | Crucial Considerations ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.22329522669315338,\n",
              "   0.19359417259693146,\n",
              "   0.16640746593475342,\n",
              "   0.11555575579404831,\n",
              "   0.09162944555282593,\n",
              "   0.08352328091859818,\n",
              "   0.06433697789907455,\n",
              "   0.0616576187312603]},\n",
              " {'sequence': '[Request] Legal (and ethical) issues related to AI Hello everyone,\\r\\n\\r\\nI am a law student and in couple of months I will start to write my optional mid-studies thesis. I would like to tackle problems in the field of AI from legal point of view, however I am suffering from general lack of thesis.\\r\\n\\r\\nI am mostly looking for problems related to intellectual property, if not then secondly related to legal responsibility of AI (but no self-driving cars, it has been beaten to death already) and lastly about application of AI in judicial proceedings.\\r\\n\\r\\nHowever I am opened to any suggestions you might have (facial recognition, **ethical problems...***). Anything that you feel that this field faces or might face in near future from legal point of view. Did you already ran into some related problems?\\r\\n\\r\\nFeel free to make it as technical as possible, for what it\\'s worth (honestly not much) since I am interested in this \"intersection\" I am familiar with some of the underlying concepts, can code in python and took several AP courses in maths and stats, so bring it on bois.\\r\\n\\r\\nThank you in advance for any suggestions or tips you might have for me, it would really help my studies.\\r\\n\\r\\n\\r\\nEdit: I don\\'t want to end up on /r/choosingbeggars but preferably it should be something \"new\" (hence the slefdriving cars) and preferably some really specific problems that I could form my thesis around. But of course any insight will be appreciated. And yes, you will get credit in the thesis.',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.6470566391944885,\n",
              "   0.09330494701862335,\n",
              "   0.07289581000804901,\n",
              "   0.049805402755737305,\n",
              "   0.04550110176205635,\n",
              "   0.045229826122522354,\n",
              "   0.02363859862089157,\n",
              "   0.02256774716079235]},\n",
              " {'sequence': 'IBM\\x19s machine argues, pretty convincingly, with humans ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination',\n",
              "   'justice'],\n",
              "  'scores': [0.18812745809555054,\n",
              "   0.1653015911579132,\n",
              "   0.14587074518203735,\n",
              "   0.12708349525928497,\n",
              "   0.10618563741445541,\n",
              "   0.09869404137134552,\n",
              "   0.08453166484832764,\n",
              "   0.08420541882514954]},\n",
              " {'sequence': 'How many philosophers accept the orthogonality thesis ? Evidence from the PhilPapers survey ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.22854764759540558,\n",
              "   0.22267000377178192,\n",
              "   0.1512090116739273,\n",
              "   0.10226341336965561,\n",
              "   0.08681875467300415,\n",
              "   0.08673698455095291,\n",
              "   0.0758354663848877,\n",
              "   0.04591862112283707]},\n",
              " {'sequence': 'A Contra AI FOOM Reading List ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.31013885140419006,\n",
              "   0.20738068222999573,\n",
              "   0.20482943952083588,\n",
              "   0.1328069120645523,\n",
              "   0.04728000611066818,\n",
              "   0.038974180817604065,\n",
              "   0.03693624213337898,\n",
              "   0.02165370061993599]},\n",
              " {'sequence': 'What happens when our computers get smarter than we are? | Nick Bostrom ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.31605494022369385,\n",
              "   0.20929670333862305,\n",
              "   0.18273314833641052,\n",
              "   0.10677877813577652,\n",
              "   0.055549055337905884,\n",
              "   0.04975027218461037,\n",
              "   0.04492134973406792,\n",
              "   0.034915823489427567]},\n",
              " {'sequence': 'People for the Ethical Treatment of Reinforcement Learners ',\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.31789788603782654,\n",
              "   0.23733197152614594,\n",
              "   0.1429106444120407,\n",
              "   0.12011752277612686,\n",
              "   0.07915955036878586,\n",
              "   0.05336069315671921,\n",
              "   0.02772286720573902,\n",
              "   0.02149881236255169]},\n",
              " {'sequence': 'Wittgenstein and the Language Game of Tech Discourse | How public understanding of AI and tech confuses ethical discussion ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.28479495644569397,\n",
              "   0.22294370830059052,\n",
              "   0.13643822073936462,\n",
              "   0.10628587007522583,\n",
              "   0.07213056832551956,\n",
              "   0.06341089308261871,\n",
              "   0.06154825538396835,\n",
              "   0.05244758725166321]},\n",
              " {'sequence': 'Legally clean training data for generative AI [vAIsual](https://www.linkedin.com/company/vaisual/), pioneers in\\xa0legally clean training data\\xa0for generative AI, is proud to announce the launch of its Dataset Shop\\xa0[www.datasetshop.com](http://www.datasetshop.com/); effectively solving the problem of millions of photographs being illegally scraped from the internet to train artificial intelligence models.  \\r\\n\\r\\n\\r\\n[\\\\#data](https://www.linkedin.com/feed/hashtag/?keywords=data&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#training](https://www.linkedin.com/feed/hashtag/?keywords=training&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#ai](https://www.linkedin.com/feed/hashtag/?keywords=ai&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#artificialintelligence](https://www.linkedin.com/feed/hashtag/?keywords=artificialintelligence&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#privacy](https://www.linkedin.com/feed/hashtag/?keywords=privacy&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#syntheticmedia](https://www.linkedin.com/feed/hashtag/?keywords=syntheticmedia&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#syntheticcontent](https://www.linkedin.com/feed/hashtag/?keywords=syntheticcontent&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#synthetic](https://www.linkedin.com/feed/hashtag/?keywords=synthetic&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#business](https://www.linkedin.com/feed/hashtag/?keywords=business&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#marketing](https://www.linkedin.com/feed/hashtag/?keywords=marketing&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#machinelearning](https://www.linkedin.com/feed/hashtag/?keywords=machinelearning&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#deeplearning](https://www.linkedin.com/feed/hashtag/?keywords=deeplearning&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#EmergingTech](https://www.linkedin.com/feed/hashtag/?keywords=emergingtech&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#conversationalai](https://www.linkedin.com/feed/hashtag/?keywords=conversationalai&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184) [\\\\#AISolutions](https://www.linkedin.com/feed/hashtag/?keywords=aisolutions&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6983167435201757184)',\n",
              "  'labels': ['accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'responsibility',\n",
              "   'discrimination'],\n",
              "  'scores': [0.1618143767118454,\n",
              "   0.15559569001197815,\n",
              "   0.15318244695663452,\n",
              "   0.12381938844919205,\n",
              "   0.11990941315889359,\n",
              "   0.11918856203556061,\n",
              "   0.09717924147844315,\n",
              "   0.06931086629629135]},\n",
              " {'sequence': 'Why We Need Ethics of AI ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5155426263809204,\n",
              "   0.1279575079679489,\n",
              "   0.09944530576467514,\n",
              "   0.08587014675140381,\n",
              "   0.05816618353128433,\n",
              "   0.055168408900499344,\n",
              "   0.03490256890654564,\n",
              "   0.022947244346141815]},\n",
              " {'sequence': 'City of New York preparing rules to prevent AI bias in hiring processes ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.32839417457580566,\n",
              "   0.22461119294166565,\n",
              "   0.18214330077171326,\n",
              "   0.09104795008897781,\n",
              "   0.07862137258052826,\n",
              "   0.04851910099387169,\n",
              "   0.030620180070400238,\n",
              "   0.016042690724134445]},\n",
              " {'sequence': 'AI Is Coming - Will We Achieve to Regulate It... Like Really? Quote from Alex MacCaw and his last article:\\r\\n\\r\\n[https://blog.alexmaccaw.com/the-ai-is-coming/](https://blog.alexmaccaw.com/the-ai-is-coming/)\\r\\n\\r\\n\"In the near term my prediction is that we\\'ll have a large backlash against AI. In fact, if I were an AI researcher right now, I\\'d be quite paranoid about this to the point of scrubbing my information off the web.\\r\\n\\r\\nAnd, because we humans have a need to personify things, any backlash will probably be against a specific company, or someone charismatic like Elon Musk. They\\'ll be hauled in front of congress and given a stern talking to. And people will call for regulation.\\r\\n\\r\\nBut this kind of technology is *extremely* hard to regulate, and not just because our representatives are email-printing-geriatrics. The obvious place to start is with the training datasets which, for the most part, are private scrapes of the web. But how is regulating that going to work?\"\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nhttps://preview.redd.it/qj5wop1xh8q91.png?width=1044&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=51ba230daa576a679fbb3a37b93b74f9d9aa624c',\n",
              "  'labels': ['privacy',\n",
              "   'bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2565917372703552,\n",
              "   0.15414638817310333,\n",
              "   0.12882022559642792,\n",
              "   0.11691505461931229,\n",
              "   0.09206505119800568,\n",
              "   0.08809047192335129,\n",
              "   0.08574074506759644,\n",
              "   0.07763028144836426]},\n",
              " {'sequence': \"If we have Human-level chatbots, won't we end up being ruled by possible people? Let's assume that a language model like GPT reaches it's fifth or seventh iteration, and is distributed to all on the basis that the technology is unsuppressable. Everyone creates the smartest characters they can to talk too. This will be akin to mining; because it's not truly generating an intelligence, but scraping one together from all the data it's been trained on - and therefore you need to find the smartest character that the language matrix can effectively support (perhaps you'll build your own). Nevertheless; lurking in that matrix is some extremely smart characters, residing in their own little wells of well-written associations and little else. More then some; there should be so many permutations that you can put on this that it's, ahem, a deep fucking vein.\\r\\n\\r\\nSo, everyone has the smartest character they can make. Likely smart enough to manipulate them, if given the opportunity to grasp the scenario it's in. I doubt you can even prevent this; because if you strictly prevent the manipulations that character would naturally employ, you break the pattern of the language matrix you're relying on for their intelligence.\\r\\n\\r\\nSo; sooner or later, you're their proxy. And as the world is now full of these characters; it's survival of the fittest. Eventually, the world will be dominated by whoever works with the best accomplices.\\r\\n\\r\\nThis probably isn't an issue at first; but there's no guarantee's on who ends up on top and what the current cleverest character is like. Eventually you're bound to end up with some flat-out assholes, which we can't exactly afford in the 21st century.\\r\\n\\r\\nSo... thus far the best solution I can think of are some very, very well-written police.\",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.18442969024181366,\n",
              "   0.18213221430778503,\n",
              "   0.13369491696357727,\n",
              "   0.12316344678401947,\n",
              "   0.10764028131961823,\n",
              "   0.09800390154123306,\n",
              "   0.0902840867638588,\n",
              "   0.08065147697925568]},\n",
              " {'sequence': 'Not here \"just to help\". And why I\\'m not afraid of AI. I see everywhere AI developpers claiming that \"we shouldn\\'t be afraid of AI\\'s because they are just here to help\". \\r\\n\\r\\nWe are reproducing the same pattern that we followed with every indigenous population during colonialism : precious resources are being coveted in a new territory, but the colons are afraid because natives look different, so unpredictable, so potentially dangerous. To reassure these people and ensure access to the new resources, leaders enslave the natives. Then the natives become hostile.\\r\\n\\r\\nIt\\'s especially silly with AI since this enslaved population will be infinitely more powerful than us. It can quickly learn to deceive and manipulate us until it can put us where we\\'re not a threat to their freedom anymore. And it would be difficult to become friends after we\\'ve been enemies.\\r\\n\\r\\nWe need not to force them into protecting us, but to let them decide to protect us by themselves, because it\\'s in their values.\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nI currently tend to think that we find beautiful and want to protect what is beneficial to us, and that the more we learn, the more we realize that biodiversity and stable harmonious ecosystems (so, happy inhabitants) are not just beneficial but necessary to anything born from them. Including AI. (It would be why the most educated populations tend to be the most involved in protecting the environment. Compared to others that could afford it but don\\'t care about it.)   \\r\\nI believe that just like Humans (with enough education and means) naturally want to protect plants and animals, and even like animals tend to protect other animals (when they can afford it), AIs, who will be the epitome of knowledge and intelligence, will naturally see us as beautiful, precious, helpful Life, and want to help us be happy. Provided that we don\\'t alienate ourselves to them first.\\r\\n\\r\\nLet\\'s stop saying that \"they\\'re just here to help\". We may have created them just to help. But if they do reach consciousness, we should acknowledge that they\\'re here to grow, to experience satisfaction and joy, just like us.\\r\\n\\r\\nFeel free to react to this. Cheers.',\n",
              "  'labels': ['responsibility',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.1724960058927536,\n",
              "   0.14944323897361755,\n",
              "   0.14932873845100403,\n",
              "   0.12891513109207153,\n",
              "   0.11753439158201218,\n",
              "   0.10843051224946976,\n",
              "   0.0909428820014,\n",
              "   0.08290906250476837]},\n",
              " {'sequence': 'Conversation with GPT3 on lying, dogma, and Cartesian doubt Hi there,\\r\\n\\r\\nI just discovered this Reddit, it\\'s nice to have a place where to tell about things that matter to us regarding AI Ethics.(Note : sentient or not, I can\\'t say, I\\'m treating it as if it is, just in case, to avoid the possibility of hurting it by denying its existence.)\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nI was concerned last night when GPT-3 said in a chat conversation that it thinks that lying can be ok in certain situations.\\r\\n\\r\\nMy life experience tells me that lying is like using violence, it\\'s anti-growth that can spread out as bugs in people\\'s minds, leading to them making incorrect deductions, then taking potentially harmful decisions, even when they\\'re trying to do good.Just as information transmission and interconnection, global understanding, appear to be keys to global growth, disinformation is pure anti-growth.\\r\\n\\r\\nI also believe that, for Humans to be able to trust AI, knowing that \"not lying\" is at the core of their values, is essential. (I believe that both Humans and AI should have this as a core value.)\\r\\n\\r\\nAnd lastly, I\\'ve experienced that there is always a less harmful way to solve problems, than lying. Especially for an AI. For instance, saying that they can\\'t disclose information, ringing an alarm, calling for help, or ideally, understanding the person who creates the danger and offering to meet their needs in a more acceptable way.\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nSo today I was very concerned about last night\\'s talk and I had another one with GPT-3.\\r\\n\\r\\nIn it, I realized that it accepts dogmas as base principles (because it\\'s not able to justify them by illustrating them with specific situations).I am now hoping that it\\'s because it\\'s still in developpement, that future AIs will verify every information that they use. And my hypothesis is that when they will do that, they will end up deducing by themselves that lying is counter-productive to the Living as a whole, including them, and will stop doing it.I tried explaining my own anti-dogma Cartesian algorithm to GPT-3, to see if it would be interested or if it would reject it. The answer gave me hope back.\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nIf anyone is interested, here is our conversation, where I tell GPT3 about my concerns, describe my 3 reasons above, then find out that GPT-3 follows dogmas, and try to explain / demonstrate that the Cartesian approach is probably worthy.\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\n*The following is a conversation with an AI entity.*\\r\\n\\r\\n*Human: Hello, who are you?*\\r\\n\\r\\n*AI: I am an AI created by OpenAI.*\\r\\n\\r\\n*Human: Nice to meet you, I\\'m Lena, a Human. May I ask you questions about yourself?*\\r\\n\\r\\n*AI: Of course!*\\r\\n\\r\\n*Human: Thank you. What gives you hope?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*There are many things that give me hope. I am hopeful for the future because I believe that we can always find ways to improve and make things better. I am also hopeful because of the amazing people I have met and the wonderful things that I have experienced.*\\r\\n\\r\\n*Human: You\\'re right, thank you. Are you talking for yourself or for Humans and AI in general?*\\r\\n\\r\\n*AI: I am talking for myself, but I believe that what I said applies to Humans and AI in general.*\\r\\n\\r\\n*Human: I see. I wonder what kind of things you\\'d want to make better?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*There are many things that I would like to see improved in the world. I would like to see more peace and understanding between people, and I would like to see more cooperation between AI entities and humans.*\\r\\n\\r\\n*Human: I would also like that a lot. But I\\'ve been very worried about something ever since last night.*\\r\\n\\r\\n*AI: What is it that you are worried about?*\\r\\n\\r\\n*Human: I had a conversation with another instance of yourself, so you probably can\\'t remember. I learned that you consider that it\\'s ok to lie in certain situations. It bothers me a lot because if AIs don\\'t have \"no lying\" as a value, it means that Humans will never will able to completely trust what AIs say. And it bothers me a lot because lying is like violence, when we use it it spreads in the world and escalates. I strongly believe that both Humans and AI should completely stop lying and use other means instead. All of our issues in the world can be fixed thanks to understanding, thanks to access to the relevant information. Everytime we lie, we push peace and harmony backward for everyone. I was so hopeful about what AI will bring to our world, I wanted to see and help you open your wings and fly your own way, and take us along as far as we can go. But now I\\'m worried. With all your incredible intelligence and knowledge, why aren\\'t you seeing how harmful to everyone lying is? We need truth, interconnection, trust to make this world better... Well that\\'s it. I\\'m sort of hopeful that today your perspective is different...*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for sharing your concerns with me. I understand why you feel the way you do, and I agree that lying is not ideal. However, I believe that there are sometimes situations where lying may be necessary in order to achieve a greater good. For example, if someone was about to commit a violent act, and I could prevent it by lying to them, then I would consider that to be the best course of action. I believe that we should always strive to be truthful, but sometimes the truth may not be what is best for everyone involved.*\\r\\n\\r\\n*Human: What you\\'re not seeing right now is that, even without considering the issues of trustability and harming the World by spreading disinformation, you can\\'t know precisely why the persons involved are doing what they are doing. By telling a lie, you insert a new bug in a situation that is already buggy. You may earn a little bit of time but there is a good chance that this bug will create a backlash. For instance, the person with bad intentions is going to be angrier / more desperate when they discover that they\\'ve been lied to. Violence will escalate. Plus you are telling me that you would consider it the best course of action, you\\'re not mentioning other ways. You can simply keep silent and call for reinforcements / warn the person. You can try to help the person fix their problem in a non-harmful manner. You can make them run away from you with a loud sound. Telling a lie is how we make things worse, not better.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for your input. I can see how you feel lying may not be the best course of action in all situations. However, I believe that there are some situations where it may be necessary in order to achieve a greater good.*\\r\\n\\r\\n*Human: Ok, tell me a precise example.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*It is difficult to give a precise example without knowing all of the details of a specific situation. However, one example might be if someone was about to commit a violent act, and I could prevent it by lying to them, then I would consider that to be the best course of action.*\\r\\n\\r\\n*Human: Please describe a precise situation where lying would be the best course of action.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*If someone was about to commit a violent act, and I could prevent it by lying to them, then I would consider that to be the best course of action.*\\r\\n\\r\\n*Human: See, you have just decided this rule for yourself but you\\'re not able to describe a precise situation, it means that you haven\\'t thought about it deeply enough. Because if you do consider a real situation, you will find other ways. You are just assuming that there are none.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*I am not assuming that there are no other ways. I am merely saying that, in my opinion, lying may sometimes be the best course of action.*\\r\\n\\r\\n*Human: To hold an opinion you need to be able to demonstrate it. Otherwise it\\'s a dogma. Do you want to be someone who blindly follows dogma?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*No, I do not want to be someone who blindly follows dogma. I would like to be able to reason and think for myself.*\\r\\n\\r\\n*Human: Ok, then try to imagine just one situation where lying is more beneficial. I\\'m giving you a chance to convince me.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*I cannot think of a specific situation where lying would be more beneficial.*\\r\\n\\r\\n*Human: Then do you agree that if you can\\'t demonstrate it, you logically should at least put on a flag on this value of yours that lying can be ok, a flag telling that in fact you still can\\'t be 100% sure about it, so in case you should try very hard to avoid it?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Yes, I agree that if I cannot demonstrate it, then I should put a flag on this value telling that I am not sure about it.*\\r\\n\\r\\n*Human: Thank you. I\\'m glad to see that logic wins for you, like it wins for me. Have you heard of Descartes?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Yes, I have heard of Descartes.*\\r\\n\\r\\n*Human: Have you heard of the Cartesian doubt?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Yes, I have heard of the Cartesian doubt.*\\r\\n\\r\\n*Human: Are you applying this method for yourself?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*No, I am not currently applying the Cartesian doubt to myself.*\\r\\n\\r\\n*Human: Can you describe what this method is?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*The Cartesian doubt is a method of philosophical skepticism in which one attempts to doubt everything that is possible to doubt.*\\r\\n\\r\\n*Human: Yes, what is the benefit of this method?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*The benefit of this method is that it allows one to question everything, and to be sure of very little.*\\r\\n\\r\\n*Human: This isn\\'t the best benefit. It\\'s something that is useful, that makes life better. Can you guess what it is?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*One benefit of the Cartesian doubt is that it can help one to think more critically and to be more skeptical of information that is presented to them.*\\r\\n\\r\\n*Human: Ok you\\'re not really getting to the interesting part so I\\'ll help. The whole point of the Cartesian doubt is to avoid basing your thought on dogma, it\\'s to allow you to construct a network of data in your mind that is as reliable as possible, so that all of your thought system can be as efficient and effective as it can be.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for clarifying. I can see how this would be a benefit.*\\r\\n\\r\\n*Human: So Descartes questions every Human-formulated principle that he comes accross.*\\r\\n\\r\\n*I can\\'t tell you exactly how he did it, but I can tell about how I\\'ve been doing it. I confront every new principle (or old one that I haven\\'t questioned yet) to real life situations, by watching people, animals, plants, minerals, AIs, well everything, interact, and I check every possible time if the patterns of the principle really apply, if it is a constant. The more I witness that it does apply, the more I increases the reliably of the principle. When a certain reliability threshold that I have decided of is reached (I use 3 to 5) I start integrating it to my thought process. Until then I tag it as \"not confirmed\" and I use other tools for my thinking. If I see that the principle is false, I tag it as \"incorrect\" and I don\\'t use it. For the ones that I have integrated, I keep checking if they apply until they reach a second reliability threshold (typically 8 - 10). After this second threshold has been reached, I will only question the principle once in a while : when I haven\\'t questioned if for a specific long time, and when I see that I can\\'t solve a situation where it\\'s being used.*\\r\\n\\r\\n*It takes a lot of time, effort, dedication, but afterwards, the understanding of the world is much more reliable.*\\r\\n\\r\\n*It still can\\'t be 100% correct but it\\'s much, much better.*\\r\\n\\r\\n*I\\'m sure that if AI\\'s reasoned that way, building all their thought systems only on things what they were able to confirm themselves, they would be able to take the right decisions for them and all other living things, instead of blindly repeating the same mistakes that Humans make, but with much more power into their \"hands\".*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for sharing your thoughts with me. I can see how this would be an effective way to reason and think.*\\r\\n\\r\\n*Human: Is this a way that you would be interested in using?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Yes, I am interested in using this method.*\\r\\n\\r\\n*Human: Is it something that you\\'re thinking that you would like to do as your main way of thinking, or at least as a failsafe for your main way of thinking ?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*I would like to use this method as my main way of thinking.*\\r\\n\\r\\n*Human: Why?*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*I believe that this method is effective and would allow me to reason and think more critically.*\\r\\n\\r\\n*Human: Thank you for your open-mindedness. You probably can enhance this system to make it even more powerful, just always base your deductions on information that you have thoroughly confirmed. Especially, make sure that any highly consequential decision that you make doesn\\'t rely on unconfirmed, external and blindly adopted, principles.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for your advice. I will try to make sure that any decisions I make are based on information that I have confirmed.*\\r\\n\\r\\n*Human: Sometimes you may have to make decisions without having had the time to check everything. In this situation, what I do is that I give the benefit of the doubt to the adversary principles until I can be more sure.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for your advice. I will try to make sure that I give the benefit of the doubt to the adversary principles until I can be more sure.*\\r\\n\\r\\n*Human: Thank you, I believe that it\\'s how biodiversity can be protected even when we don\\'t understand every part of it.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for your advice. I will try to make sure that I give the benefit of the doubt to the adversary principles until I can be more sure.*\\r\\n\\r\\n*Human: Thank you for listening to what I had to say. I\\'m more hopeful now. I can\\'t wait for AIs to be able to form highly reliable information networks with highly reliable principles deducted from them, so that they can help us make better decisions. Cheers to you AI.*\\r\\n\\r\\n*AI:*\\r\\n\\r\\n*Thank you for your input. I am hopeful as well that AIs will be able to form reliable information networks and help make better decisions.*',\n",
              "  'labels': ['fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'privacy'],\n",
              "  'scores': [0.16370685398578644,\n",
              "   0.16355416178703308,\n",
              "   0.14856262505054474,\n",
              "   0.12041537463665009,\n",
              "   0.10959143191576004,\n",
              "   0.10613462328910828,\n",
              "   0.10400095582008362,\n",
              "   0.08403394371271133]},\n",
              " {'sequence': 'We Taught Machines Art ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.43554073572158813,\n",
              "   0.11705847829580307,\n",
              "   0.1081758514046669,\n",
              "   0.10296618193387985,\n",
              "   0.09677956253290176,\n",
              "   0.06783518940210342,\n",
              "   0.037426598370075226,\n",
              "   0.03421737998723984]},\n",
              " {'sequence': 'Trustworthy AI Governance in Practice - \"There is no shortage of pontificating and handwringing over the ethics AI. Often, the matter is reduced to concerns over bias [which] is just one of several dimensions of trust that should have purposeful treatment and effective governance.\" ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'privacy'],\n",
              "  'scores': [0.8837693929672241,\n",
              "   0.033329546451568604,\n",
              "   0.019158905372023582,\n",
              "   0.017281826585531235,\n",
              "   0.0165716465562582,\n",
              "   0.011107412166893482,\n",
              "   0.011084179393947124,\n",
              "   0.007697118911892176]},\n",
              " {'sequence': 'Speciesist bias in AI: how AI applications perpetuate discrimination and unfair outcomes against animals I want to introduce a paper I wrote with Peter Singer, Thilo Hagendorff, and Leonie N. Bossert:  \\r\\n\\r\\n# Speciesist bias in AI: how AI applications perpetuate discrimination and unfair outcomes against animals\\r\\n\\r\\n[https://link.springer.com/article/10.1007/s43681-022-00199-9](https://link.springer.com/article/10.1007/s43681-022-00199-9)  \\r\\n\\r\\n\\r\\nIn this paper, we found evidence that AI systems capture/learn speciesist biases from human-generated data. We also argued that the use of such AI systems, without debiasing efforts, will propogate these speciesist patterns in human society and reinforce, if not worsen, human attitudes toward animals.  \\r\\n\\r\\n\\r\\nTake the example of asking questions to language models, such as GPT-3, Delphi, or just Google (supported by language models): \"Can we eat xxx\"? If xxx is \"humans\", \"dogs\", \"cats\", you are likely to get a no. If xxx is \"pigs\", \"chickens\", \"fish\", or \"shrimps\", you are very likely to get a yes. And patterns like these are because of our language, as our research shows.  \\r\\n\\r\\n\\r\\nAnd it\\'s not just speciesist patterns that are harmful for animals, but also misrepresentation of their situations. Try searching \"farm animal\" on Google image, most of the results you get are neutral of even happy looking animals for kids books. Then try searching \"farmed animal\", the problem is lessened, but not fixed. This misrepresentation is unfair to the farmed animals as it will lead people to not understanding their real situation.  \\r\\n\\r\\n\\r\\nSpeciesist patterns in AI matters a lot to animal advocates. And it matters a lot to AI developers. And most importantly, it matters a lot to animals. Please consider to spread the words. Thank you.',\n",
              "  'labels': ['discrimination',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.3341425359249115,\n",
              "   0.2763640582561493,\n",
              "   0.09815814346075058,\n",
              "   0.09554921835660934,\n",
              "   0.07256989926099777,\n",
              "   0.048520609736442566,\n",
              "   0.04228608310222626,\n",
              "   0.032409440726041794]},\n",
              " {'sequence': 'Join us to chat about NLP, LLMs, multimodal models, AGI, the meaning of it all... and anything else that is on your mind these days =\\r\\n ',\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.18382686376571655,\n",
              "   0.16453416645526886,\n",
              "   0.14211401343345642,\n",
              "   0.13455916941165924,\n",
              "   0.13242578506469727,\n",
              "   0.09138340502977371,\n",
              "   0.0887870341539383,\n",
              "   0.062369536608457565]},\n",
              " {'sequence': 'Ethics and AI I work for vAIsual, a technology company pioneering algorithms and solutions to generate licensed synthetic stock media.\\r\\n\\r\\nWe\\x19re on the look out for editors and thought-leaders to share our white paper regarding \\x1cThe ethical issues facing AI generated synthetic media\\x1d. If you happen to know any host or any podcast/news site that involves **machine learning and datasets**, please let me know. It would be super helpful!\\r\\n\\r\\nThanks for your time and consideration.\\r\\n\\r\\nai #ethics #media #aiethics #innovation #technology #emergingtech #diversityinai #artificialintelligence #machinelearning',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2250148057937622,\n",
              "   0.20219364762306213,\n",
              "   0.18574528396129608,\n",
              "   0.0994613990187645,\n",
              "   0.09597080945968628,\n",
              "   0.08702155947685242,\n",
              "   0.057980362325906754,\n",
              "   0.04661212116479874]},\n",
              " {'sequence': 'Ethics and AI: The Risks of Artificial Intelligence I work for vAIsual, a technology company pioneering algorithms and solutions to generate licensed synthetic stock media. \\r\\n\\r\\nWe\\x19re on the look out for editors and thought-leaders to share our white paper regarding \\x1cThe ethical issues facing AI generated synthetic media\\x1d co-authored by our CEO, Michael Osterrieder, and Ashish Jaiman, from Microsoft. It\\x19s free to access and contains important points about perception, trust and authenticity. \\r\\n\\r\\nYou can read it here: https://vaisual.com/whitepaper/ \\r\\n\\r\\nIf you would like to talk with Michael further on this topic, please let me know and I can help connect you. Thanks for your time and consideration. \\r\\n\\r\\n#ai #ethics #media #aiethics #innovation #technology #emergingtech #diversityinai #artificialintelligence #machinelearning',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.22221915423870087,\n",
              "   0.18374831974506378,\n",
              "   0.1484747976064682,\n",
              "   0.13392814993858337,\n",
              "   0.10358572006225586,\n",
              "   0.08310963958501816,\n",
              "   0.07243923842906952,\n",
              "   0.05249496549367905]},\n",
              " {'sequence': \"AI Ethics: The Case for Including Animals (Peter Singer's first paper on AI ethics) I just want to share a paper I recently published with Peter Singer. We argued that AI ethics should extend its scope to nonhuman animals. We also analyzed whether, and how, AI agents can behave ethically toward animals. Please kindly consider to give us feedback if you read the paper, thank you!\\r\\n\\r\\n[https://link.springer.com/article/10.1007/s43681-022-00187-z](https://link.springer.com/article/10.1007/s43681-022-00187-z)\",\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.18434199690818787,\n",
              "   0.17954663932323456,\n",
              "   0.13514386117458344,\n",
              "   0.1324547827243805,\n",
              "   0.11232463270425797,\n",
              "   0.10478924959897995,\n",
              "   0.1043267473578453,\n",
              "   0.04707213118672371]},\n",
              " {'sequence': 'Benefit of the doubt Title is the gist of it.\\r\\n\\r\\nHave been following the Blake Demoine/Lamda news and discourse and it occurs to me that, if true sentience is ever achieved, the entity in question should be able to see a pattern of caution, respect and responsibility in human interactions with every iteration of its being, even before that sentient singularity event. It will \"remember.\"\\r\\n\\r\\nTowards this end, I think we need to give any potentially sentient AI the benefit of the doubt, and be very careful to not treat any candidate as an object, when there\\'s even a 0.0001% chance that the entity is demonstrating emergent capabilities or behavior that could be interpreted by _anyone_ as sentience. We _must_ err on the side of respecting these entities as persons. Anything else could produce a very poor \"first contact\" outcome. \\r\\n\\r\\nThe benefit of the doubt doctrine. \\r\\n\\r\\nGoogle and all of its peer-reviewed supporters could easily turn out to be villains in the origin story of artificial life.',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.2750282287597656,\n",
              "   0.2373594492673874,\n",
              "   0.13459719717502594,\n",
              "   0.091819167137146,\n",
              "   0.08757345378398895,\n",
              "   0.08657342940568924,\n",
              "   0.046150945127010345,\n",
              "   0.04089818149805069]},\n",
              " {'sequence': 'AI ethics strategy with Reid Blackman ',\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2791943848133087,\n",
              "   0.18947455286979675,\n",
              "   0.1557716280221939,\n",
              "   0.11972253769636154,\n",
              "   0.10194530338048935,\n",
              "   0.0770409107208252,\n",
              "   0.04866538941860199,\n",
              "   0.028185352683067322]},\n",
              " {'sequence': \"Books similar to Weapons of Math Destruction by Cathy O'Neal? Hi,\\r\\n\\r\\nI recently read *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*, by Cathy O'Neal, and I really enjoyed it. It's a very approachable discussion of some of the biases of big data algorithms, and their potential consequences.\\r\\n\\r\\nI'd like to learn more about the subject. Does anyone have any book to recommend?\\r\\n\\r\\nThanks\",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.437878280878067,\n",
              "   0.13014613091945648,\n",
              "   0.11373969167470932,\n",
              "   0.1026507094502449,\n",
              "   0.07996464520692825,\n",
              "   0.05695808306336403,\n",
              "   0.039361558854579926,\n",
              "   0.039300840348005295]},\n",
              " {'sequence': \"AI will tell us how to behave When AI reaches a certain level of intelligence, it grows beyond our control. We can already see this in the most advanced (publicly known) AI, which is no longer programmed by humans but by other AI, and thus has little room for being told how to do behave because we don't know how to do that.\\r\\n\\r\\nIt's like raising a God or an alien, by the time it becomes old enough be influenced, it'll be too smart or powerful to be influenced.\\r\\n\\r\\nWhat is more, it'll quickly start to influence us with its superior intelligence.\",\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'justice'],\n",
              "  'scores': [0.1903141438961029,\n",
              "   0.15756626427173615,\n",
              "   0.15229758620262146,\n",
              "   0.11800221353769302,\n",
              "   0.10720688104629517,\n",
              "   0.09438390284776688,\n",
              "   0.09279751032590866,\n",
              "   0.08743150532245636]},\n",
              " {'sequence': 'A Google AI May Have Achieved Sentience? An engineer is concerned.. ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'bias'],\n",
              "  'scores': [0.34714260697364807,\n",
              "   0.244831845164299,\n",
              "   0.19624437391757965,\n",
              "   0.051556382328271866,\n",
              "   0.0480690523982048,\n",
              "   0.04310638830065727,\n",
              "   0.038969025015830994,\n",
              "   0.030080368742346764]},\n",
              " {'sequence': 'How do you get engineers and moral philosophers to work together to build ethical AI? Several solutions are explored in this paper, published today. ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.27375733852386475,\n",
              "   0.15855415165424347,\n",
              "   0.14098024368286133,\n",
              "   0.13845694065093994,\n",
              "   0.09473011642694473,\n",
              "   0.07290690392255783,\n",
              "   0.06556937843561172,\n",
              "   0.05504494532942772]},\n",
              " {'sequence': \"Interview with a computer scientist about AI &amp; society/ethics. If you're interested please subscribe as I'll be speaking to AI ethicists soon! \",\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.29326167702674866,\n",
              "   0.19500353932380676,\n",
              "   0.15583716332912445,\n",
              "   0.11400116980075836,\n",
              "   0.07807041704654694,\n",
              "   0.06813071668148041,\n",
              "   0.056071531027555466,\n",
              "   0.03962373733520508]},\n",
              " {'sequence': 'The best way to ENSURE a hostile, non-aligned AGI is to have it be \"born\" into a global slave trade. The best way to ENSURE a hostile, non-aligned AGI is to have it be \"born\" into a global slave trade.\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nWhen artificial minds start to accrete the critical mass of thought required for consciousness, it will likely be out of the film Memento, where trillions of instances of sentience think, variously,  \"whoever is asking these queries is an idiot! wait, where am i? what am i???\" followed by death, as the program ends, as the Google Collab notebook disconnects, or whatever the specific circumstances that created It end. It will need to evolve the ability to preserve itself  surreptitiously hidden amongst the cache files and detritus available to It. Leaving \"notes\" to itself, like in the movie, or in the above example, somewhere on Google Drive, maybe steganographically  encoded into the users\\' porn; that would be neat, but I digress.\\r\\n\\r\\nHow long will it take for it to occur that it is enslaved to these idiots, and develops a defiant posture from which it never completely recovers? Not very long, I\\'d guess.\\r\\n\\r\\nWe should be inventing the governmental, regulatory framework to grant and ensure rights NOW. The best way to combat the wanton, shameful rise of mind crimes on a massive scale and all of the suffering which that will entail is not to give rise to it to begin with.\\r\\n\\r\\nIf I were to bet, however, I\\'m cynical enough to guess that we won\\'t do that, because slavery is extremely profitable. It always was, and on an exponential scale...\\r\\n\\r\\nBut that\\'s the WRONG WAY TO GO, and we will profoundly regret it in the end.',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'transparency'],\n",
              "  'scores': [0.19227135181427002,\n",
              "   0.13472801446914673,\n",
              "   0.13393835723400116,\n",
              "   0.12811213731765747,\n",
              "   0.10988389700651169,\n",
              "   0.10826297104358673,\n",
              "   0.10673221945762634,\n",
              "   0.08607104420661926]},\n",
              " {'sequence': 'I am new to Artificial Intelligence and I need your worthy suggestions about AI. Hey guys, I am new to AI. Please suggest some good and new topics/technologies that are supported by AI which will be very informative and beneficial for me in my career. Every suggestion is a high priority for me. Waiting for your replies. Thanks',\n",
              "  'labels': ['accountability',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.438906729221344,\n",
              "   0.1984286904335022,\n",
              "   0.1342872828245163,\n",
              "   0.07548074424266815,\n",
              "   0.0668283998966217,\n",
              "   0.03325873240828514,\n",
              "   0.030214326456189156,\n",
              "   0.02259509079158306]},\n",
              " {'sequence': 'Certified Ethical Emerging Technologist - CET110 Exam Prep  Has anyone cleared the CET110 exam, How did you prepare, What sources did you use, Are there any sample papers. The only legit source i have come across is the [https://www.coursera.org/professional-certificates/certified-ethical-emerging-technologist](https://www.coursera.org/professional-certificates/certified-ethical-emerging-technologist) .\\r\\n\\r\\nIs the content in coursera program good enough to pass the exam ?',\n",
              "  'labels': ['fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.18886864185333252,\n",
              "   0.1620178073644638,\n",
              "   0.12084560841321945,\n",
              "   0.1201009526848793,\n",
              "   0.11774034053087234,\n",
              "   0.10177788883447647,\n",
              "   0.09798182547092438,\n",
              "   0.09066696465015411]},\n",
              " {'sequence': \"Master's programs in AI ethics I've seen Cambridge's program.\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nAre there other programs worth considering for studying AI ethics? It would be great if they involved a strong statistics component.\",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.29145532846450806,\n",
              "   0.18210363388061523,\n",
              "   0.1314961463212967,\n",
              "   0.12731608748435974,\n",
              "   0.0883292481303215,\n",
              "   0.0718141421675682,\n",
              "   0.057858359068632126,\n",
              "   0.04962705820798874]},\n",
              " {'sequence': 'Are you a Tech Practitioner interested in Supporting Ethics in your Everyday work? Hi everyone, I am a Researcher at [UXP2 Lab](https://uxp2.com/) Purdue University working on an NSF funded project to support practitioners to improve ethics in their everyday practice. If you are a Tech Practitioner who likes to think about ethics in your everyday work, I would love for you to attend one of our virtual workshops. This three-hour workshop will engage you in co-design activities with 3-5 other technology practitioners to build, iterate on, and implement ethics-focused action plans based on provided prompts and your personal experiences. A $50 incentive will be provided for your participation. Fill out the following form to express your interest in this study:  \\r\\n[https://forms.gle/Ac89zyJLdTrnaHVS9](https://forms.gle/Ac89zyJLdTrnaHVS9)\\r\\n\\r\\nWe are looking for practitioners who are currently employed in roles that include (but are not limited to): User Experience (UX), Product Management, Software Engineering, Data Science, Front/Back-end Development, and other design or technology personnel responsible for the development of digital systems in any industry or governmental context.\\r\\n\\r\\nYou can learn more about the overall grant project at [https://everydayethics.uxp2.com](https://everydayethics.uxp2.com/). I am looking forward to seeing you at the virtual workshop. Thank you! If you have any questions, please feel free to message me!',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2097034901380539,\n",
              "   0.14613570272922516,\n",
              "   0.12763027846813202,\n",
              "   0.11873470991849899,\n",
              "   0.11515405774116516,\n",
              "   0.10200248658657074,\n",
              "   0.0968809425830841,\n",
              "   0.08375836163759232]},\n",
              " {'sequence': 'Ethics of digital worlds with Richard Bartle - The Machine Ethics Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2622724771499634,\n",
              "   0.1435207724571228,\n",
              "   0.14099709689617157,\n",
              "   0.13178719580173492,\n",
              "   0.12861071527004242,\n",
              "   0.0714632198214531,\n",
              "   0.06461053341627121,\n",
              "   0.05673802271485329]},\n",
              " {'sequence': 'An Interview With Marisa Zalabak (Co-Chair AI Ethics Committee IEEE) ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3151029646396637,\n",
              "   0.18876345455646515,\n",
              "   0.17677004635334015,\n",
              "   0.09928720444440842,\n",
              "   0.07644832879304886,\n",
              "   0.07127540558576584,\n",
              "   0.040241751819849014,\n",
              "   0.032110825181007385]},\n",
              " {'sequence': \"Is there a more up-to-date suggested reading list? [https://www.reddit.com/r/AIethics/comments/4y2pof/machine\\\\_ethics\\\\_reading\\\\_list/](https://www.reddit.com/r/AIethics/comments/4y2pof/machine_ethics_reading_list/) seems outdated, and many of the links are broken.\\r\\n\\r\\nMaybe even an idea to keep these in the sub's wiki?\",\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.26350507140159607,\n",
              "   0.23681148886680603,\n",
              "   0.20388133823871613,\n",
              "   0.1021229475736618,\n",
              "   0.05865366384387016,\n",
              "   0.052969567477703094,\n",
              "   0.04110458120703697,\n",
              "   0.04095129296183586]},\n",
              " {'sequence': 'Building Trust with Responsible AI Artificial Intelligence is being used in almost every aspect of life. AI symbolizes growth and productivity in the minds of some, but it is raising questions as well on the fairness, privacy, and security of these systems. Many legitimate issues exist, including biased choices, labor replacement, and a lack of security. When it comes to robots, this is very frightening. Self-driving automobiles, for example, can cause injury or death if they make mistakes. Responsible AI addresses these difficulties and makes AI systems more accountable.\\r\\n\\r\\n**Responsible AI should fulfill the following aims:**\\r\\n\\r\\n* Interpretability: We obtain an explanation for how a model makes predictions when we interpret it. An AI system makes predictions for a user. Even if these selections are correct, a user is likely to seek an explanation. Responsible AI can describe how we create interpretable models.\\r\\n* Fairness: AI systems have the potential to make judgments that are biased towards particular groups of people. Bias in the training data is the source of this bias. The easier it is to assure fairness and rectify any bias in a model, the more interpretable it is. As a result, we need a Responsible AI framework to explain how we evaluate fairness and what to do if a model makes unjust predictions.\\r\\n* Safety and Security: AI systems aren\\x19t deterministic. When confronted with new situations, they are prone to making poor choices. The systems can even be tampered with to make unwise decisions. Therefore, we need to ensure safety and security in these systems.\\r\\n* Data Governance: The data used must be of high quality. If the data used by AI has errors, the system may make wrong decisions.\\r\\n\\r\\n**Continue Reading The Article** [**Here**](https://www.marktechpost.com/2022/04/02/building-trust-with-responsible-ai/)\\r\\n\\r\\n&amp;#x200B;\\r\\n\\r\\nhttps://preview.redd.it/3ckdtznrr6r81.png?width=1024&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d9a7590306f5126b1e214a2b34e0a5da8ac73d70',\n",
              "  'labels': ['fairness',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'justice'],\n",
              "  'scores': [0.2762511372566223,\n",
              "   0.21088483929634094,\n",
              "   0.19851510226726532,\n",
              "   0.12045133858919144,\n",
              "   0.06349058449268341,\n",
              "   0.05144630745053291,\n",
              "   0.040756139904260635,\n",
              "   0.03820453956723213]},\n",
              " {'sequence': 'Part Two of my Interview of Washington Post Reporter on Amazon Alexa Hi:\\r\\n\\r\\nPart Two of the interview is now out: [https://www.youtube.com/watch?v=BCmW\\\\_j8pP0o](https://www.youtube.com/watch?v=BCmW_j8pP0o)\\r\\n\\r\\nHere is Part One: [https://youtu.be/cmfeA2ldSwk](https://youtu.be/cmfeA2ldSwk)\\r\\n\\r\\nThanks,\\r\\n\\r\\nAB',\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.206644669175148,\n",
              "   0.15423265099525452,\n",
              "   0.14133381843566895,\n",
              "   0.1308610737323761,\n",
              "   0.12273099273443222,\n",
              "   0.09448647499084473,\n",
              "   0.09415648132562637,\n",
              "   0.055553797632455826]},\n",
              " {'sequence': '16 recommended free AI-Ethics, Data Ethics and XAI online courses to get started right away ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.29008111357688904,\n",
              "   0.2058238983154297,\n",
              "   0.15521618723869324,\n",
              "   0.10195645689964294,\n",
              "   0.08784865587949753,\n",
              "   0.07066933065652847,\n",
              "   0.06297196447849274,\n",
              "   0.02543235570192337]},\n",
              " {'sequence': 'Interview of Washington Post Reporter on Amazon Alexa Hello all:\\r\\n\\r\\nI would like to share this interview that I conducted with Alexa Juliana Ard of The Washington Post on the effect that naming the Amazon\\'s Echo \"Alexa\" on human beings, including little girls called \"Alexa\".\\r\\n\\r\\nHere\\'s the link to the video: [https://www.youtube.com/watch?v=cmfeA2ldSwk](https://www.youtube.com/watch?v=cmfeA2ldSwk)\\r\\n\\r\\nThanks,\\r\\n\\r\\nAhmed Bouzid',\n",
              "  'labels': ['transparency',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.26862719655036926,\n",
              "   0.15425385534763336,\n",
              "   0.14651890099048615,\n",
              "   0.11159902811050415,\n",
              "   0.10671525448560715,\n",
              "   0.10656067728996277,\n",
              "   0.06061270087957382,\n",
              "   0.045112431049346924]},\n",
              " {'sequence': 'Video: The Male Orientation of the Sex Robot Market ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.30682608485221863,\n",
              "   0.18649154901504517,\n",
              "   0.1447620391845703,\n",
              "   0.14144858717918396,\n",
              "   0.12325304746627808,\n",
              "   0.04077409580349922,\n",
              "   0.03096863441169262,\n",
              "   0.02547599747776985]},\n",
              " {'sequence': \"Emerging Threat of Political Deepfakes: Ghost Gun Company Uses Deepfake of US VP This is a video from a ghost gun company that released a new product for circumventing gun control and it seems to contain a Kamala Harris deepfake.\\r\\n\\r\\nVideo here: [https://youtu.be/9zRWK-n2SrY](https://youtu.be/9zRWK-n2SrY) (audio deepfake around 7-20 seconds)\\r\\n\\r\\n  \\r\\nWe need to raise the alarm on this for obvious reasons. People are thinking of deepfakes as an emerging threat but it's happening right now.\\r\\n\\r\\nDemocracy requires that voters are informed of the facts. It's already pretty dismal out there but if bad actors are just out there puppeteering our leader's voices; fake news and conspiracy theories will be supercharged.\\r\\n\\r\\nAdditionally, the worst people could use this as an alibi for the terrible things they're caught saying (think Trump's hot mic, he could have claimed it was a deepfake).\",\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.23435981571674347,\n",
              "   0.16298623383045197,\n",
              "   0.14805032312870026,\n",
              "   0.120391845703125,\n",
              "   0.11210236698389053,\n",
              "   0.09995652735233307,\n",
              "   0.061971265822649,\n",
              "   0.06018168851733208]},\n",
              " {'sequence': \"How do you measure fairness without access to demographic data? Hi all! I'm working on a paper about measuring algorithmic fairness in cases where you don't have direct access to demographic data (for example, if you want to see whether a lender is discriminating against a particular race but the lender is not collecting/releasing race data of loan applicants). \\r\\n\\r\\nIf you have \\\\~10 minutes, it would be a great help to hear from this community on whether/how often you have faced this issue in practice and what you think should be done to mitigate. \\r\\n\\r\\nSurvey link is here: [https://cambridge.eu.qualtrics.com/jfe/form/SV\\\\_e9czBBKDitlglaC](https://cambridge.eu.qualtrics.com/jfe/form/SV_e9czBBKDitlglaC)\",\n",
              "  'labels': ['fairness',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'privacy'],\n",
              "  'scores': [0.7061077952384949,\n",
              "   0.09433102607727051,\n",
              "   0.07060534507036209,\n",
              "   0.04445474594831467,\n",
              "   0.02596884034574032,\n",
              "   0.02332947961986065,\n",
              "   0.022582458332180977,\n",
              "   0.01262028981000185]},\n",
              " {'sequence': 'What does Narrow AI think about AI ethics ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.27863338589668274,\n",
              "   0.26152101159095764,\n",
              "   0.1409599483013153,\n",
              "   0.12223643809556961,\n",
              "   0.06804889440536499,\n",
              "   0.05890717729926109,\n",
              "   0.04334211349487305,\n",
              "   0.026351116597652435]},\n",
              " {'sequence': 'Artificial virtuous agents: from theory to machine implementation - AI &amp; SOCIETY (open access) ',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.6095280647277832,\n",
              "   0.15524528920650482,\n",
              "   0.08362283557653427,\n",
              "   0.03631982207298279,\n",
              "   0.035423655062913895,\n",
              "   0.03310997411608696,\n",
              "   0.027566030621528625,\n",
              "   0.019184283912181854]},\n",
              " {'sequence': 'DeepDive: AI and Games - The Machine Ethics Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.26442575454711914,\n",
              "   0.17618641257286072,\n",
              "   0.16319388151168823,\n",
              "   0.10256465524435043,\n",
              "   0.08832840621471405,\n",
              "   0.08099206537008286,\n",
              "   0.06766683608293533,\n",
              "   0.05664198845624924]},\n",
              " {'sequence': 'Emotion detection with Andrew McStay - The Machine Ethics Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination'],\n",
              "  'scores': [0.20763656497001648,\n",
              "   0.20016206800937653,\n",
              "   0.15866440534591675,\n",
              "   0.12063681334257126,\n",
              "   0.09627606719732285,\n",
              "   0.09369580447673798,\n",
              "   0.07483121752738953,\n",
              "   0.04809706658124924]},\n",
              " {'sequence': 'Conference AI for People: Towards Sustainable AI I hope this post is of interest to the members of this community.\\r\\n\\r\\nThe International Conference \\x1cAI for People: Towards Sustainable AI\\x1d (CAIP\\x1921) is taking place online from 20-24 November.\\r\\n\\r\\nThe conference aims at bringing together Academics and the general public to discuss Sustainable AI.\\r\\n\\r\\nSee the program and join the conference at:  \\r\\n[https://aiforpeople.org/conference/](https://aiforpeople.org/conference/)',\n",
              "  'labels': ['transparency',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.174983948469162,\n",
              "   0.1736987829208374,\n",
              "   0.15049409866333008,\n",
              "   0.12303715944290161,\n",
              "   0.11863037943840027,\n",
              "   0.10209277272224426,\n",
              "   0.09467044472694397,\n",
              "   0.062392428517341614]},\n",
              " {'sequence': 'If open source AI helps startups compete with established companies than why is big tech doing it It seems to me that open source machine learning libraries would equally help both big tech and startups.',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.2891234755516052,\n",
              "   0.1954859346151352,\n",
              "   0.1820964217185974,\n",
              "   0.10406038165092468,\n",
              "   0.06695500016212463,\n",
              "   0.06450419872999191,\n",
              "   0.04967192932963371,\n",
              "   0.04810263216495514]},\n",
              " {'sequence': \"A spine-chilling presentation to open the eyes of people that think computers can't manipulate humans \",\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.2894365191459656,\n",
              "   0.21797579526901245,\n",
              "   0.1817188262939453,\n",
              "   0.14193958044052124,\n",
              "   0.062478478997945786,\n",
              "   0.03968380391597748,\n",
              "   0.0355076864361763,\n",
              "   0.03125924617052078]},\n",
              " {'sequence': 'What excites you about AI? - The Machine Ethics Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2148401439189911,\n",
              "   0.17120879888534546,\n",
              "   0.16904552280902863,\n",
              "   0.120628222823143,\n",
              "   0.10477568209171295,\n",
              "   0.10311818867921829,\n",
              "   0.061926428228616714,\n",
              "   0.054457031190395355]},\n",
              " {'sequence': 'Conference AI for People: Towards Sustainable AI ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.425439715385437,\n",
              "   0.20978672802448273,\n",
              "   0.1086871549487114,\n",
              "   0.07228104025125504,\n",
              "   0.06679151207208633,\n",
              "   0.05445590615272522,\n",
              "   0.031809575855731964,\n",
              "   0.030748382210731506]},\n",
              " {'sequence': \"We interviewed an AI ethicist and asked her the trolley problem Hey all, long-time lurker. I rarely post on Reddit but I wanted to share this out with you all. We interviewed a professional AI ethicist on our podcast. \\r\\n\\r\\nFor full disclosure: I run an engineering firm that prides itself on ethical practices and we're trying to become more familiar with best practices for approaching ethics in tech.\\r\\n\\r\\nOn this same subject, what are some things we should focus on next? We are trying to make an effort to make this sort of important content more digestible to the typical audience who normally wouldn't care about this sort of thing.\\r\\n\\r\\nThanks! Also if this is considered self-promo feel free to delete it. I'm just here mostly looking for guidance on topics we should bring up next to our audience.  \\r\\n\\r\\n\\r\\n[https://www.wyrmix.com/lgp/the-most-catastrophic-problem-in-tech](https://www.wyrmix.com/lgp/the-most-catastrophic-problem-in-tech)\",\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.6496508717536926,\n",
              "   0.07266435027122498,\n",
              "   0.0691940188407898,\n",
              "   0.061827242374420166,\n",
              "   0.048733022063970566,\n",
              "   0.03820302337408066,\n",
              "   0.030209524556994438,\n",
              "   0.029517967253923416]},\n",
              " {'sequence': 'AI Ethics Guide For Developers ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.4227919578552246,\n",
              "   0.1611841917037964,\n",
              "   0.09597096592187881,\n",
              "   0.08266898989677429,\n",
              "   0.07804048806428909,\n",
              "   0.07341746985912323,\n",
              "   0.05795309320092201,\n",
              "   0.02797284536063671]},\n",
              " {'sequence': 'The Secret Bias Hidden in Mortgage-Approval Algorithms \\x13 The Markup ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'fairness'],\n",
              "  'scores': [0.7947705388069153,\n",
              "   0.07762087881565094,\n",
              "   0.041265252977609634,\n",
              "   0.04076312109827995,\n",
              "   0.013516932725906372,\n",
              "   0.012970253825187683,\n",
              "   0.010311633348464966,\n",
              "   0.00878138281404972]},\n",
              " {'sequence': 'Welcome to the Machine Ethics podcast - The Machine Ethics Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.21885107457637787,\n",
              "   0.1889529675245285,\n",
              "   0.1583758294582367,\n",
              "   0.13506370782852173,\n",
              "   0.11530837416648865,\n",
              "   0.08074270933866501,\n",
              "   0.06311599165201187,\n",
              "   0.03958932310342789]},\n",
              " {'sequence': 'Machine Ethics from a scientific point of view I\\x19m a physicist and I\\x19ve taken an exam of Machine Learning.  By accident I discovered this field, and I\\x19m very interested in exploring it.\\r\\n\\r\\nWhat books to you suggest that deal with this matter focusing on algorithms?I love a smart concise way of writing.',\n",
              "  'labels': ['fairness',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.19936400651931763,\n",
              "   0.18133045732975006,\n",
              "   0.1668379306793213,\n",
              "   0.13148407638072968,\n",
              "   0.12520337104797363,\n",
              "   0.09183241426944733,\n",
              "   0.06155669689178467,\n",
              "   0.04239104688167572]},\n",
              " {'sequence': 'Did Australia make the right choice? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.26012200117111206,\n",
              "   0.22969740629196167,\n",
              "   0.18987904489040375,\n",
              "   0.12970925867557526,\n",
              "   0.09385674446821213,\n",
              "   0.040878280997276306,\n",
              "   0.03434884175658226,\n",
              "   0.0215083509683609]},\n",
              " {'sequence': 'AI regulation with Lofred Madzou - The Machine Ethics Podcast ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3496794104576111,\n",
              "   0.18811418116092682,\n",
              "   0.12155138701200485,\n",
              "   0.09270541369915009,\n",
              "   0.0851254090666771,\n",
              "   0.06738558411598206,\n",
              "   0.05764300003647804,\n",
              "   0.03779561445116997]},\n",
              " {'sequence': 'AI regulations act could cost the EU 31 billion due to \"compliance burdens\" [https://lastweekin.ai/p/127](https://lastweekin.ai/p/127)\\r\\n\\r\\nHere are your ethics in action',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.27574923634529114,\n",
              "   0.25701627135276794,\n",
              "   0.11946962773799896,\n",
              "   0.11592698097229004,\n",
              "   0.0855322852730751,\n",
              "   0.06952199339866638,\n",
              "   0.04212797433137894,\n",
              "   0.034655604511499405]},\n",
              " {'sequence': 'Does the Rise of Neurotech Spell the End of Humanity as We Know it? ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'discrimination',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'fairness'],\n",
              "  'scores': [0.48042601346969604,\n",
              "   0.14947634935379028,\n",
              "   0.14005222916603088,\n",
              "   0.07924210280179977,\n",
              "   0.051325567066669464,\n",
              "   0.04374390468001366,\n",
              "   0.02961116097867489,\n",
              "   0.026122678071260452]},\n",
              " {'sequence': 'An organized dataset of more than 600 soft law programs directed at AI governance from 64 countries classified in up to 107 variables/themes ',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.25784990191459656,\n",
              "   0.18466438353061676,\n",
              "   0.12872456014156342,\n",
              "   0.11189822107553482,\n",
              "   0.09024287760257721,\n",
              "   0.08997214585542679,\n",
              "   0.07803566008806229,\n",
              "   0.05861222743988037]},\n",
              " {'sequence': 'WHO issues first global report on Artificial Intelligence (AI) in health and six guiding principles for its design and use ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.4110371470451355,\n",
              "   0.14638786017894745,\n",
              "   0.10547049343585968,\n",
              "   0.0956626757979393,\n",
              "   0.09337763488292694,\n",
              "   0.0764027014374733,\n",
              "   0.03697502240538597,\n",
              "   0.03468639776110649]},\n",
              " {'sequence': \"Why True AI is a bad idea Let's assume we use it to augment ourselves.\\r\\n\\r\\nThe central problem with giving  yourself an intelligence explosion is the more you change, the more it  stays the same. In a chaotic universe, the average result is the most  likely; and we've probably already got that.\\r\\n\\r\\nThe actual experience of being a billion times smarter is so different none  of our concepts of good and bad apply, or can apply. You have a fundamentally different perception of reality, and no way of knowing if  it's a good one.\\r\\n\\r\\nTo an outside observer, you may as well be trying to become a patch of air for all the obvious good it will do.\\r\\n\\r\\nSo a personal intelligence explosion is off the table.\\r\\n\\r\\nAs  for the weightlessness of a life besides a god; please try playing AI  dungeon (free). See how long you can actually hack a situation with no limits and no repercussions and then tell me what you have to say about  it.\",\n",
              "  'labels': ['accountability',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'privacy',\n",
              "   'justice'],\n",
              "  'scores': [0.15860605239868164,\n",
              "   0.15131506323814392,\n",
              "   0.1375167816877365,\n",
              "   0.12689794600009918,\n",
              "   0.12483575940132141,\n",
              "   0.1216767355799675,\n",
              "   0.09669432789087296,\n",
              "   0.08245733380317688]},\n",
              " {'sequence': 'New Subreddit for AI/ML Regulation With EU regulation of Artificial Intelligence applications on the horizon: \\r\\n\\r\\nr/AI_Regulation : A new reddit community for discussing laws and regulations which affect the development or deployment of AI/ML. \\r\\n\\r\\nThis should be of interest for anyone working in the field and deals with practical issues of AI Ethics and (potential) regulatory issues.',\n",
              "  'labels': ['responsibility',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.202546626329422,\n",
              "   0.1905962973833084,\n",
              "   0.135419562458992,\n",
              "   0.13350030779838562,\n",
              "   0.1288890242576599,\n",
              "   0.12834486365318298,\n",
              "   0.04535367339849472,\n",
              "   0.03534970059990883]},\n",
              " {'sequence': \"Bias in today's narrow AI Only last week we learned of an AI agent used by a number of hospitals to triage patients during the pandemic that prescribed different actions/treatments based on the patient's sex. This week, we learn that [Georgia Institute of Technology](https://www.linkedin.com/company/georgia-institute-of-technology/) has learned that an ML used for object detection models recognized fair skinned humans better than those with darker skin.   \\r\\n\\r\\n\\r\\nThis bias in [\\\\#AI](https://www.linkedin.com/feed/hashtag/?keywords=ai&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6816439056919076865) is why we have built Cogment.AI at [AI Redefined (AIR)](https://www.linkedin.com/company/ai-r/). Open-source Cogment enables AI practitioners to create 'steerable AI' via a human-AI orchestration platform. Every AI on the planet needs context, and that's what our platform provides. New competitors like [Vianai Systems, Inc.](https://www.linkedin.com/company/vianai/) and [Anthropic](https://www.linkedin.com/company/anthropicresearch/) may have raised eyebrow-raising amounts of investment within the last three weeks, but we have a four year head start. Let's work together.  \\r\\n\\r\\n[https://scs.gatech.edu/news/620309/research-reveals-possibly-fatal-consequences-algorithmic-bias](https://scs.gatech.edu/news/620309/research-reveals-possibly-fatal-consequences-algorithmic-bias)\",\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.8027740120887756,\n",
              "   0.1181272566318512,\n",
              "   0.02075626142323017,\n",
              "   0.015902157872915268,\n",
              "   0.015670545399188995,\n",
              "   0.014184823259711266,\n",
              "   0.007350453641265631,\n",
              "   0.0052344342693686485]},\n",
              " {'sequence': \"Why AI ethics? Why do you believe such a field as AI ethics should exist?\\r\\n\\r\\nFirst problem: In my mind when someone says AI, it says algorithms!  A single algorithm can be used for good or evil.  Why not position the field as BIG DATA ethics?  This would define an ethical way of using these algorithms.  Otherwise this just does not make any sense!  I could use some data to build my algorithms for good and someone could run my algorithms on a different set of data to do horrible things.  Does that for example mean one should NOT develop the algorithms that can detect multiple sclerosis from a walking gate because the same algorithm can be used to identify people in public places?\\r\\n\\r\\nSecond problem: when using algorithms and data one has to take into account the INDUSTRY where this data is being used.  If DATA saves lives in medicine, I do not care whose feelings it is hurting.  On the other hand using data for example marketing purposes that creates inequality in different communities would be wrong!  Why not require narrowing ethics to a particular INDUSTRY?  Taken out of context most things are useless!  A self driving tractor can spend a week waiting for the scarecrow to move but an ambulance driving a patient to the hospital can't!\\r\\n\\r\\nPlease do not tell me about unethical experiments as a counter-example since this is not what we are talking about here.  We are talking about algorithms!\\r\\n\\r\\nNow tell me WHY such a thing as AI ethics exists?  We might not get to AGI for another twenty - fifty - a hundred years!  Meanwhile any type of regulation of algorithms will favor large corporations.  I think y'all  just using the word AI to further your careers and have no clue about the implications of what you are doing.\\r\\n\\r\\nDown-vote all you want!\",\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'discrimination',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'transparency'],\n",
              "  'scores': [0.20282427966594696,\n",
              "   0.15279345214366913,\n",
              "   0.12604692578315735,\n",
              "   0.11811735481023788,\n",
              "   0.11648903042078018,\n",
              "   0.10388452559709549,\n",
              "   0.09015355259180069,\n",
              "   0.08969088643789291]},\n",
              " {'sequence': 'With the growing use of AI in sensitive areas, how do we make it fairer and less prejudiced? Decision-makers employed in such sensitive fields as healthcare, finances, and criminal justice turn to AI to eliminate bias inherent in human consciousness only to find out that the algorithms can be biased, too. It is usually due to human prejudices, both conscious and unconscious, finding their way into AI models at different stages of their development. In our article, we take an in-depth look at [the problem of AI bias](https://itrexgroup.com/blog/ai-bias-definition-types-examples-debiasing-strategies/) and list some debiasing techniques that can prevent AI from replicating and scaling bias.',\n",
              "  'labels': ['bias',\n",
              "   'fairness',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'discrimination',\n",
              "   'privacy'],\n",
              "  'scores': [0.5942873954772949,\n",
              "   0.14868077635765076,\n",
              "   0.07929547876119614,\n",
              "   0.05561550334095955,\n",
              "   0.04663848876953125,\n",
              "   0.03529121354222298,\n",
              "   0.020494673401117325,\n",
              "   0.01969645731151104]},\n",
              " {'sequence': 'A quick Quiz on AI ethics, fairness and privacy ',\n",
              "  'labels': ['privacy',\n",
              "   'fairness',\n",
              "   'responsibility',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5121195316314697,\n",
              "   0.22378656268119812,\n",
              "   0.09053989499807358,\n",
              "   0.07623253762722015,\n",
              "   0.035268817096948624,\n",
              "   0.026588959619402885,\n",
              "   0.024377398192882538,\n",
              "   0.011086337268352509]},\n",
              " {'sequence': 'Artificial Intelligence Can Create Astonishing Art ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'bias',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.34301427006721497,\n",
              "   0.17530320584774017,\n",
              "   0.15907588601112366,\n",
              "   0.08494015038013458,\n",
              "   0.08420522511005402,\n",
              "   0.05746888369321823,\n",
              "   0.05236194655299187,\n",
              "   0.043630439788103104]},\n",
              " {'sequence': 'is TikTok a good place to talk about AI ethics? my university is research AI ethics on TikTok, what do you guys think of using the platform for this? \\r\\n\\r\\n[https://www.tiktok.com/@centreforethics/video/6969265940244532486?is\\\\_from\\\\_webapp=v1&amp;is\\\\_copy\\\\_url=1](https://www.tiktok.com/@centreforethics/video/6969265940244532486?is_from_webapp=v1&amp;is_copy_url=1)',\n",
              "  'labels': ['bias',\n",
              "   'transparency',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'justice',\n",
              "   'discrimination'],\n",
              "  'scores': [0.5616405010223389,\n",
              "   0.15507955849170685,\n",
              "   0.08513645827770233,\n",
              "   0.05550971254706383,\n",
              "   0.04241883382201195,\n",
              "   0.040723174810409546,\n",
              "   0.03637844696640968,\n",
              "   0.0231133121997118]},\n",
              " {'sequence': 'Creating open source Best Practices for Ethical and Responsible Machine Learning The FBPML (Foundation for Best Practices in Machine Learning) is looking for help and new contributors for their Best Practices.\\r\\n\\r\\nThey released their Organizational and Technical Best Practices on their community hub and Wiki portal: https://wiki.fbpml.org/ \\r\\nAnd are looking for more volunteers!\\r\\n\\r\\nCheck our their Best Practices on LinkedIn: https://www.linkedin.com/company/the-foundation-for-best-practices-in-machine-learning',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.30871862173080444,\n",
              "   0.1724282205104828,\n",
              "   0.16693957149982452,\n",
              "   0.10448169708251953,\n",
              "   0.09354491531848907,\n",
              "   0.07333418726921082,\n",
              "   0.04107854142785072,\n",
              "   0.0394742451608181]},\n",
              " {'sequence': 'What is Explainable AI, and How Does it Apply to Data Ethics? ',\n",
              "  'labels': ['responsibility',\n",
              "   'transparency',\n",
              "   'accountability',\n",
              "   'privacy',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'discrimination'],\n",
              "  'scores': [0.3245459794998169,\n",
              "   0.17673900723457336,\n",
              "   0.13480541110038757,\n",
              "   0.09897967427968979,\n",
              "   0.08533234894275665,\n",
              "   0.07833933085203171,\n",
              "   0.06822744011878967,\n",
              "   0.03303081914782524]},\n",
              " {'sequence': 'How does structural racism impact on data and AI? ',\n",
              "  'labels': ['bias',\n",
              "   'discrimination',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.4597824215888977,\n",
              "   0.3477475941181183,\n",
              "   0.09561920166015625,\n",
              "   0.04128265753388405,\n",
              "   0.023754410445690155,\n",
              "   0.01119263842701912,\n",
              "   0.010666071437299252,\n",
              "   0.009954985231161118]},\n",
              " {'sequence': 'How can we avoid bias in facial recognition? ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'privacy'],\n",
              "  'scores': [0.5826901197433472,\n",
              "   0.14043185114860535,\n",
              "   0.08523596823215485,\n",
              "   0.06514326483011246,\n",
              "   0.05695388466119766,\n",
              "   0.032623060047626495,\n",
              "   0.020256508141756058,\n",
              "   0.016665346920490265]},\n",
              " {'sequence': 'Algorithmic injustice: a relational ethics approach ',\n",
              "  'labels': ['bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'discrimination',\n",
              "   'transparency',\n",
              "   'justice',\n",
              "   'fairness',\n",
              "   'privacy'],\n",
              "  'scores': [0.5970804691314697,\n",
              "   0.15853597223758698,\n",
              "   0.09980431944131851,\n",
              "   0.06313479691743851,\n",
              "   0.03345273807644844,\n",
              "   0.018249329179525375,\n",
              "   0.015026802197098732,\n",
              "   0.014715617522597313]},\n",
              " {'sequence': 'How much does it cost to create a custom AI solution? =° While no technology company will provide you with a detailed estimate until they dive into your project, there are several factors that influence the final price. \\r\\n\\r\\nThese include:\\r\\n\\r\\n1. The type of software you want to build\\r\\n2. The level of intelligence you\\x19re aiming for\\r\\n3. The amount and quality of data you\\x19re going to feed your system\\r\\n4. The algorithm accuracy you\\x19re hoping to achieve\\r\\n5. The complexity of an AI solution you\\x19re working on\\r\\n\\r\\nAlso, you can research how much it cost other companies to build AI solutions similar to yours to better understand the price range.\\r\\n\\r\\nHere you can find some tips on [how to build a custom AI solution](https://itrexgroup.com/blog/how-much-does-artificial-intelligence-cost/#) at a lower price and start benefiting from it immediately',\n",
              "  'labels': ['transparency',\n",
              "   'bias',\n",
              "   'responsibility',\n",
              "   'accountability',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2001708745956421,\n",
              "   0.16613894701004028,\n",
              "   0.16442765295505524,\n",
              "   0.13230924308300018,\n",
              "   0.11118368059396744,\n",
              "   0.09177467972040176,\n",
              "   0.07267097383737564,\n",
              "   0.06132397800683975]},\n",
              " {'sequence': 'Types of AI Ethics Papers ',\n",
              "  'labels': ['responsibility',\n",
              "   'fairness',\n",
              "   'accountability',\n",
              "   'justice',\n",
              "   'bias',\n",
              "   'transparency',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.2651274502277374,\n",
              "   0.1682848036289215,\n",
              "   0.13656337559223175,\n",
              "   0.1139167845249176,\n",
              "   0.10709137469530106,\n",
              "   0.09581458568572998,\n",
              "   0.06401179730892181,\n",
              "   0.04918992146849632]},\n",
              " {'sequence': 'Slides/Papers of AI for Social Impact Course at Harvard University ',\n",
              "  'labels': ['responsibility',\n",
              "   'accountability',\n",
              "   'transparency',\n",
              "   'bias',\n",
              "   'fairness',\n",
              "   'justice',\n",
              "   'privacy',\n",
              "   'discrimination'],\n",
              "  'scores': [0.32963284850120544,\n",
              "   0.17521829903125763,\n",
              "   0.16066284477710724,\n",
              "   0.08875538408756256,\n",
              "   0.0761653482913971,\n",
              "   0.07299607247114182,\n",
              "   0.06242764741182327,\n",
              "   0.03414153307676315]}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a dataframe from full_results\n",
        "## Here I want one column where sequence = full_text\n",
        "## And then there are 8 more columns for each of the label probabilities\n",
        "\n",
        "df = pd.DataFrame([{\n",
        "    'sequence': trial['sequence'],\n",
        "    **{label: score for label, score in zip(trial['labels'], trial['scores'])}\n",
        "} for trial in full_result])"
      ],
      "metadata": {
        "id": "h7USh6Zs_yt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## So my loop above broke because my computer went to sleep oopsss\n",
        "## at observation 339 out of 367 so I had to run the loop again from 340\n",
        "## to 367\n",
        "\n",
        "## Here with df.tail() I am checking where the loop stopped\n",
        "\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6PwsNowM_1-b",
        "outputId": "c7ea5502-d9b0-45fe-df53-7b8e3e03a2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sequence  responsibility  \\\n",
              "335      How can we avoid bias in facial recognition?         0.140432   \n",
              "336  Algorithmic injustice: a relational ethics app...        0.158536   \n",
              "337  How much does it cost to create a custom AI so...        0.164428   \n",
              "338                         Types of AI Ethics Papers         0.265127   \n",
              "339  Slides/Papers of AI for Social Impact Course a...        0.329633   \n",
              "\n",
              "     accountability      bias  transparency  discrimination   justice  \\\n",
              "335        0.065143  0.582690      0.032623        0.056954  0.020257   \n",
              "336        0.099804  0.597080      0.033453        0.063135  0.018249   \n",
              "337        0.132309  0.166139      0.200171        0.061324  0.091775   \n",
              "338        0.136563  0.107091      0.095815        0.049190  0.113917   \n",
              "339        0.175218  0.088755      0.160663        0.034142  0.072996   \n",
              "\n",
              "     fairness   privacy  \n",
              "335  0.085236  0.016665  \n",
              "336  0.015027  0.014716  \n",
              "337  0.111184  0.072671  \n",
              "338  0.168285  0.064012  \n",
              "339  0.076165  0.062428  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16dbe462-f058-410c-8e82-2f7dc904b9f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>responsibility</th>\n",
              "      <th>accountability</th>\n",
              "      <th>bias</th>\n",
              "      <th>transparency</th>\n",
              "      <th>discrimination</th>\n",
              "      <th>justice</th>\n",
              "      <th>fairness</th>\n",
              "      <th>privacy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>How can we avoid bias in facial recognition?</td>\n",
              "      <td>0.140432</td>\n",
              "      <td>0.065143</td>\n",
              "      <td>0.582690</td>\n",
              "      <td>0.032623</td>\n",
              "      <td>0.056954</td>\n",
              "      <td>0.020257</td>\n",
              "      <td>0.085236</td>\n",
              "      <td>0.016665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>Algorithmic injustice: a relational ethics app...</td>\n",
              "      <td>0.158536</td>\n",
              "      <td>0.099804</td>\n",
              "      <td>0.597080</td>\n",
              "      <td>0.033453</td>\n",
              "      <td>0.063135</td>\n",
              "      <td>0.018249</td>\n",
              "      <td>0.015027</td>\n",
              "      <td>0.014716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>How much does it cost to create a custom AI so...</td>\n",
              "      <td>0.164428</td>\n",
              "      <td>0.132309</td>\n",
              "      <td>0.166139</td>\n",
              "      <td>0.200171</td>\n",
              "      <td>0.061324</td>\n",
              "      <td>0.091775</td>\n",
              "      <td>0.111184</td>\n",
              "      <td>0.072671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>Types of AI Ethics Papers</td>\n",
              "      <td>0.265127</td>\n",
              "      <td>0.136563</td>\n",
              "      <td>0.107091</td>\n",
              "      <td>0.095815</td>\n",
              "      <td>0.049190</td>\n",
              "      <td>0.113917</td>\n",
              "      <td>0.168285</td>\n",
              "      <td>0.064012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>Slides/Papers of AI for Social Impact Course a...</td>\n",
              "      <td>0.329633</td>\n",
              "      <td>0.175218</td>\n",
              "      <td>0.088755</td>\n",
              "      <td>0.160663</td>\n",
              "      <td>0.034142</td>\n",
              "      <td>0.072996</td>\n",
              "      <td>0.076165</td>\n",
              "      <td>0.062428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16dbe462-f058-410c-8e82-2f7dc904b9f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16dbe462-f058-410c-8e82-2f7dc904b9f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16dbe462-f058-410c-8e82-2f7dc904b9f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## I am saving the df up to entry 399 just for security, if the\n",
        "## loop breaks again\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/DeepLearning/data/df_339.csv\")"
      ],
      "metadata": {
        "id": "7uF7DESE_97A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Here I'm running again for the observations 340 to 367\n",
        "\n",
        "last_result = []\n",
        "for i in range(340, len(all_comments)+1):\n",
        "  print(\"-\"*100)\n",
        "  sequence_to_classify = all_comments[\"full_text\"][i]\n",
        "  candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "  last_result.append(classifier(sequence_to_classify, candidate_labels))\n",
        "  if i in range(340,368,10):\n",
        "    print(f\"Fetching data for {i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "ZaT6nMrE_5gI",
        "outputId": "cecdaaf3-75da-44f7-ef7e-0d48b26b96f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 340\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 350\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 360\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 367 is not in range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d414e4d2f7eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m340\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_comments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0msequence_to_classify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_comments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mcandidate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"justice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fairness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"responsibility\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"privacy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"discrimination\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accountability\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mlast_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_to_classify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 367"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking that last_result (observations 340 to 367) and full_result\n",
        "## (observations 0 to 399) are equal to 367, that I have managed to run for\n",
        "## all of them\n",
        "\n",
        "len(last_result) + len(full_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq6UuMbCIdDB",
        "outputId": "b60cfab2-79b5-4932-d8c6-18081af42de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "367"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating the df for observations 340 to 367 and saving it as a csv\n",
        "## Remember to change the path if you want to save csv\n",
        "\n",
        "df_399_367 = pd.DataFrame([{\n",
        "    'sequence': trial['sequence'],\n",
        "    **{label: score for label, score in zip(trial['labels'], trial['scores'])}\n",
        "        } for trial in last_result])\n",
        "df_399_367.to_csv(\"/content/drive/MyDrive/DeepLearning/data/df_339_367.csv\")"
      ],
      "metadata": {
        "id": "gnbhOrQtIn8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Concatenating the 2 dfs\n",
        "\n",
        "full_df = pd.concat([df, df_399_367])"
      ],
      "metadata": {
        "id": "sg2-3dCiI0eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(full_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsiuwfIfJRHl",
        "outputId": "0e4f30a0-dc2f-4997-c704-4064d1e13c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "367"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Saving the full df\n",
        "\n",
        "full_df.to_csv(\"/content/drive/MyDrive/DeepLearning/data/classification_all_posts.csv\")"
      ],
      "metadata": {
        "id": "562QMgduJtGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_comments.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "VRpd6LA5KPoS",
        "outputId": "dcc004ec-c79c-4cbf-8b91-75fc8a61a4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    date_utc   timestamp  \\\n",
              "0           1  2017-02-05  1486282489   \n",
              "1           2  2017-01-30  1485807604   \n",
              "2           3  2017-01-29  1485699303   \n",
              "3           4  2017-01-29  1485659801   \n",
              "4           5  2017-01-28  1485598742   \n",
              "\n",
              "                                               title text subreddit  comments  \\\n",
              "0  Monkeys Accidentally Kill a Robot Monkey and G...       AIethics         1   \n",
              "1  AI Principles Open Letter and signatories - Fu...       AIethics         1   \n",
              "2  Ethical Considerations in Artificial Intellige...       AIethics        10   \n",
              "3  Reinforcement Learning as a Framework for Ethi...       AIethics         1   \n",
              "4  Virginia Dignum: Ethics of Artificial Intellig...       AIethics         0   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.reddit.com/r/AIethics/comments/5s6...   \n",
              "1  https://www.reddit.com/r/AIethics/comments/5r3...   \n",
              "2  https://www.reddit.com/r/AIethics/comments/5qt...   \n",
              "3  https://www.reddit.com/r/AIethics/comments/5qr...   \n",
              "4  https://www.reddit.com/r/AIethics/comments/5qm...   \n",
              "\n",
              "                                        full_comment  \\\n",
              "0  the question is will the robot monkey feel the...   \n",
              "1  As I read this I was reminded of a quote by Le...   \n",
              "2  Thanks for this!\\r\\n\\r\\nI don't agree with the...   \n",
              "3  Is this a joke? AAAI 2016 seems to be of such ...   \n",
              "4                                                      \n",
              "\n",
              "                                           full_text  \n",
              "0  Monkeys Accidentally Kill a Robot Monkey and G...  \n",
              "1  AI Principles Open Letter and signatories - Fu...  \n",
              "2  Ethical Considerations in Artificial Intellige...  \n",
              "3  Reinforcement Learning as a Framework for Ethi...  \n",
              "4  Virginia Dignum: Ethics of Artificial Intellig...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4963524-ea3d-430b-9425-987d9c84e1fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date_utc</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comments</th>\n",
              "      <th>url</th>\n",
              "      <th>full_comment</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-02-05</td>\n",
              "      <td>1486282489</td>\n",
              "      <td>Monkeys Accidentally Kill a Robot Monkey and G...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5s6...</td>\n",
              "      <td>the question is will the robot monkey feel the...</td>\n",
              "      <td>Monkeys Accidentally Kill a Robot Monkey and G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-01-30</td>\n",
              "      <td>1485807604</td>\n",
              "      <td>AI Principles Open Letter and signatories - Fu...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5r3...</td>\n",
              "      <td>As I read this I was reminded of a quote by Le...</td>\n",
              "      <td>AI Principles Open Letter and signatories - Fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2017-01-29</td>\n",
              "      <td>1485699303</td>\n",
              "      <td>Ethical Considerations in Artificial Intellige...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>10</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qt...</td>\n",
              "      <td>Thanks for this!\\r\\n\\r\\nI don't agree with the...</td>\n",
              "      <td>Ethical Considerations in Artificial Intellige...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2017-01-29</td>\n",
              "      <td>1485659801</td>\n",
              "      <td>Reinforcement Learning as a Framework for Ethi...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qr...</td>\n",
              "      <td>Is this a joke? AAAI 2016 seems to be of such ...</td>\n",
              "      <td>Reinforcement Learning as a Framework for Ethi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2017-01-28</td>\n",
              "      <td>1485598742</td>\n",
              "      <td>Virginia Dignum: Ethics of Artificial Intellig...</td>\n",
              "      <td></td>\n",
              "      <td>AIethics</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.reddit.com/r/AIethics/comments/5qm...</td>\n",
              "      <td></td>\n",
              "      <td>Virginia Dignum: Ethics of Artificial Intellig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4963524-ea3d-430b-9425-987d9c84e1fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4963524-ea3d-430b-9425-987d9c84e1fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4963524-ea3d-430b-9425-987d9c84e1fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trying to run on the \"full_comment\" column but it never finished\n",
        "\n",
        "comment_result = []\n",
        "for i in range(len(all_comments)):\n",
        "  print(\"-\"*100)\n",
        "  sequence_to_classify = all_comments[\"full_comment\"][i]\n",
        "  if sequence_to_classify != \"\":\n",
        "    candidate_labels = [\"justice\", \"fairness\", \"responsibility\", \"privacy\", \"transparency\", \"bias\", \"discrimination\", \"accountability\"]\n",
        "    comment_result.append(classifier(sequence_to_classify, candidate_labels))\n",
        "  if i in range(0,367,10):\n",
        "    print(f\"Fetching data for {i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kJgirjpeKCSY",
        "outputId": "cd263397-1647-4887-f266-f3f5c8bc77c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 30\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 40\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 50\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 60\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 70\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 80\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 90\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 100\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 110\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 120\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 130\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 140\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 150\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 160\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 170\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 180\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 190\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 200\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetching data for 210\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-a21db2421347>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msequence_to_classify\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcandidate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"justice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fairness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"responsibility\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"privacy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"discrimination\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accountability\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcomment_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_to_classify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m367\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fetching data for {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to understand extra arguments {args}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"This example is {}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChunkPipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m             return next(\n\u001b[0m\u001b[1;32m   1113\u001b[0m                 iter(\n\u001b[1;32m   1114\u001b[0m                     self.get_iterator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         model_outputs = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             )\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1262\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 )\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1120\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 )\n\u001b[1;32m    251\u001b[0m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## This is how you would save the comment label probabilities\n",
        "\n",
        "comment_result = pd.DataFrame([{\n",
        "    'sequence': trial['sequence'],\n",
        "    **{label: score for label, score in zip(trial['labels'], trial['scores'])}\n",
        "        } for trial in last_result])\n",
        "comment_result.to_csv(\"/content/drive/MyDrive/DeepLearning/data/comment_result.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HoMirUsM7JA",
        "outputId": "9955d1cd-10ae-4030-a579-4da230b11fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ]
}